\def\t#1{\texttt{#1}}


\chapter{Test Case Generation for Grammatical Framework}
\label{chapterGFtest}

Now we change to a completely new topic. 
Previously, we have enforced an internal logic to the grammar rules, without needing any interaction with the external world. We have taken for granted that the humans who write the rules know what they are doing; and even if this assumption is false, there are already methods that test whether a given rule takes effect in a corpus.


\section{The problem}

Traditionally, GF grammars are tested by the grammarians themselves,
much like unit testing. When implementing some feature, such as 
relative clauses, the grammarian comes up with a test suite of 
sentences that include relative clauses, and stores in the form of 
abstract syntax trees. In principle, a test suite created for one 
language can easily be reused for another, because the ASTs are 
identical. Ideally, every time someone touches relative clauses 
in the any concrete syntax, the trees in the test suite will be 
linearised with the changed concrete syntax, and verified by someone
who speaks the language (or compared to the original gold standard, 
if there is one). This scheme can fail for various reasons: 

\begin{itemize}
\item The original list is not exhaustive: for instance, it tests only
``X, who loves me'' but not ``X, whom I love''. 
\item The original list is exhaustive in one language, but not in all:
for instance, it started in English and only included one noun, but in
French it would need at least one masculine and one feminine noun. 
\item The list is overly long, with redundant test cases, and human
testers are not motivated to read through. 
\item A grammarian makes a change somewhere else in the grammar, and
does not realize that it affects relative clauses, and thus does not
rerun the appropriate test suite. 
\end{itemize}

\section{How it works}


\begin{figure}[h]
  \caption{GF grammar}
  \centering
    \begin{verbatim}
abstract Foods = {
  flags startcat = Comment ;
  cat
    Comment ; Item ; Kind ; Quality ;
  fun
    Pred : Item -> Quality -> Comment ;
    This, That, These, Those : Kind -> Item ;
    Mod : Quality -> Kind -> Kind ;
    Wine, Cheese, Fish, Pizza : Kind ;
    Very : Quality -> Quality ;
    Fresh, Warm, Good, Italian, 
      Expensive, Delicious, Boring : Quality ;
}
    \end{verbatim}
\end{figure}

Figure~\ref{fig:exampleGrammar} shows a small example of a GF grammar. We refer to this grammar throughout the section.

\paragraph{Test case} 
The basic unit of a test case is a single constructor. 
We start by building a set of trees using the constructor.
The constructor can be of any arity: if we are interested in a 0-place function, such as \t{Pizza}, then the subtree \t{Pizza} is the full set of trees. If we choose a function with arguments, such as \t{Pred}, then we do the following:
\begin{itemize}
\item For each argument type (\t{Item} and \t{Quality}), compute the set of minimal and representative trees. This is a recursive process: to compute the set of trees in \t{Item}, we must consider all functions that create its argument types (\t{Kind}), until we have a set of 0-place functions which to choose from.
\item Apply the constructor \t{Mod} to the combinations of the trees.
\end{itemize}

Let us consider a Spanish concrete syntax, and test the function \t{Very : Quality -> Quality}.
\t{Very} takes a \t{Quality} and generates a \t{Quality}; for example, \emph{warm} to \emph{very warm}.

So we need first an argument of type \t{Quality} to \t{Very}. All generated examples must be minimal, so we can rule out arguments that are already using \t{Very}---we only concentrate on the set \t{Fresh, Warm, Good, Italian, Expensive, Delicious, Boring}, and pick as many as are needed to highlight different grammatical phenomena.
The normal Spanish word order is noun--adjective, e.g. \emph{vino italiano} `Italian wine', but a few exceptions, such as \emph{good}, can be placed in front of the noun. Thus in order to pick a representative set of adjectives, we need one premodifier and one postmodifier adjective. The two examples of the category \t{Quality} could be e.g. \t{\{Good, Fresh\}}.

Now we have a set of argument trees, and we finish the test cases by applying the constructor to them. We end up with subtrees \t{\{Very Good, Very Fresh\}}.


\paragraph{Context} 

Now we create contexts for those subtrees. They are of type \t{Quality}, so we create trees in the start category with a hole of \t{Quality}.

There are two ways that a \t{Quality} can end up in a \t{Comment}: by using \t{Pred} or \t{Mod}. (It can also use another \t{Very}, but we exclude repetitions of the same constructor.) 

So let's look at a tree where the hole is in a subtree created by \t{Mod}.
Spanish nouns have gender, so we need at least one masculine and one feminine noun.
Thus minimal and representative trees in category \t{Kind} could be e.g. \{\t{Pizza},\t{Cheese}\}. 

We get \t{\{Mod (Very Good) Pizza, Mod (Very Good) Cheese\}}. 

For Pred, the gender is also relevant, this time the agreement comes from the subject and the adjective is in a predicative position. So we can just reuse the representative Kinds to create representative Items. 
But actually now there's also number to consider, so we end up with 4 trees:

 \t{\{This Pizza, This Cheese, These Pizza, These Cheese\}}.

\section{Technical details}

GF grammar compiles into a low-level format called PGF. After the
compilation, we get one category for each combination of parameters:
for English adjectives, \texttt{A => A$_{pos}$, A$_{comp}$,
A$_{superl}$}, and for Spanish, \texttt{A => A$_{pos×sg×masc}$, \dots,
A$_{superl×pl×fem}$}. 

Suddenly, we have a bunch of new types, and those are different for
each concrete syntax! The original question ``we need a sample of
nouns/verbs/… that makes sense'' can be simplified ``we need one
noun/verb/… of each type''. The types are determined by the parameters
in the concrete syntax. 

So remember all the hassle when you can't pattern match strings to
know something, but instead you have to define a parameter? This is
actually a nice side effect from that: each parameter contributes to a
new category, so it pays off in generating examples. If the feature is
important for your grammar---say that in language A, negation is
simply attaching the word  ``no'' before the verb, and in language B,
negation changes the word order and the object case. Then in the GF
grammar for language B, we would need a Boolean \texttt{isNeg} field
in the relevant categories, which we then pattern match against in
order to determine the relevant operations. That parameter in the
abstract category translates into different concrete categories, and
that way, when we generate example trees, we make sure to include one
of each. For instance, in language A, we could end up with the trees
``any horse'' and ``all horses'' when testing NPs, but in language B,
the set would also include ``no horses''. 

\section{Evaluation}


\begin{itemize}
\item Cost
  \begin{itemize}
  \item time of generating examples
  \item time of looking at examples
  \end{itemize}

\item Effect
  \begin{itemize}
  \item compare against other methods -- what methods?
  \item For application grammars, if you're writing them from scratch, it is actually pretty feasible to just gt the hell out of it as you write. But this doesn't work for bigger grammars.
  \item Morphology can be tested efficiently againts any existing morphological analyser. I've used Apertium for Dutch and Basque.
  \end{itemize}
\end{itemize}


\section{Future work}

We plan to look into existing text corpora, and find trees that are
structurally identical  to those that our program generates as a
minimal and representative example. As a simplified example, ``a worm
without winter'', generated by the program, would be identical\footnote{This particular example holds for English, but in another language, the words ``pizza'' and ``worm'', as well as ``winter'' and ``cheese'' may not match in all relevant features---grammatical gender, whether the word starts with a vowel or a consonant, etc. All this information comes from the concrete syntax!} 
in structure to ``a pizza without cheese'', found in a real text, and
can thus be substituted for the generated one.   
Alternatively, we could use statistical information on co-occurrences
of words, and generate appropriate pools of words, from which we draw
example sentences. 
