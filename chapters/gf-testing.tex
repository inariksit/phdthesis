\def\t#1{\texttt{#1}}
\def\gf{\textsc{gf}}
\def\pgf{\textsc{pgf}}
\def\lfg{\textsc{lfg}}
\def\ccg{\textsc{ccg}}
\def\tag{\textsc{tag}}
\def\cfg{\textsc{cfg}}
\def\pmcfg{\textsc{pmcfg}}
\def\hpsg{\textsc{hpsg}}
\def\feat{\textsc{feat}}
\def\numOfLex{17}
\def\numOfFun{8}
\def\gray#1{{\color{gray}\char`<#1\char`>}}
\newcommand{\tts}[1]{{\tt #1}}
% \newcommand{\quality}[1]{${\tt AP_{#1}}$}
% \newcommand{\kind}[1]{${\tt CN_{#1}}$}
% \newcommand{\very}[1]{${\tt Very_{#1}}$}
% \newcommand{\comment}{${\tt S}$}
% \newcommand{\modFun}[2]{${\tt Mod_{#1\times#2}}$}
% \newcommand{\predFun}[3]{${\tt Pred_{#1\times#2\times#3}}$}
% \newcommand{\itemSpa}[2]{${\tt NP_{#1\times#2}}$}
% \newcommand{\itemEng}[1]{${\tt NP_{#1}}$}

\chapter{Test Case Generation for Grammatical Framework}
\label{chapterGFtest}

\epigraph{\it Fixpoint computation is the new SAT I'm afraid.}{Koen
  Claessen, 2018}

\noindent What is the \emph{essence} of a language? When formalising
and implementing a natural language grammar, which example sentences
do we need to check in order to convince ourselves that the grammar is
correct? 
% Previously, we have enforced an internal logic to the grammar rules,
% without needing any interaction with the external world. We have taken
% for granted that the humans who write the rules know what they are
% doing; and even if this assumption is false, there are already methods
% that test whether a given rule takes effect in a corpus.

Imagine we are formalising a grammar for English, and in particular we
are working on the reflexive construct. In order to check correctness
for the 3rd person singular, we need to test for three different
subjects, because the object has to agree with the subject: ``he sees
himself'', ``she sees herself'' and ``it sees itself''. Without seeing
all three examples (along with the rest of the pronouns), we cannot be certain that the reflexive
construction is implemented correctly. In contrast, the general
pattern of a transitive verb with a non-reflexive object is enough to
test with only one third person subject: \emph{he, she, it}, or any
singular noun or proper name. The agreement only shows in the verb
form, thus including both ``she sees a dog'' and ``John sees a dog''
in the test suite is redundant.  

Now, what is minimal and representative is highly language-dependent. 
For instance, Basque transitive verbs agree with both subject and
object, thus we need 6 $\times$ 6 examples just to cover all verb
forms. In this paper, we are not interested in the morphology per se---there are
easier methods to test for that---but the correctness of the syntactic
function: does the function pick the correct verb form for the correct
combination of subject and object? For that purpose, it is enough to
test the syntactic construction ``transitive verb phrase'' with just a
single transitive verb.

We present a method that, given a grammar (that in general encompasses
an infinite set of sentences), generates a finite set of sentences
that can be used as test cases for the correctness of the grammar. Our
concrete implementation is for a particular grammar formalism,
namely parallel multiple context-free grammars ({\sc pmcfg})
\cite{seki91pmcfg}, which is the core formalism used by the
Grammatical Framework (\gf) \cite{ranta2004gf}. However, the general
method works for any formalism that is at most as expressive as
\pmcfg{}, including context-free grammars (\cfg), formalisms such as Tree-Adjoining Grammar (\tag)
\cite{joshi1975tag}, and several variants of Categorial Grammar
\cite{deGroote2004,steedman1988ccg}.

The following sections assume knowledge of \gf{} and \pmcfg{}
formalisms; we direct the reader to Section~\ref{sec:gf-intro} for a
general \gf{} introduction, and \ref{sec:PMCFG} especially for
translation of a \gf{} grammar into \pmcfg{}.


\section{Related work}

Traditionally, \gf{} grammars are tested by the grammarians themselves,
much in the way described in the introduction of this article. An example
human-written treebank can be found in Khegai's work \cite[p.~136--142]{khegai2006phd}.
For testing the coverage of the grammars, grammarians have used
treebanks such as the UD treebank \cite{nivre2016ud} and Penn treebank
\cite{marcus1993penntreebank}, and for testing morphology, various open-source resources
have been used, such as morphological lexica from the Apertium
project \cite{forcada2011apertium}.

%\todo{Pick one function, get a treebank, see how exhaustively the
%function is used in the treebank.}


As an example of other grammar formalisms, Butt et al.
\cite[pp.~212--213]{butt1999lfg} describe common methods of testing
the {\sc lfg} formalism: similarly to \gf, they use a combination of
human-written test suites meant to cover particular phenomena, and
external larger corpora to test the coverage. As a difference from \gf{}
testing tradition, their human-written test suites include also
ungrammatical sentences: those that the grammar should \emph{not} be
able to parse. However, their tests are only meant for monolingual
grammars, whereas \gf{} tests are for multilingual grammars, so they are
stored as trees. In other words, \gf{} tests only what the grammar
outputs, not what it parses.

Other related work in computational linguistics includes error mining
for parsing grammars, such as Gardent
\cite{gardent2012errormining}. The setup includes triples of dependency
tree, generated sentence and the gold standard sentence. For every triple
where the generated sentence and the gold standard sentence are different, their algorithm
finds the smallest subtrees that cause the problems. Gardent's
algorithm fills a slightly different need than ours: it relies on the
correct linearisation so be known, which we don't. Instead, we want to
generate trees whose linearisations are then read by humans. On the
other hand, Gardent's method would prove very useful once an error is
found---it can be tricky to determine which function exactly caused
the error.

Further away from our approach, \todo{cite and find relevant stuff}
works on parsing grammars rather than generation, with the goal of
detecting strings that cause parsing errors.

Bender et al. \cite{bender2010} describe a system for creating and
testing \hpsg{} \cite{pollard1994hpsg} grammars, by using a detailed
questionnaire about the features of the given language. This system
achieves both generating the grammar rules and testing them
simultaneously, whereas our method relies on an existing grammar. On
the other hand, our system is more general to any kinds of grammars,
including application grammars where the distinctions are not
syntactic but semantic.

However, our biggest source of inspiration is automatic test case
generation for general software, such as \todo{Find more stuff!}
\cite{hamon2004testgen}. Software testing and grammar testing both
deal with notions of coverage and compactness.


\todo{``I suggest that the authors connect their work with generating test for software and automata and also to computational linguistic work on correcting grammars conceived for parsing to turn them into grammars for generation.''}

\section{Grammar}


\begin{figure}[h]
  \centering
\begin{verbatim}
abstract NounPhrases = {
  flags startcat = NP ;
  cat
    S ; NP ; Adv ;                       -- Non-terminal categories
    CN ; Det ; Adj ; Prep ;              -- Terminal (lexical) categories
  fun
    UttNP   : NP -> S ;                  -- Single NP as an utterance
    PredAdj : NP -> Adj -> S ;           -- e.g. "this house is blue"
    PredAdv : NP -> Adv -> S ;           -- e.g. "this house is on a hill"
    DetNP : Det -> NP ;                  -- e.g. "this"; "yours"
    DetCN : Det -> CN -> NP ;            -- e.g. "this house"
    PrepNP : Prep -> NP -> Adv ;         -- e.g. "without the house"
    AdjCN : Adj -> CN -> CN ;            -- e.g. "small house"
    AdvCN : Adv -> CN -> CN ;            -- e.g. "house on a hill"

    a, the, this, these, your : Det ;
    good, small, blue, tired, ready : Adj ;
    house, hill : CN ;
    in, next_to, on, with, without : Prep ; 
}
\end{verbatim}
  \caption{\gf{} grammar for noun phrases}
\label{fig:exampleGrammar}
\end{figure}

Figure~\ref{fig:exampleGrammar} shows a small example of a \gf{}
abstract grammar. The grammar generates noun phrases for a lexicon of
\numOfLex{} words (\emph{a, the, \dots, without}) in four lexical
categories, and \numOfFun{} functions to construct phrases. \t{CN} stands
for common noun, and it can be modified by arbitrarily many adjectives
(\t{Adj}), e.g. \emph{small blue house} is an English linearisation of
the abstract syntax tree \t{AdjCN small (AdjCN blue house)}. A \t{CN}
is quantified into a noun phrase (\t{NP}) by adding a determiner
(\t{Det}), e.g. \emph{the small house} corresponds to tree \t{DetCN
  the (AdjCN small house)}. Alternatively, a \t{Det} can also become
an independent noun phrase (as in, \emph{(I like) this} instead of
\emph{(I like) this house}) using the constructor \t{DetNP}. Finally,
we can form an adverb (\t{Adv}) by combining a preposition (\t{Prep})
with an \t{NP}, and those adverbs can modify yet another \t{CN}.  We
refer to this grammar throughout the chapter.

\subsection{Examples to test}

As examples that help illustrate different testing needs for different
languages, let us take four language-specific phenomena in the scope
of our small grammar: preposition contraction in Dutch, adjective
agreement in Estonian, adjective placement and agreement in Spanish
and determiner placement in Basque. Concrete syntaxes for all four
languages are found in
\url{https://github.com/inariksit/GF-testing/data/grammars/}; however,
the chapter can be read without understanding the details of the
concrete syntaxes.

\paragraph{Preposition contraction in Dutch} In Dutch, some prepositions should
merge with a single determiner or pronoun, e.g. \emph{met~dit} `with
this' becomes \emph{hiermee} `herewith', but stay independent when the
determiner quantifies a noun, e.g. \emph{met~dit~huis} `with this house'. 
Other prepositions, such as \emph{zonder} `without', do not
contract with any determiners: \emph{zonder~dit} `without this' and
\emph{zonder~dit~huis} `without this house'.
When testing \t{PrepNP}, we would like to see one preposition that
contracts and one that does not, as well as one \t{NP} that is a
single determiner, and one that comes from a noun. Since the result of
\t{PrepNP} is an adverb, which does not inflect any further, we are
happy with just finding the right arguments to \t{PrepNP}, no need for contexts.
In order to catch a bug in the function, or confirm there is none, we
need the following 4 trees: 
\t{PrepNP} \{ \stackanchor{\tt with}{\tt without} \} 
           \{ \stackanchor{\tt DetNP this}{\tt DetCN this house} \}. 


\paragraph{Adjective agreement in Estonian} In Estonian,
most adjectives agree with nouns in case and number in an attributive
position. However, participles are invariable (singular nominative) as 
attributes but inflect regularly in a predicative position, and a set
of invariable adjectives do not inflect in any position. Furthermore,
in 4 of the 14 grammatical cases, even the regular adjectives only
agree with the noun in number, but the case is always genitive.
Table~\ref{estonian} shows the different behaviours in attributive
position, with \emph{sinine} `blue' as an example of a regular
adjective, and \emph{valmis} `ready' as an invariable.

\begin{table}[h]
\small
\begin{tabular}{ll | ll | ll}

\multicolumn{2}{c|}{\bf Regular} & \multicolumn{2}{c|}{\bf Genitive
                                   agreement} & \multicolumn{2}{c}{\bf
                                                Invariable} \\ \hline
 sinises & majas &  sinise & majaga &  valmis & majas \\
blue-{\sc sg.ine} & house-{\sc sg.ine} & blue-{\sc sg.gen} & house-{\sc sg.com} &  ready.{\sc sg.nom} & house-{\sc sg.ine} \\
\multicolumn{2}{l|}{`in a blue house'} & \multicolumn{2}{l|}{`with a blue house'} & \multicolumn{2}{l}{`in a finished house'} \\
 & & & & & \\
sinistes & majades & siniste & majadega & valmis & majades \\
blue-{\sc pl.ine} & house-{\sc pl.ine} & blue-{\sc pl.gen} & house-{\sc pl.com} & ready.{\sc sg.nom} & house-{\sc pl.ine} \\
\multicolumn{2}{l|}{`in blue houses'} & \multicolumn{2}{l|}{`with blue
                                         houses'} &
                                                     \multicolumn{2}{l}{`in finished houses'}

\end{tabular}
\caption{Estonian adjective agreement}
\label{estonian}
\end{table}

% \begin{table}[h]
% \begin{tabular}{cllcll}
% (1) & suur-e        &  auto-ga       & (2) & suur-te  & auto-de-ga \\ 
%     & big-{\sc gen} &  car-{\sc com} &  & big-{\sc pl.gen} & car-{\sc pl-com} \\
%     & \multicolumn{2}{l}{`with (the) big cars'} 
%                                      &  & \multicolumn{2}{l}{`with (the) big cars'} \\
% \end{tabular}
% \end{table}

%\stackanchor{ \emph{suur-e} \emph{auto-ga}}{\small
%\emph{big}-\textsc{gen} \emph{car}-\textsc{com}} 

%\emph{suur-e} \emph{auto-ga}  \emph{big}-{\sc sg.gen} \emph{car}-\textsc{com} `with a big car'. 
% \noindent Thus in order to test adjectives as attributes, we need an
% example for one of the 10 ``usual'' cases and one of the 4 ``unusual''
% cases, one of each type of adjective, and one of each number. 
\noindent Since we are interested in adjectives, choosing \t{AdjCN} as
the base sounds reasonable---but that only creates an inflection
table, so we must think of a context too. Just like in English, number
comes from the determiner, so we need to wrap the \t{CN} in a \t{DetCN}
with two determiners of different number, for instance \t{this} and
\t{these}. But we still need an example for one of the 10 cases with
normal agreement, such as inessive (in something), and one of the 4
cases with restricted agreement, such as comitative (with something).
These cases correspond to the English prepositions \emph{in} and \emph{with},
so in this abstract syntax we can use \t{PrepNP} with the arguments
\t{in} and \t{with}. This is another showcase of the abstraction level
of \gf{}: in the English concrete syntax, \t{Prep} contains a string
such as `in' or `with', and \t{PrepNP} concatenates the string from its
\t{Prep} argument into the resulting adverb, but in Estonian, \t{Prep}
contains a case, and \t{PrepNP} chooses that case from its \t{NP} argument.
The following set of 8 trees creates all the relevant
distinctions:
% \footnote{If the grammar covered predicative
% constructions, we would need a participle in the test set. As an
% attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable.}: 
 \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
             {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
             {\tt AdjCN}  \{\stackanchor{\tt blue}{\tt ready} \} 
             {\tt house)}.

% If we wanted to test \emph{adjectives} exhaustively, we would need one more context, where
% the adjective is in the predicative position: e.g. `the house is \verb|_|'.
% Furthermore, we need to add a participle to the test cases.
% As an attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable. If we want to test specifically adjectives and not
% \t{PrepNP}, we would prefer to see all types in all positions:
%  \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
%              {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
%              {\tt AdjCN}  \{\stackanchor{\tt blue}{\stackanchor{\tt
%                  ready}{\tt tired}} \} 
%              {\tt house)}.


\paragraph{Adjective placement and agreement in Spanish}
Spanish adjectives agree in number and gender with the noun, in both
attributive and predicative position. In attributive position, most
adjectives (e.g. \t{small}) come after its head, but some adjectives
(e.g. \t{good}) are placed before the head. 
In order to test \t{AdjCN}, with regards to both adjective placement
and agreement, we need the following 8 trees: 
\t{DetCN}  \{ \stackanchor{\tt this}{\tt these} \}
 \t{AdjCN} \{ \stackanchor{\tt good}{\tt small} \} 
           \{ \stackanchor{\tt house}{\tt hill} \}.

\paragraph{Determiner placement in Basque} In Basque, there are three
different ways to place a determiner into a noun phrase. When a number
(other than 1) or a possessive pronoun acts as a determiner in a
complex noun phrase, it is placed between ``heavy'' modifiers, such as
adverbials or relative clauses, and the rest of the noun
phrase. Demonstrative pronouns, such as \emph{this}, are placed after
all modifiers as an independent word. Number 1, which functions as an
indefinite article, acts like demonstratives, but the definite article
is a suffix. If there is a ``light'' modifier, such as an adjective,
the definite article attaches to the modifier; otherwise it attaches
to the noun. In order to test the implementation of this phenomenon,
we need the following 12 trees: 
\t{DetCN} \{
\stackanchor{\stackanchor{}{\tts{the}}}{\stackanchor{\tts{this}}{\tts{your}}}
\} \{ \stackanchor{\tt AdvCN on (DetCN the hill)}{$\varnothing$} \} 
\{ \stackanchor{\tt AdjCN small}{$\varnothing$} \}  {\tt house}.


\section{Using the tool}

Here is a typical use for the tool. Let us take the noun phrase
grammar for Dutch, and pick a single function, say \t{AdvCN}. We
generate test cases, which include the following trees:
\begin{itemize}
\item[] \t{AdvCN (PrepNP next\_to (DetNP your)) hill} \\
`hill next to yours'
\item[] \t{AdvCN (PrepNP next\_to (DetNP your)) house} \\ `house next
to yours'
\end{itemize}
In Dutch, the words \emph{hill} and \emph{house} have different
genders, and the word \emph{yours} has to agree in gender with the
antecedent: \emph{(de) heuvel naast de jouwe} and \emph{(het) huis
  naast het jouwe}. The test cases reveal a bug, where \t{DetNP your}
picks a gender too soon (always neuter), instead of leaving it open in
an inflection table. To fix the bug, we add gender as a parameter to
the \t{Adv} type, and have \t{AdvCN} choose the correct form based on
the gender of the \t{CN}.

After implementing the fix, we run a second test case generation: this
time, not meant for human eyes, but just to compare the old and new
versions of the grammar. We want to make sure that our changes 
to \t{Adv}, \t{AdvCN} and \t{DetNP} 
have not caused new bugs in other categories and functions. The
simplest strategy is to generate test cases for \emph{all} functions
in both grammars, and only show those outputs that differ between the
grammars. After our changes, we get the following differences: 

\begin{itemize}
\item[] \t{DetCN the (AdvCN (PrepNP next\_to (DetNP your)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel naast {\bf  het} jouwe}}
   \item[+] \emph{de heuvel naast {\bf  de} jouwe}
  \end{itemize}
\item[] \t{DetCN the (AdvCN (PrepNP without (DetNP this)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel zonder {\bf  dit}}}
   \item[+] \emph{de heuvel zonder {\bf  deze}}
  \end{itemize}
\end{itemize}

\noindent We notice a side effect that we may not have thought of: the
gender is retained in all adverbs made of NPs made of determiners, so
now it has become impossible to say ``the hill next to \emph{that}'',
where \emph{that} is referring to a house. So we do another round of
modifications, compute the difference (to the original grammar or to
the intermediate), and see if something else has changed.

%  We have seen that, in order to test
% whether or not we have implemented a linguistic phenomenon correctly,
% we take a single function as a base, and describe all combinations of
% arguments that are needed to test the function. If the result of the
% function is an inflection table rather than a fully specified result,
% then we need several \emph{contexts} to squeeze out all the different
% forms. For example, a \t{CN} in English is open for number---\t{house}
% is really a table \{\t{Sg~=>}~\emph{``house''}~\t{;~Pl~=>}
% \emph{``houses''}\}, and applying a determiner chooses the right form:
% \t{DetCN~this~house} linearises to \emph{this house} and \t{DetCN
%   these house} linearises to \emph{these houses}. 

% \label{sec:wishlist_comments}
% The example grammar, with only \numOfLex{}-word lexicon and \numOfFun{} syntactic functions,
% generates over 10,000 %17,574
% trees\footnote{e.g. {\tt DetCN the (AdvCN (PrepNP on
% (DetCN a (AdjCN small hill)) (AdjCN blue house))} `the blue house on a
% small hill'}  up to depth 5. 
% However, as we have seen in the examples above, we can test complex
% morphosyntactic phenomena with just a set of 4, 8 or 12 trees,
% depending on the complexity of the language. 

% As mentioned previously, the base of a test case is one syntactic
% function, but often the same sentence ends up showcasing several
% functions. In the Estonian example, we start from \t{AdjCN} 
% and end up in a context formed by \t{PrepNP}---in fact, these 8 trees
% cover all tests we would've needed for \t{PrepNP} itself. Thus,
% it is possible to shrink the test cases effectively, if one wants to
% test the whole grammar at one go.

% Of course, such a test set will not catch e.g. individual
% misspellings, or more systematic bugs in the morphological
% paradigms. But there are easier methods to test for such bugs---our 
% goal is to test the more abstract, syntactic phenomena with as few
% trees as possible.  


\section{Generating the test suite}
\label{sec:testing}

In this section, we explain how the test suites are built.
Earlier in Section~\ref{sec:PMCFG}, we saw how a single abstract category
compiles into multiple concrete categories, depending on the
combinations of parameters. Instead of dealing with parameters
directly, we now have a set of new \emph{types}, which is helpful for
generating test cases.

We use one syntactic function as the base for one set of test
cases. For lexical categories, it also makes sense to test the whole
category, i.e. generate all trees that show that \t{AP} is defined and
handled correctly in the functions. However, we only explain in detail
the method with one syntactic function as a base.

We assume that all test cases are trees with the same start
(top-level) category, such as \t{S} in our example grammar. The
requirement is that the start category is linearised as one string only. 

\subsection{Enumerate functions} As we explained before, each syntactic
function turns into multiple versions, one for each combination of
parameters of its arguments. We test each of these versions
seperately. Each concrete syntactic function may produce one or several trees.

In order to construct trees that use the syntactic function, we need
to supply the function with \emph{arguments}, as well as put the resulting tree
into a \emph{context} that produces a tree in the correct start
category.

\subsection{Enumerate arguments} Some syntactic functions are
simply a single lexical item (for example the word \emph{good}); in
this case just the tree \t{Good} is our answer.
If we choose a function with arguments, such as \t{PrepNP}, then we have
to supply it with argument trees. Each argument needs to be a
tree belonging to the right category (in the example, \t{Prep} and
\t{NP}, respectively). 

When we test a function, we want to see whether or not it uses the
right information from its arguments, in the right way. The
information that a syntactic function uses is any of the strings that
come from linearizing its arguments. In order to be able to see which
string in the result comes from which field from which argument, we
want to generate test cases that only contain unique strings.
For example, the English pronouns {\em you} and {\em she} are worse
test cases than other English pronouns, because all forms are not
identical: {\em you} is both nominative and accusative (I saw {\em
  you} vs. {\em you} sleep), and {\em her} is both accusative and
genitive (I saw {\em her} vs. {\em her} house). 
If we only needed some pronoun for our test case, we would be better
off with e.g. {\em they, them, their}, which has three different forms. 

It is often possible to generate one combination of arguments where
all strings in the linearizations are different. However, it is not
always possible to do this, which is why we in general aim to generate
a set of combinations of arguments, where for each pair of strings
from the arguments, there is always one test case where those strings
are different. In this way, if the syntactic function contains a
mistake, there is always one test case that reveals it.
To continue with the example, if all pronouns behaved like {\em you}
and {\em her}, we could still make do just by creating test cases with
both of them, because their ambiguity manifests in different forms.

In our implementation, we use the \feat{} framework \cite{feat} to
enumerate possible combinations of argument trees, in size order. We
stop when we have found a suitable set of combinations of arguments,
according to the requirement above. \todo{Check the numbers: We also stop (give up) when too
many tries have been made (currently 10.000), but we have not seen
this happen in practice.}

\paragraph{Example: Test cases using \t{AdjCN}} Let us test the function
\t{AdjCN : Adj $\rightarrow$ CN $\rightarrow$ CN} in Spanish
concrete syntax. 
Firstly, we need a minimal and representative set of arguments:
one premodifier and one postmodifier \t{AP} (\t{good} and
\t{small}), as well as one feminine and one masculine
\t{CN} (\t{house} and \t{hill}). Now, our full set of test cases are
\t{AdjCN} applied to the cross product of \{\stackanchor{\tt \small
  good}{\tt \small small}\} $\times$ \{\stackanchor{\tt \small
  house}{\tt \small hill}\}, as seen in Table~\ref{tab:adjAttr}.

\begin{table}[h]
\centering
\begin{tabular}{| l | l |}
\hline
\t{AdjCN good house}   & \t{AdjCN good hill} \\
\textsc{(sg)} buena casa            & \textsc{(sg)} buen cerro \\
\textsc{(pl)} buenas casas          & \textsc{(pl)} buenos cerros \\ \hline

\t{AdjCN small house}   & \t{AdjCN small hill} \\

\textsc{(sg)} casa peque\~{n}a            & \textsc{(sg)} cerro peque\~{n}o \\
\textsc{(pl)} casas peque\~{n}as          & \textsc{(pl)} cerros peque\~{n}os \\ \hline
\end{tabular}
\caption{Agreement and placement of Spanish adjectives in attributive position}
\label{tab:adjAttr}
\end{table}

\subsection{Enumerate contexts} The third and last enumeration we
perform when generating test cases is to generate all possible
\emph{uses} of a function. After we provide a function with arguments,
we need to put the resulting tree into a context, so that we can generate a
single string from the result. By \emph{context}, we mean a tree in
the start category (\t{S} in our example) with a \emph{hole} of the
same type as the function under test (denoted by \char`_).

The important thing here is that the generated set of contexts shows
all the possible different ways the tree can be used. For example, for
a test tree with an inflection table of 4 forms, we would generate 4
different sentences in which each of the 4 inflections is used.

As an example, consider generating contexts for a tree of category \t{CN}.
Since \t{CN} is variable for number, we need two contexts: 
one that chooses the singular form and other that chooses
the plural form. 
This suggests that we should apply two different
\t{CN $\rightarrow$ NP} functions, for instance
\t{DetCN this} and \t{DetCN these}, and
give their results to the \t{UttNP} function, which constructs an \t{S}.

We could pick any of the \t{Pred*} functions, which also has the goal
type \t{S}, but their second arguments don't make any difference as to
which field we choose from the \t{NP}. In the name of minimalism, we
choose \t{UttNP}, because it is the smallest tree. The concrete set of
contexts is thus  \t{UttNP (DetCN this \char`_)}  and \t{UttNP (DetCN these \char`_)}.
We insert the 4 test cases from Figure~\ref{tab:adjAttr} into the
holes, and get 8 trees in total as shown in Figure~\ref{tab:testCases}.

\begin{table}
\centering
\begin{tabular}{| l | l |}
\hline
\t{UttNP (DetCN this
    (\underline{AdjCN good house}))} & \t{UttNP (DetCN this
                                            (\underline{AdjCN good hill}))} \\
esta buena casa          & este buen cerro \\ \hline
\t{UttNP (DetCN these
    (\underline{AdjCN good house}))} & \t{UttNP (DetCN these
                                            (\underline{AdjCN good hill}))} \\
estas buenas casas       & estos buenos cerros \\ \hline
\t{UttNP (DetCN this
    (\underline{AdjCN small house}))} & \t{UttNP (DetCN this
                                            (\underline{AdjCN small hill}))} \\
esta casa peque\~{n}a          & este cerro peque\~{n}o \\ \hline
\t{UttNP (DetCN these
    (\underline{AdjCN small house}))} & \t{UttNP (DetCN these
                                            (\underline{AdjCN small hill}))} \\
estas casas peque\~{n}as      & estos cerros peque\~{n}os \\ \hline
\end{tabular}
\caption{Complete test cases to test \t{AdjCN}}
\label{tab:testCases}
\end{table}

\paragraph{Fixpoint iteration} 
The contexts are generated using fixpoint iteration. We give a full
explanation in Section~\ref{sec:moreFP} (which may be skipped by the
uninterested reader), and just a quick intuition in the
present section.

A subtree in any category \t{C} gets to show its strings to the world
by one way: the strings need to end up in a tree of the start
category.  If \t{C} is the start category, then the subtree of type
\t{C} needs no further context. If \t{C} is not the start category,
then the subtree depends on other categories in order to make it to
the start category. We need to find a succession of function
applications that take a string from some field in \t{C}, through all
other intermediate categories, so that it finally ends up in the start
category.

The word \emph{depend} is a bit counterintuitive here: normally one
would think that e.g. \t{NP}~depends~on~\t{CN}, because we form
\t{NP}s by using functions of type \t{CN $\rightarrow$ NP}. But when
we think of contexts, we say instead that the \emph{context of} \t{CN}
depends on the \emph{context of} \t{NP}. A tree of type \t{CN} would
like to show its strings, but the function \t{UttNP}, which is the
fastest way to the start category, only takes \t{NP}s. So it has to
rely on applications of \t{DetCN this} and \t{DetCN these} to lift it
up into an \t{NP}, and only then can \t{UttNP} get access to its
strings.

We model this as a top-down fixpoint computation, where in the beginning, only
the start category \t{S} has a context (some trivial context like the
identity function, i.e. ``do nothing, you're already there!''). On the
first round, we get to compute contexts for all categories \t{B} that
are arguments to some function \t{g : B $\rightarrow$ S}. On the
second round, we compute contexts for all categories \t{A} that are
arguments to some function \t{f : A $\rightarrow$ B}. Each round
unlocks more categories further down from the start category, so we
get to compute more contexts for categories that depend on the newly
unlocked ones, until all categories have their contexts.

\subsection{Pruning the trees within one set of test cases} 

% \t{your} as definite,
% singular\footnote{In our grammar, \t{your} is singular just because we
%   decided---we could as well have made it plural, or include two
%   variants, \t{yourSg} and \t{yourPl}.} and non-contracting; \t{a} as
% indefinite, singular and non-contracting; \t{this} and \t{the} as
%  definite, singular and contracting; finally, \t{these} as definite,
%  plural and contracting. 

Sometimes we can further reduce test cases created for a single
function, taking advantage of the coercions in the grammar (explained
in Section~\ref{sec:PMCFG}).  Let us take as an example the function
\t{DetNP : Det $\rightarrow$ NP} for Dutch. As usual, the category
\t{Det} compiles into 8 concrete categories: combinations of singular
vs. plural, contracting vs.  non-contracting, and definite
vs. indefinite. But our grammar only has 5 determiners in total, out
of 8 possible combinations---does this mean that we cannot test
\t{DetNP} exhaustively with the small lexicon? Firstly, we look for
coercions of \emph{arguments} (\t{Det}) in the different concrete
versions of \t{DetNP}, and secondly, coercions of the \emph{goal
  category} (\t{NP}) used in the contexts.

\paragraph{Coercions of \t{Det} used by \t{DetNP}} Due to coercions, there are only 4
different type signatures for \t{DetNP}: definiteness is not relevant
when a \t{Det} is made directly into an \t{NP} (it only matters when
combining a determiner with an adjective). This brings us down to 4
arguments for \t{DetNP}, shown below.

\begin{itemize}
\setlength\itemsep{0em}
\item[--] \t{DetNP : Det$_{*\text{,sg,noncontr}}$ $\rightarrow$ NP$_\text{sg,noncontr}$}
\item[--] \t{DetNP : Det$_{*\text{,pl,noncontr}}$ $\rightarrow$ NP$_\text{pl,noncontr}$}
\item[--] \t{DetNP : Det$_{*\text{,sg,contr}}$ $\rightarrow$ NP$_\text{sg,contr}$}
\item[--] \t{DetNP : Det$_{*\text{,pl,contr}}$ $\rightarrow$ NP$_\text{pl,contr}$}
\end{itemize}

% \noindent Four looks better than eight, but we are missing a plural
% non-contracting determiner in the lexicon. However, we may still be
% able to test \t{DetNP} exhaustively---
\paragraph{Contexts for \t{NP}} The next step is to look at the \emph{contexts} for all goal
categories of \t{DetNP}, as shown in Table~\ref{tbl:nps}.  The
contracting \t{NP}s get two contexts, one to choose the full form and
other the contracted form.  The non-contracting ones only get one
context each, because their field for the contracted form is empty.


\begin{table}
\centering
%\resizebox{\textwidth}{!}{
\begin{tabular}{|l|l|l|l|} \hline
\t{NP$_\text{sg,noncontr}$} & \t{NP$_\text{pl,noncontr}$} & \t{NP$_\text{sg,contr}$}  & \t{NP$_\text{pl,contr}$}\\ \hline

\t{UttNP~\char`_}   & \t{UttNP~\char`_}   & \t{UttNP~\char`_} & \t{UttNP~\char`_} \\
 &  & \t{PredAdv \gray{any NP} (PrepNP on \char`_)} & \t{PredAdv
                                                      \gray{any NP} (PrepNP on \char`_)}
  \\ \hline
\end{tabular} %}
\caption{Contexts to showcase all strings of different concrete \t{NP}s in the Dutch grammar}
\label{tbl:nps}
\end{table}


\paragraph{Coercions of \t{NP} used in contexts} In addition, we look
for \emph{coercions} for all the goal categories. For instance, there
is one that covers all \t{NP}s; let us call that \t{NP$_*$}. This
tells us that there are functions that take \t{NP}, but don’t care
anything about about its parameters. One such example is \t{UttNP},
which just takes an \t{NP}, chooses the nominative form and makes it
into a standalone utterance.  There is another useful coercion, which
covers both singular and plural contracting \t{NP}s; we call that
\t{NP$_{*\text{,contr}}$}. It is used by \t{PrepNP}\footnote{Along
  with a similar coercion \t{NP$_{*\text{,noncontr}}$} for
  non-contracting \t{NP}s.}, which doesn't care about number, just
whether to merge its arguments or not.  In order to reduce the number
of test cases for any function \t{f~:~A~$\rightarrow$~B}, two
properties need to hold:
\begin{enumerate}
\item A number of concrete categories for \t{B} are interchangeable in a particular
context;
\item That context is one of those chosen to showcase \t{B}.
\end{enumerate}

\noindent With \t{NP$_*$} and \t{NP$_\text{*,contr}$}, both of these
properties hold.
%\t{UttNP : NP$_*$ $\rightarrow$ S}, and \t{PrepNP :
%  Prep  $\rightarrow$ NP$_\text{*,contr}$  $\rightarrow$ Adv}.
Thus, we only need to put one representative of \emph{any} \t{NP} into
the context \t{UttNP~\char`_}, and one representative of the
contracting \t{NP}s into the context \t{PredAdv~\gray{any NP}~(PrepNP~on~\char`_)}. 
The following trees would fit the description:

\begin{itemize}
\item[] \t{UttNP (DetNP this)}  \\
 \emph{deze} \\
 `this'
\item[] \t{PredAdv (DetCN a house) (PrepNP on (DetNP this)}  \\
\emph{een huis hierop} \\
`a house on this'
\end{itemize}


% Now, in order to compute a context for a coercion, we simply take
% the largest common subset of the categories that the coercion covers.
% The coercion \t{NP$_*$} is the most general, covering all \t{NP}s, so it only has the most general
% context: \t{UttNP~\char`_}, which is common to all non-coerced
% \t{NP}s. The other coercion \t{NP$_\text{*,contr}$} is more specific,
% so it has also a second context, only included for contracting
% \t{NP}s. Some contexts for coercions are shown in Table~\ref{tbl:npcs}.

% \begin{table}[h]
% \centering
% \begin{tabular}{|l|l|l|} \hline
% \t{NP$_*$}  &  \t{NP$_{*\text{,noncontr}}$} &\t{NP$_{*\text{,contr}}$}\\ \hline

% \t{UttNP~\char`_} & \t{UttNP~\char`_} & \t{UttNP~\char`_} \\
%                   & & \t{PredAdv \dots{} (PrepNP on \char`_)}
%   \\ \hline
% \end{tabular}
% \caption{Contexts to showcase all strings of some \t{NP}-coercions in the Dutch grammar}
% \label{tbl:npcs}
% \end{table}


\subsection{Pruning the trees to test the whole grammar}
\label{sec:pruning_all}

So far we have completely ignored that one tree can showcase more than
one function. In the Estonian example, we start
by testing \t{AdjCN} and end up with the following 8 trees, where
\t{PrepNP} is in the context: 
\t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
             {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
             {\tt AdjCN}  \{\stackanchor{\tt blue}{\tt ready} \} 
             {\tt house)}.
In fact, these 8 trees cover all tests we would've needed for
\t{PrepNP} itself. Thus, it is possible to shrink the test cases
effectively, if one wants to test the whole grammar at one go.

\paragraph{Deterministic argument generation}
There is a simple way to detect redundancy in the generated trees. We
make the generation of arguments and contexts completely
deterministic, e.g. always choose the function that is alphabetically
first. Then, we would get a sentence such as ``the good house is
good'' for testing both \t{AdjCN} and \t{PredAdj}. The downside is
that the sentences can get boring to read, or even confusing, in the
style of ``the house gives the house the house''.

However, we can split the generation in two stages:
first stage is deterministic, where every noun is \t{house}, and we
can eliminate redundancies by just eliminating copies of the same
tree. Then, when we have a set of unique trees, we can substitute
individual words in them with other words in the same concrete
category.  A sentence such as ``the house gives the hill the
ham'' tests the same properties as the version with \emph{house} in every
role, but at least it is easier to keep track who does what, and
compare the translations of the same tree.

In practice, we only apply the first step, and let the sentences be
redundant. In Section~\ref{sec:evalGF}, we refer to total and unique
trees when generating tests for the whole grammar; ``unique trees''
means the number after removing duplicate trees that are generated to
test different functions, but happen to be the same.

\paragraph{Alternative priorities for context generation} The current
implementation of context generation prioritises minimal trees, such
as \t{UttNP} for \t{NP} instead of any other functions. An alternative
method would be to choose contexts where the \t{NP} can also use its
parameters, in addition to just showing all of its strings. Arguably,
it would tell more to the user to see a sentence like ``this house is
big'', formed with \t{PredAdj}, rather than just ``this house'',
formed by \t{UttNP}. 

However, these alternative priorities are not implemented yet. With
the current scheme, we have found it a useful practice to hide
functions such as \t{UttNP}, which just lift a category into the start
category without introducing other arguments. For future, it would
make sense for a context to serve double purpose: show all its strings
and (try to) use all of its parameters.
% Prefer contexts where there are no coercions


\input{chapters/gf-fixpoints.tex}

\section{Evaluation}
\label{sec:evalGF}

\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|lll|ll|ll|ll|ll|}
\hline
\multicolumn{3}{|r}{Concrete syntax $\rightarrow$}              &
                                                                   \multicolumn{2}{|c}{\bf Dutch} & \multicolumn{2}{|c}{\bf Spanish} & \multicolumn{2}{|c}{\bf Estonian} & \multicolumn{2}{|c|}{\bf Basque} \\
$\downarrow$ Grammar & \#funs+lex & \#trees  &
                                                          \#total & \#uniq & \#total & \#uniq & \#total & \#uniq  & \#total  & \#uniq \\ \hline
{\bf Noun phrases}     & \numOfFun{}+\numOfLex{}  
                               & \textgreater{}10,000  &    21    & 18     & 16     &15     & 33      & 27      & 40       & 36     \\ \hline
{\bf Phrasebook}       
                  & 130+160   & \textgreater{}480,000       
                                                       &   513    & 419     & 504     &382    & 610     & 505     & 538      & 503   \\ \hline
   {\bf Resource gr.}    & 217+446   & \textgreater{}500 billion  
                                                       &  21,370  & 19,825  & 19,689  & 16,662 & 13,733  & 9,194    & 100,967  & 64,390 \\ \hline
\end{tabular}}
\caption{Test cases for all functions in three grammars}
\label{results}
\end{table}


\begin{table}[h]

\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
{\bf Resource grammar function} & {\bf Dutch} & {\bf Spanish}
   & {\bf Estonian} & {\bf Basque} \\ \hline
 
\t{ComparA~} `stronger than you' & 10   & 4   & 20 & 6   \\
\t{RelNP~~~} `a cat that I saw'  & 2    & 23 & 23 & 20   \\
\t{ComplVS~} `say that I sleep'  & 89   & 206 & 171 & 104 \\
\t{ReflVP~~} `see myself'        & 1034 & 890 & 343 & 1082 \\
\hline
\end{tabular}
\caption{Test cases for some individual functions in the resource
  grammar}
\label{results_indiv}
\end{table}

In order to evaluate our method, we generate test cases for grammars
of varying sizes, using the four languages presented earlier: Dutch, Spanish,
Estonian and Basque. These languages come from different language
families, and cover a wide range of grammatical complexity. Dutch and
Spanish are both Indo-European languages, with fairly simple nominal
morphology. Dutch features word order changes in subordinate and
question clauses, and separable prefixes in verb phrases (imagine
English behaving ``look something \emph{up} \~{} {\it up}looked''). 
Spanish has a large number of tenses and moods, and clitics for direct
and indirect objects, which attach to verbs.  To add some linguistic
variety, we include Estonian from the Finno-Ugric language family, and
Basque, an isolate language.  In contrast to Dutch and Spanish,
Estonian and Basque have a rich nominal morphology, with 14
grammatical cases in each. In addition, Basque has the most complex
verb morphology out of all the 4 languages, featuring agreement in
subject, object and indirect object.
The Dutch, Spanish and Estonian grammars behaved similarly to each other
and Basque significantly worse, both in execution time and examples
generated.

Table~\ref{results} shows the number of generated trees for 
in total for all syntactic functions in the three grammars, and
Table~\ref{results_indiv} shows some example functions from the resource grammar. 
As stated earlier, we do not consider generating test cases for all
functions an optimal way of testing a whole resource grammar from scratch;
this gives merely a baseline reduction from all possible trees up to a
reasonable depth. We introduce the grammars and comment on the results
in the following sections. 

\subsection{Grammars}

The first grammar is the toy example introduced earlier in this
article: \t{NounPhrases} with \numOfFun syntactic functions and
\numOfLex words in the lexicon. We wrote the concrete syntaxes from
scratch for each of the languages, instead of using the full resource
grammar and reducing it to only noun phrases. All four concrete
syntaxes were completed in less than an hour, by an experienced
grammarian with some knowledge in all the languages.

The second grammar is a mid-size application grammar: Phrasebook
\cite{ranta2010phrasebook}, with 42 categories such as \t{Person,
  Currency, Price} and \t{Nationality}, 160-word lexicon and 130
functions with arguments. As opposed to the trees that we have seen so far,
which only contain syntactic information, the trees in the Phrasebook
are much more semantic: for example, the abstract tree for the
sentence ``how far is the bar?'' in the Phrasebook is \t{PQuestion
  (HowFar (ThePlace Bar))}, in contrast to the resource grammar tree
{\tt \small UttQS (UseQCl (TTAnt TPres ASimul) PPos (QuestIComp
  (CompIAdv (AdvIAdv how\_IAdv (PositAdvAdj far\_A))) 
  (DetCN (DetQuant DefArt NumSg) (UseN bar\_N))))} for the same
sentence. Limiting up to depth 3, the Phrasebook grammar produces over
480,000 trees\footnote{Application grammars are usually
much more compact than resource grammars, hence depth 3 covers already
a lot of relevant trees.}.

%  All four concrete syntaxes were
% implemented using their respective resource grammars; thus if some
% Phrasebook function has a bug, say it produces ``Spaniard restaurant''
% instead of ``Spanish restaurant'', the problem could be in either grammar.
% In the first case, the resource grammar contains both \t{spanish\_A} ``Spanish'' and
% \t{spaniard\_N} ``Spaniard'', but the application grammarian has
% chosen the wrong function.
% In the second case, the application grammarian has correctly chosen
% \t{spanish\_A} from the resource grammar, but that word itself is
% linearised wrongly into ``Spaniard''.


The third grammar is a restricted version of the \gf{} resource grammar,
with 84 categories, 217 syntactic functions and 446 words in the
lexicon. Since all the languages did not have a complete
implementation, we simply took the subset of functions that was
common, and removed manually a couple of rare constructions and words
that are potentially distracting. 
This fragment produces hundreds of billions of trees already up to depth 5.
None of the resource grammars has been tested systematically before---for
the Estonian grammar \cite{listenmaa_kaljurand2014}, the morphological
paradigms were tested extensively against existing resources, but
syntactic functions were only tested with a treebank of 425 trees.

%: say, animate and inanimate nouns, ending in front vowel and back vowel.

\subsection{Execution time} We ran all the experiments on a MacBook Air
with 1,7 GHz processor and 8 GB RAM. For Phrasebook, it took just
seconds to generate the test suite for all languages. For the resource
grammar, Dutch and Estonian finished in 3--4 minutes. However, the
Basque resource grammar is noticeably more complex, and creating test
trees for all functions took almost three hours.

\subsection{Generated trees}

We report both total and unique trees: total trees are simply the sum
of all trees for all functions, and unique trees is the count after
removing duplicates, as explained in Section~\ref{sec:pruning_all}
(``the pizza gives the pizza the pizza'' style).

\paragraph{Grammar engineering vs. language typology}
As we can see, the number of trees differs a
lot. Table~\ref{results_indiv} shows some expected patterns. For
instance, Basque and Estonian have more complex noun morphology than
Dutch, so \t{RelNP} needs more tests (20+ vs. 2): any function that
constructs an \t{NP} needs to put it in all relevant contexts. We
would expect Spanish to behave more like Dutch, with only 2 distinct
forms, so what is the deal? Looking at the implementation of \t{NP} in
the Spanish grammar, we discover that it actually includes 14
fields. In fact, around 80 \% of the code in the Spanish grammar is
inherited from a common module to all Romance languages (except for
Romanian); thus the implementation is meant to be as general as
possible, and support distinctions that appear in some language, not
necessarily in Spanish.
% In addition to nominative and accusative, which differ for
% personal pronouns (\emph{yo} `I' vs. \emph{m\'{i}} `me'), a few
% prepositions are also encoded as cases, perhaps to generalise among
% all Romance languages so that they can share code. In addition,
% each ``case'' includes a stressed and unstressed form

Likewise, Basque and Dutch have more complex verb phrases
(for different reasons!) than Estonian, so \t{ReflVP} needs more
tests.  In general, we believe the number of test cases has both
language typological and grammar engineering reasons. Other resource
grammarians have reported significant differences in complexity
between implementations: \cite{enache2010} report a 200-time reduction
in the number of concrete rules after changing the implementation of
clitics in verb phrases. 

To further explore the effect of grammar engineering vs. inherent
language complexity, it would be interesting to generate test cases
for two different implementations of the same language.  However,
there is not much material to explore---writing a full resource
grammar is several months' effort, thus writing a second
implementation for a language that already is in the RGL is not a
motivating thing to do. We could explore related languages, but in
practice they are often based on one another, either by copying an
existing one and modifying it (e.g. Afrikaans based on Dutch, Estonian
on Finnish), or writing a parameterised module from the beginning,
with the intention of fitting several languages (e.g. Romance and
Scandinavian languages).  It could be interesting to compare a grammar
similar to a \gf{} resource grammar, but written in some different
grammar formalism. \todo{Find references about converting other
  grammars into a PMCFG format (something by Peter Ljunglöf?)},
convert it to a \pmcfg{} format, and then compare the generated test
cases. 

\paragraph{Two different implementations of Basque noun phrase grammar}


We experimented with the noun phrase grammar for Basque. In one of
them, we implemented nominal morphology using inflection tables, and
syntactic functions choose the correct one.  In another grammar, we
used the Basque resource grammar, which has implemented nouns as
stems, and syntactic functions concatenate suffixes to the stems. 
In the stem-based grammar, nouns have phonological features as
inherent parameters, in order to attach the correct form of the
inflectional morphemes. For test case generation, this had
the added benefit or curse of implicitly testing morphology as
well. For instance, the test cases for \t{AdjCN} included the
adjectives \t{good} and \t{small} just because \emph{good} ends in a
consonant and \emph{small} in a vowel. 

\begin{table}[h]

\centering
\begin{tabular}{| l | l | l |}
\hline
{\bf Function} & {\bf Inflection table}
   & {\bf Concatenate suffixes to stems} \\ \hline
 
\t{UttNP}    & 1 & 1  \\
\t{PredAdj}  & 1 & 1  \\
\t{PredAdv}  & 1 & 1    \\
\t{DetNP}    & 3 & 4   \\
\t{DetCN}    & 3 & 4   \\
\t{PrepNP}   & 1 & 1   \\
\t{AdjCN}    & 7 & 4   \\
\t{AdvCN}    & 7 & 4   \\ \hline
{\bf Total:} & 24 & 20 \\ 
\hline
\end{tabular}
\caption{Two versions of Basque concrete syntax for noun phrase grammar}
\label{basque_versions}
\end{table}

Other differences: AdjCN for inflection table behaved more nicely: the
argument generation gave a nice and manageable \t{AdjCN small house}
and put it in all kinds of weird contexts:

\begin{itemize}
\item UttNP (DetCN a \char`_)
\item UttNP (DetCN your \char`_)
\item UttNP (DetCN thePl \char`_)
\item PredAdv (DetNP your) (PrepNP on (DetCN your \char`_))
\item PredAdv (DetNP your) (PrepNP from (DetCN your \char`_))
 \item PredAdv (DetNP your) (PrepNP on (DetCN thePl \char`_))
 \item PredAdv (DetNP your) (PrepNP from (DetCN thePl \char`_))

\end{itemize}

In contrast, the stem-based grammar created an argument where all the
awkwardness was already: AdjCN good (AdvCN (PrepNP without (DetCN a
house)) house) `good house without a house', and only put it in two
contexts, singular and plural. This is because the lincat for NP
includes all this stuff in different fields, and the most
representative example, i.e. no empty fields, has this awkward adverb
in there.

Why the RG version didn't include \t{your}: because all determiners
have two fields in the RG, \t{pre} and \t{post}, and no matter if one
is empty, all applications of \t{DetCN} are just implemented as
\t{det.pre ++ noun ++ det.post}. So there is no parameter in the RG
for ``det comes before/det comes after''.

\subsection{Qualitative analysis} 

The Basque resource grammar is still a work in progress, and the test
sentences showed serious problems in morphology. We thought it
premature to get a fluent speaker to evaluate the grammar, because the
errors in morphology would probably make it difficult to assess syntax
separately. Phrasebook was implemented using the resource grammar, so
it was equally error-ridden.

For Estonian, we read through all the Phrasebook test sentences. These
505 sentences showed a handful of bugs, all coming from Phrasebook
itself not the resource grammar. Most were individual words having the
wrong inflection paradigm (the right one exists in the resource
grammar, but wrong one was chosen by the application grammarian), but
there were also some bugs in more general functions—for example, using
a wrong form of nationality when applied to a human and when to an
institution, along the lines of ``Spaniard restaurant''. As expected,
Phrasebook sentences were easier to read, and made more sense
semantically than sentences from the resource grammar.

We have been developing the tool by testing it on the Dutch resource
grammar---this process is described in more detail in
Section~\ref{dutch-experiment}. During 6 months, we have committed 22
bugfixes on Dutch in the \gf{} main repository. (In the name of
honesty, a few of the bugs were caused by our earlier “fixes”—that was
before we had implemented the comparison against an older version of
the grammar.) One of the bugs found in Dutch was also present in other
languages, so we fixed it in German and English.

\input{chapters/dutch-experiment.tex}

\section{Conclusion and future work}

We have presented method for automatically generating minimal and
exhaustive sets of test cases for testing grammars.  We have found the
tool useful in large-scale grammar writing, in a context where
grammars need to be \emph{reliable}.

One problem we have encountered is that the test sentences from
resource grammars are often nonsensical semantically, and hence a
native speaker might intuitively say that a sentence is wrong, even
though it is just unnatural.  For instance, the function \t{AdvQVP}
covers constructions such as ``you did \emph{what}?''. However, the
function itself is completely general and can take any verb phrase and
any question adverb, thus bizarre combinations like ``you saw the dog
why'' may appear in the generated test cases. If the grammar is purely
syntactic, we would need external tools to ensure semantic coherence,
but if the grammatical categories already include semantic
distinctions, e.g. limiting the subject and indirect object of
\emph{give} into humans, that naturally restricts the generated test
suite.


So far the only mode of operation is generating test cases for a
single function. 
% Generating test cases to all trees often leads to redundant
% trees---as we noted in Section~\ref{sec:wishlist_comments}, the trees
% that are needed to test \t{AdjCN} in Estonian are exactly the same
% trees we need to test \t{PrepNP}, even though the functions are
% seemingly separate. 
As future work, we are planning to add a separate
mode for testing the whole grammar from scratch: intentionally create
trees that test several functions at once.
We have an implementation only for \gf{} grammars so far, but the
general method works for any grammar formalism that can be compiled
into \pmcfg{}. \gf{} already supports reading context-free grammars,
so testing any existing \cfg{} is a matter of some preprocessing. 

