\def\t#1{\texttt{#1}}
\def\gf{\textsc{gf}}
\def\pgf{\textsc{pgf}}
\def\lfg{\textsc{lfg}}
\def\ccg{\textsc{ccg}}
\def\tag{\textsc{tag}}
\def\cfg{\textsc{cfg}}
\def\pmcfg{\textsc{pmcfg}}
\def\hpsg{\textsc{hpsg}}
\def\feat{\textsc{feat}}
\def\numOfLex{17}
\def\numOfFun{8}
\newcommand{\tts}[1]{{\tt #1}}
% \newcommand{\quality}[1]{${\tt AP_{#1}}$}
% \newcommand{\kind}[1]{${\tt CN_{#1}}$}
% \newcommand{\very}[1]{${\tt Very_{#1}}$}
% \newcommand{\comment}{${\tt S}$}
% \newcommand{\modFun}[2]{${\tt Mod_{#1\times#2}}$}
% \newcommand{\predFun}[3]{${\tt Pred_{#1\times#2\times#3}}$}
% \newcommand{\itemSpa}[2]{${\tt NP_{#1\times#2}}$}
% \newcommand{\itemEng}[1]{${\tt NP_{#1}}$}

\chapter{Test Case Generation for Grammatical Framework}
\label{chapterGFtest}

\epigraph{\it Fixpoint computation is the new SAT I'm afraid.}{Koen
  Claessen, 2018}

\noindent What is the \emph{essence} of a language? When formalising
and implementing a natural language grammar, which example sentences
do we need to check in order to convince ourselves that the grammar is
correct? 
% Previously, we have enforced an internal logic to the grammar rules,
% without needing any interaction with the external world. We have taken
% for granted that the humans who write the rules know what they are
% doing; and even if this assumption is false, there are already methods
% that test whether a given rule takes effect in a corpus.

Imagine we are formalising a grammar for English, and in particular we
are working on the reflexive construct. In order to check correctness
for the 3rd person singular, we need to test for three different
subjects, because the object has to agree with the subject: ``he sees
himself'', ``she sees herself'' and ``it sees itself''. Without seeing
all three examples, we cannot be certain that the reflexive
construction is implemented correctly. In contrast, the general
pattern of a transitive verb with a non-reflexive object is enough to
test with only one third person subject: \emph{he, she, it}, or any
singular noun or proper name. The agreement only shows in the verb
form, thus including both ``she sees a dog'' and ``John sees a dog''
in the test suite is redundant.  

Now, what is minimal and representative is highly language-dependent. 
For instance, Basque transitive verbs agree with both subject and
object, thus we need 6 $\times$ 6 examples just to cover all verb
forms. In this paper, we are not interested in the morphology per se---there are
easier methods to test for that---but the correctness of the syntactic
function: does the function pick the correct verb form for the correct
combination of subject and object? For that purpose, it is enough to
test the syntactic construction ``transitive verb phrase'' with just a
single transitive verb.

We present a method that, given a grammar (that in general encompasses
an infinite set of sentences), generates a finite set of sentences
that can be used as test cases for the correctness of the grammar. Our
concrete implementation is for a particular grammar formalism,
namely parallel multiple context-free grammars ({\sc pmcfg})
\cite{seki91pmcfg}, which is the core formalism used by the
Grammatical Framework (\gf) \cite{ranta2004gf}. However, the general
method works for any formalism that is at most as expressive as
\pmcfg{}, including context-free grammars (\cfg), formalisms such as Tree-Adjoining Grammar (\tag)
\cite{joshi1975tag}, and several variants of Categorial Grammar
\cite{deGroote2004,steedman1988ccg}.

The following sections assume knowledge of \gf{} and \pmcfg{}
formalisms; we direct the reader to Section~\ref{sec:gf-intro} for a
general \gf{} introduction, and \ref{sec:PMCFG} especially for
translation of a \gf{} grammar into \pmcfg{}.


\section{Previous work}

Traditionally, \gf{} grammars are tested by the grammarians themselves,
much in the way described in the introduction of this article. An example
human-written treebank can be found in \cite[p.~136--142]{khegai2006phd}.
For testing the coverage of the grammars, grammarians have used
treebanks such as the UD treebank \cite{nivre2016ud} and Penn treebank
\cite{marcus1993penntreebank}, and for testing morphology, various open-source resources
have been used, such as morphological lexica from the Apertium
project \cite{forcada2011apertium}.

%\todo{Pick one function, get a treebank, see how exhaustively the
%function is used in the treebank.}


As an example of other grammar formalisms,
\cite[pp.~212--213]{butt1999lfg} describe common methods of testing
the {\sc lfg} formalism: similarly to \gf, they use a combination of
human-written test suites meant to cover particular phenomena, and
external larger corpora to test the coverage. As a difference from \gf{}
testing tradition, their human-written test suites include also
ungrammatical sentences: those that the grammar should \emph{not} be
able to parse. However, their tests are only meant for monolingual
grammars, whereas \gf{} tests are for multilingual grammars, so they are
stored as trees. In other words, \gf{} tests only what the grammar
outputs, not what it parses.

\todo{``I suggest that the authors connect their work with generating test for software and automata and also to computational linguistic work on correcting grammars conceived for parsing to turn them into grammars for generation.''}

\cite{bender2010} describe a system for creating and testing \hpsg{} \cite{pollard1994hpsg}
grammars, by using a detailed questionnaire about the features of the
given language. This system achieves both generating the grammar rules
and testing them simultaneously, whereas our method relies on an
existing grammar. On the other hand, our system is more general to any
kinds of grammars, including application grammars where the
distinctions are not syntactic but semantic.

\section{Grammar}


\begin{figure}[h]
  \centering
\begin{verbatim}
abstract NounPhrases = {
  flags startcat = NP ;
  cat
    S ; NP ; Adv ;                       -- Non-terminal categories
    CN ; Det ; Adj ; Prep ;              -- Terminal (lexical) categories
  fun
    UttNP   : NP -> S ;                  -- Single NP as an utterance
    PredAdj : NP -> Adj -> S ;           -- e.g. "this house is blue"
    PredAdv : NP -> Adv -> S ;           -- e.g. "this house is on a hill"
    DetNP : Det -> NP ;                  -- e.g. "this"; "yours"
    DetCN : Det -> CN -> NP ;            -- e.g. "this house"
    PrepNP : Prep -> NP -> Adv ;         -- e.g. "without the house"
    AdjCN : Adj -> CN -> CN ;            -- e.g. "small house"
    AdvCN : Adv -> CN -> CN ;            -- e.g. "house on a hill"

    a, the, this, these, your : Det ;
    good, small, blue, tired, ready : Adj ;
    house, hill : CN ;
    in, next_to, on, with, without : Prep ; 
}
\end{verbatim}
  \caption{\gf{} grammar for noun phrases}
\label{fig:exampleGrammar}
\end{figure}

Figure~\ref{fig:exampleGrammar} shows a small example of a \gf{} abstract
grammar. The grammar generates noun phrases for a lexicon of 15
words (\emph{a, the, \dots, without}) in four lexical categories,
and seven functions to construct phrases. \t{CN} stands for common
noun, and it can be modified by arbitrarily many adjectives (\t{Adj}),
e.g. \emph{small blue house} is an English linearisation of the
abstract syntax tree \t{AdjCN small (AdjCN blue house)}. A \t{CN} is
quantified into a noun phrase (\t{NP}) by adding a determiner
(\t{Det}), e.g. \emph{the small house} corresponds to tree \t{DetCN the (AdjCN small
  house)}. Alternatively, a \t{Det} can also become an independent
noun phrase (as in, \emph{(I like) this} instead of \emph{(I like) this
  house}) using the constructor \t{DetNP}. Finally, we can form an
adverb (\t{Adv}) by combining a preposition (\t{Prep}) with an \t{NP},
and those adverbs can modify yet another \t{CN}. 
We refer to this grammar throughout the chapter.

As examples that help illustrate different testing needs for different
languages, let us take four language-specific phenomena in the scope
of our small grammar: adjective placement and agreement in Spanish,
preposition contraction in Dutch, adjective agreement in Estonian and
determiner placement in Basque. Concrete syntaxes for all four
languages are found in Appendix~\todo{make appendix}; however, the
chapter can be read without understanding the details of the grammar.


\subsection{Preposition contraction in Dutch} In Dutch, some prepositions should
merge with a single determiner or pronoun, e.g. \emph{met~dit} `with
this' becomes \emph{hiermee} `herewith', but stay independent when the
determiner quantifies a noun, e.g. \emph{met~dit~huis} `with this house'. 
Other prepositions, such as \emph{zonder} `without', do not
contract with any determiners: \emph{zonder~dit} `without this' and
\emph{zonder~dit~huis} `without this house'.
When testing \t{PrepNP}, we would like to see one preposition that
contracts and one that does not, as well as one \t{NP} that is a
single determiner, and one that comes from a noun. Since the result of
\t{PrepNP} is an adverb, which does not inflect any further, we are
happy with just finding the right arguments to \t{PrepNP}, no need for contexts.
In order to catch a bug in the function, or confirm there is none, we
need the following 4 trees: \\
\t{PrepNP} \{ \stackanchor{\tt with}{\tt without} \} 
           \{ \stackanchor{\tt DetNP this}{\tt DetCN this house} \}. 

\subsection{Adjective agreement in Estonian} In Estonian,
most adjectives agree with nouns in case and number in an attributive
position. However, participles are invariable (singular nominative) as 
attributes but inflect regularly in a predicative position, and a set
of invariable adjectives do not inflect in any position. Furthermore,
in 4 of the 14 grammatical cases, even the regular adjectives only
agree with the noun in number, but the case is always genitive.
Table~\ref{estonian} shows the different behaviours in attributive
position, with \emph{sinine} `blue' as an example of a regular
adjective, and \emph{valmis} `ready' as an invariable.

\begin{table}[h]
\small
\begin{tabular}{ll | ll | ll}

\multicolumn{2}{c|}{\bf Regular} & \multicolumn{2}{c|}{\bf Genitive
                                   agreement} & \multicolumn{2}{c}{\bf
                                                Invariable} \\ \hline
 sinises & majas &  sinise & majaga &  valmis & majas \\
blue-{\sc sg.ine} & house-{\sc sg.ine} & blue-{\sc sg.gen} & house-{\sc sg.com} &  ready.{\sc sg.nom} & house-{\sc sg.ine} \\
\multicolumn{2}{l|}{`in a blue house'} & \multicolumn{2}{l|}{`with a blue house'} & \multicolumn{2}{l}{`in a finished house'} \\
 & & & & & \\
sinistes & majades & siniste & majadega & valmis & majades \\
blue-{\sc pl.ine} & house-{\sc pl.ine} & blue-{\sc pl.gen} & house-{\sc pl.com} & ready.{\sc sg.nom} & house-{\sc pl.ine} \\
\multicolumn{2}{l|}{`in blue houses'} & \multicolumn{2}{l|}{`with blue
                                         houses'} &
                                                     \multicolumn{2}{l}{`in finished houses'}

\end{tabular}
\caption{Estonian adjective agreement}
\label{estonian}
\end{table}

% \begin{table}[h]
% \begin{tabular}{cllcll}
% (1) & suur-e        &  auto-ga       & (2) & suur-te  & auto-de-ga \\ 
%     & big-{\sc gen} &  car-{\sc com} &  & big-{\sc pl.gen} & car-{\sc pl-com} \\
%     & \multicolumn{2}{l}{`with (the) big cars'} 
%                                      &  & \multicolumn{2}{l}{`with (the) big cars'} \\
% \end{tabular}
% \end{table}

%\stackanchor{ \emph{suur-e} \emph{auto-ga}}{\small
%\emph{big}-\textsc{gen} \emph{car}-\textsc{com}} 

%\emph{suur-e} \emph{auto-ga}  \emph{big}-{\sc sg.gen} \emph{car}-\textsc{com} `with a big car'. 
% \noindent Thus in order to test adjectives as attributes, we need an
% example for one of the 10 ``usual'' cases and one of the 4 ``unusual''
% cases, one of each type of adjective, and one of each number. 
\noindent Since we are interested in adjectives, choosing \t{AdjCN} as
the base sounds reasonable---but that only creates an inflection
table, so we must think of a context too. Just like in English, number
comes from the determiner, so we need to wrap the \t{CN} in a \t{DetCN}
with two determiners of different number, for instance \t{this} and
\t{these}. But we still need an example for one of the 10 cases with
normal agreement, such as inessive (in something), and one of the 4
cases with restricted agreement, such as comitative (with something).
These cases correspond to the English prepositions \emph{in} and \emph{with},
so in this abstract syntax we can use \t{PrepNP} with the arguments
\t{in} and \t{with}. This is another showcase of the abstraction level
of \gf{}: in the English concrete syntax, \t{Prep} contains a string
such as `in' or `with', and \t{PrepNP} concatenates the string from its
\t{Prep} argument into the resulting adverb, but in Estonian, \t{Prep}
contains a case, and \t{PrepNP} chooses that case from its \t{NP} argument.
The following set of 8 trees creates all the relevant
distinctions:
% \footnote{If the grammar covered predicative
% constructions, we would need a participle in the test set. As an
% attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable.}: 
 \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
             {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
             {\tt AdjCN}  \{\stackanchor{\tt blue}{\tt ready} \} 
             {\tt house)}.

% If we wanted to test \emph{adjectives} exhaustively, we would need one more context, where
% the adjective is in the predicative position: e.g. `the house is \verb|_|'.
% Furthermore, we need to add a participle to the test cases.
% As an attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable. If we want to test specifically adjectives and not
% \t{PrepNP}, we would prefer to see all types in all positions:
%  \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
%              {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
%              {\tt AdjCN}  \{\stackanchor{\tt blue}{\stackanchor{\tt
%                  ready}{\tt tired}} \} 
%              {\tt house)}.

\subsection{Determiner placement in Basque} In Basque, there are three
different ways to place a determiner into a noun phrase. When a number
(other than 1) or a possessive pronoun acts as a determiner in a
complex noun phrase, it is placed between ``heavy'' modifiers, such as
adverbials or relative clauses, and the rest of the noun
phrase. Demonstrative pronouns, such as \emph{this}, are placed after
all modifiers as an independent word. Number 1, which functions as an
indefinite article, acts like demonstratives, but the definite article
is a suffix. If there is a ``light'' modifier, such as an adjective,
the definite article attaches to the modifier; otherwise it attaches
to the noun. In order to test the implementation of this phenomenon,
we need the following 12 trees:  \\ 
\t{DetCN} \{
\stackanchor{\stackanchor{}{\tts{the}}}{\stackanchor{\tts{this}}{\tts{your}}}
\} \{ \stackanchor{\tt AdvCN on (DetCN the hill)}{$\varnothing$} \} 
\{ \stackanchor{\tt AdjCN small}{$\varnothing$} \}  {\tt house} 


\subsection{Adjective placement and agreement in Spanish}
Spanish adjectives agree in number and gender with the noun, in both
attributive and predicative position. In attributive position, most
adjectives (e.g. \t{small}) come after its head, but some adjectives
(e.g. \t{good}) are placed before the head. 
In order to test \t{AdjCN}, with regards to both adjective placement
and agreement, we need the following 8 trees: \\
\t{DetCN}  \{ \stackanchor{\tt this}{\tt these} \}
 \t{AdjCN} \{ \stackanchor{\tt good}{\tt small} \} 
           \{ \stackanchor{\tt house}{\tt hill} \}.

\subsection{Using our tool} We have seen that, in order to test
whether or not we have implemented a linguistic phenomenon correctly,
we take a single function as a base, and describe all combinations of
arguments that are needed to test the function. If the result of the
function is an inflection table rather than a fully specified result,
then we need several \emph{contexts} to squeeze out all the different
forms. For example, a \t{CN} in English is open for number---\t{house}
is really a table \{\t{Sg =>} \emph{``house''} \t{; Pl =>}
\emph{``houses''}\}, and applying a determiner chooses the right form:
\t{DetCN this house} linearises to \emph{this house} and \t{DetCN
  these house} linearises to \emph{these houses}. 

\label{sec:wishlist_comments}
The example grammar, with only \numOfLex{}-word lexicon and \numOfFun{} syntactic functions,
generates over 10,000 %17,574
trees\footnote{e.g. {\tt DetCN the (AdvCN (PrepNP on
(DetCN a (AdjCN small hill)) (AdjCN blue house))} `the blue house on a
small hill'}  up to depth 5. 
However, as we have seen in the examples above, we can test complex
morphosyntactic phenomena with just a set of 4, 8 or 12 trees,
depending on the complexity of the language. 

As mentioned previously, the base of a test case is one syntactic
function, but often the same sentence ends up showcasing several
functions. In the Estonian example, we start from \t{AdjCN} 
and end up in a context formed by \t{PrepNP}---in fact, these 8 trees
cover all tests we would've needed for \t{PrepNP} itself. Thus,
it is possible to shrink the test cases effectively, if one wants to
test the whole grammar at one go.

Of course, such a test set will not catch e.g. individual
misspellings, or more systematic bugs in the morphological
paradigms. But there are easier methods to test for such bugs---our 
goal is to test the more abstract, syntactic phenomena with as few
trees as possible.  


\section{Generating the test suite}
\label{sec:testing}

We now have all building blocks for creating a representative and
minimal set of test cases.
In Section~\ref{sec:PMCFG}, we saw how a single abstract category
compiles into multiple concrete categories, depending on the
combinations of parameters. Instead of dealing with parameters
directly, we now have a set of new \emph{types}, which is helpful for
generating test cases.

We use one syntactic function as the base for one set of test
cases. For lexical categories, it also makes sense to test the whole
category, i.e. generate all trees that show that \t{AP} is defined and
handled correctly in the functions. However, we only explain in detail
the method with one syntactic function as a base.

We assume that all test cases are trees with the same start
(top-level) category, such as \t{S} in our example grammar. The
requirement is that the start category is linearized as one string only. 

\subsection{Enumerate functions} As we explained before, each syntactic
function turns into multiple versions, one for each combination of
parameters of its arguments. We test each of these versions
seperately. Each concrete syntactic function may produce one or several trees.

In order to construct trees that use the syntactic function, we need
to supply the function with \emph{arguments}, as well as put the resulting tree
into a \emph{context} that produces a tree in the correct start
category.

\subsection{Enumerate arguments} Some syntactic functions are
simply a single lexical item (for example the word \emph{good}); in
this case just the tree \t{Good} is our answer.
If we choose a function with arguments, such as \t{Pred}, then we have
to supply it with argument trees. Each argument needs to be a
tree belonging to the right category (in the example, \t{NP} and
\t{AP}, respectively). 

When we test a function, we want to see whether or not it uses the
right information from its arguments, in the right way. The
information that a syntactic function uses is any of the strings that
come from linearizing its arguments. In order to be able to see which
string in the result comes from which field from which argument, we
want to generate test cases that only contain unique strings.
For example, the English pronouns {\em you} and {\em she} are worse
test cases than other English pronouns, because all forms are not
identical: {\em you} is both nominative and accusative (I saw {\em
  you} vs. {\em you} sleep), and {\em her} is both accusative and
genitive (I saw {\em her} vs. {\em her} house). 
If we only needed some pronoun for our test case, we would be better
off with e.g. {\em they, them, their}, which has three different forms. 

It is often possible to generate one combination of arguments where
all strings in the linearizations are different. However, it is not
always possible to do this, which is why we in general aim to generate
a set of combinations of arguments, where for each pair of strings
from the arguments, there is always one test case where those strings
are different. In this way, if the syntactic function contains a
mistake, there is always one test case that reveals it.
To continue with the example, if all pronouns behaved like {\em you}
and {\em her}, we could still make do just by creating test cases with
both of them, because their ambiguity manifests in different forms.

In our implementation, we use the \feat{} framework \cite{feat} to
enumerate possible combinations of argument trees, in size order. We
stop when we have found a suitable set of combinations of arguments,
according to the requirement above. We also stop (give up) when too
many tries have been made (currently 10.000), but we have not seen
this happen in practice.

\paragraph{Example: Test cases using \t{AdjCN}} Let us test the function
\t{AdjCN : Adj $\rightarrow$ CN $\rightarrow$ CN} in Spanish
concrete syntax. 
Firstly, we need a minimal and representative set of arguments:
one premodifier and one postmodifier \t{AP} (\t{Good} and
\t{Vegan}), as well as one feminine and one masculine
\t{CN} (\t{Pizza} and \t{Wine}). Now, our full set of test cases are
\t{Mod} applied to the cross product of \{\stackanchor{\tt \small
  good}{\tt \small small}\} $\times$ \{\stackanchor{\tt \small
  house}{\tt \small hill}\}, as seen in Table~\ref{tab:adjAttr}.

\begin{table}[h]
\centering
\begin{tabular}{| l | l |}
\hline
\t{AdjCN good house}   & \t{AdjCN good hill} \\
\textsc{(sg)} buena casa            & \textsc{(sg)} buen cerro \\
\textsc{(pl)} buenas casas          & \textsc{(pl)} buenos cerros \\ \hline

\t{AdjCN small house}   & \t{AdjCN small hill} \\

\textsc{(sg)} casa peque\~{n}a            & \textsc{(sg)} cerro peque\~{n}o \\
\textsc{(pl)} casas peque\~{n}as          & \textsc{(pl)} cerros peque\~{n}os \\ \hline
\end{tabular}
\caption{Agreement and placement of Spanish adjectives in attributive position}
\label{tab:adjAttr}
\end{table}

\subsection{Enumerate contexts} The third and last enumeration we
perform when generating test cases is to generate all possible
\emph{uses} of a function. After we provide a function with arguments,
we need to put the resulting tree into a context, so that we can generate a
single string from the result (a sentence). Generating contexts thus requires the specification of a top-level \emph{start category}, which is typically the sentence category (\t{S} in our example).

The important thing here is that the generated set of contexts shows
all the possible different ways the tree can be used. For example, for
a test tree with an inflection table of 4 forms, we would generate 4 different sentences in which each of the 4 inflections is used.

More specifically, by \emph{context}, we mean a tree in the start category (in our case \t{S}), with a \emph{hole} of the same type as the function under test (denoted by \t{\char`_}).

As an example, consider generating contexts for a tree of category \t{CN}.
Since \t{CN} is variable for number, we need two contexts: 
one that picks out the singular form and other that picks out
the plural form. 
This suggests that we should apply two different
\t{Det $\rightarrow$ CN $\rightarrow$ NP} functions, for instance
\t{DetCN this} and \t{DetCN these}, and
give their results to the \t{UttNP} function, which constructs a \t{S}.

We could pick any of the \t{Pred*} functions, which also has the goal
type \t{S}, but their second arguments don't make any difference as to
which field we choose from the \t{NP}. In the name of minimalism, we
choose \t{UttNP}, because it is the smallest tree. The concrete set of
contexts is thus  \t{UttNP (DetCN this \char`_)}  and \t{UttNP (DetCN these \char`_)}.

We insert the 4 test cases from Figure~\ref{tab:adjAttr} into the
holes, and get 8 trees in total as shown in Figure~\ref{tab:testCases}.

\begin{table}
\centering
\begin{tabular}{| l | l |}
\hline
\t{UttNP (DetCN this
    (AdjCN good house))} & \t{UttNP (DetCN this
                                            (AdjCN good hill))} \\
esta buena casa          & este buen cerro \\ \hline
\t{UttNP (DetCN these
    (AdjCN good house))} & \t{UttNP (DetCN these
                                            (AdjCN good hill))} \\
estas buenas casas       & estos buenos cerros \\ \hline
\t{UttNP (DetCN this
    (AdjCN small house))} & \t{UttNP (DetCN this
                                            (AdjCN small hill))} \\
esta peque\~{n}a casa          & este peque\~{n}o cerro \\ \hline
\t{UttNP (DetCN these
    (AdjCN small house))} & \t{UttNP (DetCN these
                                            (AdjCN small hill))} \\
estas peque\~{n}as casas       & estos peque\~{n}os cerros \\ \hline
\end{tabular}
\caption{Complete test cases to test \t{Mod}}
\label{tab:testCases}
\end{table}

\paragraph{Fixpoint iteration} In our tool, computing relevant contexts in a given start category \t{S}, is done once, in advance, for all possible hole types $H$ at the same time, using a fixpoint iteration. It is possible to express the set of relevant contexts for one hole type $H$ in terms of the sets of relevant contexts for other hole types $H'$:
$$
\textsf{contexts}(H) = \textsf{filter}(\;\{ C[F(\_)] \; | \; F \in H \rightarrow H', \; C \in \textsf{contexts}(H') \}\;)
$$
In words, to generate contexts with holes of type $H$, we enumerate all functions $F$ that have a $H$ as an argument, and enumerate all contexts $C$ that have the result type $H'$ of $F$ as a hole type, and put $C$ and $F$ together to get a new context. Then, we apply a function $\textsf{filter}$ to the result in order to filter out redudant contexts, i.e. contexts whose uses of the strings of $H$ are already covered by other contexts in the same set.

To compute relevant contexts with the start category \t{S} as a hole, we use the following definition $\textsf{contexts}(\t{S}) = \{ \; \_ \; \}$.

Now, in order to compute all sets of contexts for all possible hole categories $H$, we set up a system of equations (as specified above). In general, this system of equations is recursive, and we use a fixpoint iteration to solve it, starting with the empty set $\empty$ for each set of contexts. There is a guaranteed minimal solution, because the RHSs are monotonic in $H'$.

\subsection{Pruning the trees within one set of test cases} 
On the scope of our tiny example grammar, this pruning method is
easiest to illustrate when we test a category instead of a function;
however, in bigger grammars, the need arises when testing functions as
well. 
In order to test the category \t{AP}, we need in total 12 example sentences:
\begin{itemize}
\setlength\itemsep{0em}
\item[--] 4 test cases for a premodifier \t{AP} as modifier;
\item[--] 4 test cases for a postmodifier \t{AP} as modifier;
\item[--] 4 test cases for \emph{any} \t{AP} as predicative.
\end{itemize}
These categories correspond to the concrete categories \quality{pre},
\quality{post} and the coercion \quality{*} (as explained in
Section~\ref{sec:Coercions}). Instead of generating redundant test
cases for the predicative, we use the coercions in the grammar to
detect when something is redundant.

So how do coercions help us pruning? Here's the algorithm:

We generate test cases and contexts for them, as usual.
For instance, we have tested \t{AdjCN}, and we get the following:

\begin{verbatim}
(AdjCN : AdjPre  -> CNFem -> CNFem, [Attributive, Predicative])
(AdjCN : AdjPost -> CNFem -> CNFem, [Attributive, Predicative])
(AdjCN : AdjPre  -> CNMasc -> CNMasc, [Attributive, Predicative])
(AdjCN : AdjPost -> CNMasc -> CNMasc, [Attributive, Predicative])

Table XXX
\end{verbatim}

In addition, we look into the coercions in the grammar, and keep those
that coerce at least 2 of the concrete categories in our list. (That
is, CNFem and CNMasc).

\begin{verbatim}
Coercion_999 -> [CNFem,CNMasc]
\end{verbatim}

Now we find the list of contexts for the \emph{coercion}: e.g.

\begin{verbatim}
(Coercion_999, [Predicative,SomethingIrrelevant,EvenMoreIrrelevant])
\end{verbatim}

Out of these contexts, we keep those that are somewhere in the list of
the contexts for \t{AdjCN}. There is one context that matches, namely
\t{Predicative}. Now we have got our pruning candidates:

\begin{verbatim}
(Coercion\_999, [CNFem,CNMasc], [Predicative])
\end{verbatim}

i.e. ``Coercion 999 covers the categories CNFem and CNMasc, in the
context Predicative''. This means that it is redundant to include
Predicative for \emph{all} the test cases in Table XXX. But on the
other hand, the context Attributive never appears in the contexts for
Coercion 999, thus we know that it is important to repeat it for all
the items in Table XXX.

We linearise the following sentences:

\begin{verbatim}
Attributive (AdjCN : AdjPre  -> CNFem -> CNFem)
Attributive (AdjCN : AdjPost -> CNFem -> CNFem)
Attributive (AdjCN : AdjPre  -> CNMasc -> CNMasc)
Attributive (AdjCN : AdjPost -> CNMasc -> CNMasc)
Predicative (<Pick any of the following trees!>)

Table YYY
\end{verbatim}

Sometimes it happens that one test case only has contexts that other
trees could as well fill. Then it may happen that the test case is
never even shown to the user. Consider the following initial table:

\begin{verbatim}
(Foo : X1 -> Y2 -> Z3, [1,2,3])
(Foo : X4 -> Y5 -> Z6, [1,2])

Table ZZZ
\end{verbatim}

with coercions \t{(Coercion\_999, [Z3,Z6], [1,2])}. In this case, two
things happen:
\begin{itemize}
\item Z6's contexts are fully contained in Z3's,\emph{and} 
\item Z3 and Z6 coerce to the same category Coercion\_999.
\end{itemize}
This is why we can safely ignore all of the test case \t{Foo : X4 ->
  Y5 -> Z6} and only use \t{Foo : X1 -> Y2 -> Z3}.

\subsection{Pruning the trees to test the whole grammar}
\label{sec:pruning_all}
So far we have completely ignored that one tree can showcase more
than one function. In fact, the 8 test sentences created for \t{Mod}
happen to also test \t{Pred} exhaustively.
Let us recap the steps we took to create them for \t{Mod}:
enumerating arguments brought us \t{Good}, \t{Vegan}, \t{Pizza} and
\t{Wine}, and enumerating contexts brought us \t{This} and
\t{These}. Had we been creating test cases for \t{Pred}, we would've
gotten \t{This} and \t{These} at the stage of enumerating arguments,
and then there would've been no need for contexts, because \t{Pred}
already creates the start category \t{S}.

There is a simple way to detect the redundancy: make the generation of
arguments completely deterministic, e.g. always choose the function
that is alphabetically first. The downside is that we get a lot of
redundancy, in the style of ``the good pizza is good''. The problem
gets more severe when testing functions with more arguments: ``the
pizza gives the pizza the pizza'' is not only boring but confusing.
However, if we want to generate sentences for the whole grammar at one 
go, we can split the generation in two stages: first stage is
deterministic, where every feminine noun is \t{Pizza}, and we can 
eliminate redundancies by just eliminating copies of the same
tree. Then, when we have a set of unique trees, we can substitute
individual words in them with other words in the same concrete
category.
A sentence such as ``the house gives the pizza the fountain'' tests
the same properties as the version with pizza in every role, but at
least it is easier to keep track who does what, and compare the
translations of the same tree. 

It would be ideal to generate sentences that make sense,
such as ``the waitress gives the girl the pizza''. If the grammar is
purely syntactic, we would need external tools to ensure semantic
coherence, but if the grammatical categories already include semantic
distinctions, e.g. limiting the subject and indirect object of
\emph{give} into humans, that naturally restricts the generated test
suite.

\section{General features of \pmcfg: unused, equal,
  erased or empty fields}

Aside from concrete language-dependent phenomena, there are more
general, engineering questions a grammar writer may ask. For instance, say that our
concrete type for a \t{CN} in Dutch is an inflection table from case
to string, we would like to know if (a) a given string field is unreachable from the start category; (b) any two fields always contain the same string; or (c) some fields
are always the empty string. A yes answer to any of these may indicate a bug in the grammar.

In Dutch, nominative and accusative are only different for
pronouns, so for this grammar we would indeed find out that case is
redundant: all nominative and accusative fields would be
identical. As grammarians, we could decide to keep the distinction for
further extension of the grammar---maybe we want to add pronouns in
the future---or remove it as redundant.

\gf{} has the expressivity of \pmcfg{}, which means that it is
possible to erase arguments: say that there is a bug, \t{AdjCN : Adj
  $\rightarrow$ CN  $\rightarrow$ CN} never actually adds the
adjective to the new \t{CN}, in which case \t{AdjCN blue house} and
\t{house} are linearised identically. Instead of testing every single
function, we would like to know if there are any functions in the
grammar that behave like this.

The analyses mentioned in this section are implemented in a similar way to the method for enumerating all contexts.

\section{Use cases}

Here is a typical use for the tool. 
Let us take the noun phrase grammar for Dutch, and pick a single function,
say \t{AdvCN}. We generate test cases, which include the following
trees: 
\begin{itemize}
\item \t{AdvCN (PrepNP next\_to (DetNP your)) hill} `hill next to
yours'
\item \t{AdvCN (PrepNP next\_to (DetNP your)) house} `house next
to yours'
\end{itemize}
In Dutch, the words \emph{hill} and \emph{house} have different
genders, and the word \emph{yours} has to agree in gender 
with the antecedent: \emph{(de) heuvel naast de jouwe} and \emph{(het)
  huis naast het jouwe}. The test cases reveal a bug, where \t{DetNP your} 
picks a gender too soon, instead of leaving it open in an inflection
table. We implement a fix by adding gender as a parameter to the
\t{Adv} type, and have \t{AdvCN} choose the correct form based on the gender of the \t{CN}. 

After implementing the fix, we run a second test case generation: this
time, not meant for human eyes, but just to compare the old and new
versions of the grammar. We want to make sure that our changes 
to \t{Adv}, \t{AdvCN} and \t{DetNP} 
have not caused new bugs in other categories and functions. The
simplest strategy is to generate test cases for \emph{all} functions
in both grammars, and only show those outputs that differ between the
grammars. After our changes, we get the following differences: 

\begin{itemize}
\item \t{DetCN the (AdvCN (PrepNP next\_to (DetNP your)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel naast {\bf  het} jouwe}}
   \item \emph{de heuvel naast {\bf  de} jouwe}
  \end{itemize}
\item \t{DetCN the (AdvCN (PrepNP without (DetNP this)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel zonder {\bf  dit}}}
   \item \emph{de heuvel zonder {\bf  deze}}
  \end{itemize}
\end{itemize}

\noindent We notice a side effect that we may not have thought of: the
gender is retained in all adverbs made of NPs made of determiners, so
now it has become impossible to say ``the hill without \emph{that}'' and
pointing to a house. So we do another round of modifications, compute
the difference (to the original grammar or to the intermediate), and
see if something else has changed.

\section{Evaluation}

\begin{table}[h]
\centering
\begin{tabular}{|lll|ll|ll|ll|}
\hline
\multicolumn{3}{|r}{Concrete grammar $\rightarrow$}              &
                                                                   \multicolumn{2}{|c}{\bf Dutch} & \multicolumn{2}{|c}{\bf Basque} & \multicolumn{2}{|c|}{\bf Estonian} \\
$\downarrow$ Abstract grammar & \#funs+lex & \#trees  &
                                                                 \#total & \#uniq & \#total & \#uniq  & \#total  & \#uniq \\ \hline
{\bf Noun phrases}     & \numOfFun{}+\numOfLex{}        & \textgreater{}10,000          & 21    & 18     & 33      & 27      & 40       & 36     \\ \hline
{\bf Phrasebook}       
                  & 130+160   & \textgreater{}480,000       
   & 513     & 419    & 610     & 505     & 538      & 503   \\ \hline
   {\bf Resource gr.}    & 217+446   & \textgreater{}500 billion  
   & 21,370  & 19,825 &  13,733  & 9,194    & TODO  & TODO \\ \hline
\end{tabular}
\caption{Test cases for all functions in three grammars}
\label{results}
\end{table}


\begin{table}[h]

\centering
\begin{tabular}{|l|l|l|l|}
\hline
{\bf Resource grammar function} & {\bf Dutch}
   & {\bf Estonian} & {\bf Basque} \\ \hline
 
\t{ComparA} `younger than me'  & 10   & 20 & 6   \\
%\t{ComplVS} `say that I sleep' & 89   & 171 & b   \\
\t{RelNP~~} `a cat that I saw' & 2    & 23 & 20   \\
\t{ReflVP~} `see myself'       & 1034 & 343 & b   \\
\hline
\end{tabular}
\caption{Test cases for some individual functions in the resource grammar}
\label{results_indiv}
\end{table}

In order to evaluate our method, we generate test cases for grammars
of varying sizes, using the four languages presented earlier: Dutch, Spanish,
Estonian and Basque. These languages come from different language
families, and cover a wide range of grammatical complexity. Dutch and
Spanish are both Indo-European languages, with fairly simple nominal
morphology. Dutch features word order changes in subordinate and
question clauses, and separable prefixes in verb phrases (imagine
English behaving ``look somethig \emph{up} \~ \emph{up}looked''). 
Spanish has a large number of tenses and moods, and clitics for direct
and indirect objects, which attach to verbs.  To add some linguistic
variety, we include Estonian from the Finno-Ugric language family, and
Basque, an isolate language.  In contrast to Dutch and Spanish,
Estonian and Basque have a rich nominal morphology, with 14
grammatical cases in each. In addition, Basque has the most complex
verb morphology out of all the 4 languages, featuring agreement in
subject, object and indirect object.

\todo{add Spanish. Contrary to our expectations, we found
Dutch and Estonian behaving similarly to each other and Basque
significantly worse, both in execution time and examples generated.}

Table~\ref{results} shows the number of generated trees for 
in total for all syntactic functions in the three grammars, and
Table~\ref{results_indiv} shows some example functions from the resource grammar. 
As stated earlier, we do not consider generating test cases for all
functions an optimal way of testing a whole resource grammar from scratch;
this gives merely a baseline reduction from all possible trees up to a
reasonable depth. We introduce the grammars and comment on the results
in the following sections. 

\subsection{Grammars}

The first grammar is the toy example introduced earlier in this
article: NounPhrases with \numOfFun syntactic functions and \numOfLex words in the
lexicon. We wrote the concrete syntaxes from scratch for each of the
languages, instead of using the full resource grammar and reducing it
to only noun phrases. All three concrete syntaxes were completed
in less than an hour, by an experienced grammarian with knowledge in
all three languages.

The second grammar is a mid-size application grammar: Phrasebook
\cite{ranta2010phrasebook}, with 42 categories such as \t{Person,
  Currency, Price} and \t{Nationality}, 160-word lexicon and 130
functions with arguments. As opposed to the trees that we have seen so far,
which only contain syntactic information, the trees in the Phrasebook
are much more semantic: for example, the abstract tree for the
sentence ``how far is the bar?'' in the Phrasebook is \t{PQuestion
  (HowFar (ThePlace Bar))}, in contrast to the resource grammar tree
{\tt \small UttQS (UseQCl (TTAnt TPres ASimul) PPos (QuestIComp
  (CompIAdv (AdvIAdv how\_IAdv (PositAdvAdj far\_A))) 
  (DetCN (DetQuant DefArt NumSg) (UseN bar\_N))))} for the same
sentence. Limiting up to depth 3, the Phrasebook grammar produces over
480,000 trees\footnote{Application grammars are usually
much more compact than resource grammars, hence depth 3 covers already
a lot of relevant trees.}.

%  All three concrete syntaxes were
% implemented using their respective resource grammars; thus if some
% Phrasebook function has a bug, say it produces ``Spaniard restaurant''
% instead of ``Spanish restaurant'', the problem could be in either grammar.
% In the first case, the resource grammar contains both \t{spanish\_A} ``Spanish'' and
% \t{spaniard\_N} ``Spaniard'', but the application grammarian has
% chosen the wrong function.
% In the second case, the application grammarian has correctly chosen
% \t{spanish\_A} from the resource grammar, but that word itself is
% linearised wrongly into ``Spaniard''.


The third grammar is a restricted version of the \gf{} resource grammar,
with 84 categories, 217 syntactic functions and 446 words in the
lexicon. Since all the languages did not have a complete
implementation, we simply took the subset of functions that was
common, and removed manually a couple of rare constructions and words
that are potentially distracting. However, we should not limit the
lexicon too much, because we may miss important distinctions 
in some languages---to give a hypothetical example, some grammar may
have a bug that shows up only in animate nouns which end in a
consonant. This subset of the resource grammar produces hundreds of
billions of trees up to depth 5. 
%: say, animate and inanimate nouns, ending in front vowel and back vowel.

\subsection{Execution time} We ran all the experiments on a MacBook Air
with 1,7 GHz processor and 8 GB RAM. For Phrasebook, it took just
seconds to generate the test suite for all languages. For the resource
grammar, Dutch and Estonian finished in 3--4 minutes. However, the
Basque resource grammar is noticeably more complex, and creating test
trees for all functions took several hours. We ran the experiment in
smaller batches over two days, and noticed a lot of variance:
functions that handle e.g. noun phrases, adjectives and adverbs ran in
a few minutes, but a function involving verb phrases could take an
hour just by itself.

\subsection{Generated trees}

We report both total and unique trees: total trees are simply the sum
of all trees for all functions, and unique trees is the count after
removing duplicates, as explained in Section~\ref{sec:pruning_all}.

As we can see, the number of trees differs a lot. We believe this has
both language typological and grammar engineering reasons---there
is no way to implement Basque in a way that results in as few example
sentences as English, but other resource grammarians have reported
significant differences in complexity between implementations: Enache
et al. \cite{enache2010} report a 200-time reduction in the number of
concrete rules after changing the implementation of clitics in verb
phrases.

We experimented with the noun phrase grammar for
Basque. In one of them, we implemented nominal morphology using
inflection tables, and syntactic functions choose the correct one.
In another grammar, we implemented nouns as stems, and syntactic
functions concatenate suffixes to the stems. The second approach
required inherent parameters for nouns, in order to add correct
suffixes to each noun. For test case generation, this had the added
benefit or curse of implicitly testing morphology as well---in the first
approach, there may be a concrete category for animacy or gender, but
in the second one, also for phonological features. 

\begin{table}[h]

\centering
\begin{tabular}{| l | l | l |}
\hline
{\bf Function} & {\bf Inflection table}
   & {\bf Concatenate suffixes to stems} \\ \hline
 
\t{UttNP}    & TODO & TODO  \\
\t{PredAdj}  & TODO & TODO  \\
\t{PredAdv}  & TODO & TODO    \\
\t{DetNP}    & TODO & TODO   \\
\t{DetCN}    & TODO & TODO   \\
\t{PrepNP}   & TODO & TODO   \\
\t{AdjCN}    & TODO & TODO   \\
\t{AdvCN}    & TODO & TODO   \\ \hline
{\bf Total:} & & \\ 
\hline
\end{tabular}
\caption{Two versions of Basque concrete syntax for noun phrase grammar}
\label{basque_versions}
\end{table}


\subsection{Qualitative analysis} 

We read through the test sentences of the small grammar in all the
four languages. 
For Dutch we had a native speaker; for Estonian and Spanish an
intermediate non-native, and for Basque, a beginner. None of the
\todo{four? is Spanish tested?}
grammars had been tested systematically before---for the Estonian grammar
\cite{listenmaa_kaljurand2014}, the morphological paradigms had been
tested extensively against existing resources, but syntactic functions
were only tested with a treebank of 425 trees.

We read through all the 1314 sentences from Estonian Phrasebook,
which took around 45 minutes (not including the time to fix the bugs).
We found 4 errors in the inflection of individual words---they did not
come from the resource lexicon, which was tested in
\cite{listenmaa_kaljurand2014}, but were implemented separately in the
grammar. In addition, we found one error in forming compound words,
also coming from the Phrasebook grammar and not from the resource
library. There was one bug in a syntactic function: using a wrong form
of nationality when applied to a human and when to an institution,
along the lines of ``Spaniard restaurant''. As expected, Phrasebook
sentences were easier to read, and made more sense semantically than
sentences from the resource grammar. For a similarly sized grammar,
reading through the whole test set at one go seems like a feasible
strategy, even when the tool creates examples for a single function at
a time.


We have been developing the tool by testing it on the Dutch resource
grammar, and during 6 months, we have committed 22 bugfixes on Dutch
in the \gf{} main repository. (In the name of honesty, a few of the bugs were
caused by our earlier ``fixes''---that was before we had implemented
the comparison against an older version of the grammar!) In addition,
one of the bugs found in Dutch was also present in other languages, so
we fixed it in German and English.

The Basque resource grammar is still a work in progress, and the
test sentences showed serious problems in morphology.
We thought it premature to get a fluent speaker to evaluate the grammar,
because the errors in morphology would probably make it
difficult to assess syntax separately. We think that the best course
of action is to evaluate the morphological paradigms against existing
resources, fix the implementation, and then concentrate on syntax.
The Phrasebook was implemented using the resource grammar, so the
same problems apply.





\section{Conclusion and future work}

We have presented method for automatically generating minimal and exhaustive sets of test cases for testing grammars.  We have found the tool useful in large-scale grammar writing, in a context where grammars need to be \emph{reliable}.

One problem
we have encountered is that the test sentences from resource grammars are often
nonsensical semantically, and hence a native speaker might intuitively
say that a sentence is wrong, even though it is just unnatural. 
For instance, the function \t{AdvQVP} covers constructions such as ``you
did \emph{what}?''. However, the function itself is completely general
and can take any verb phrase and any question adverb, thus  bizarre
combinations like ``you saw the dog why'' may appear in the generated
test cases. For future work, we plan to use an external treebank to
guide the algorithm to pick trees that also make sense semantically.

So far the only mode of operation is generating test cases for a
single function. 
% Generating test cases to all trees often leads to redundant
% trees---as we noted in Section~\ref{sec:wishlist_comments}, the trees
% that are needed to test \t{AdjCN} in Estonian are exactly the same
% trees we need to test \t{PrepNP}, even though the functions are
% seemingly separate. 
As future work, we are planning to add a separate
mode for testing the whole grammar from scratch: intentionally create
trees that test several functions at once.
We have an implementation only for \gf{} grammars so far, but the
general method works for any grammar formalism that can be compiled
into \pmcfg{}. \gf{} already supports reading context-free grammars,
so testing any existing \cfg{} is a matter of some preprocessing. 
