\chapter{Test Case Generation for Grammatical Framework}
\label{chapterGFtest}

Traditionally, GF grammars are tested by the grammarians themselves,
much like unit testing. When implementing some feature, such as 
relative clauses, the grammarian comes up with a test suite of 
sentences that include relative clauses, and stores in the form of 
abstract syntax trees. In principle, a test suite created for one 
language can easily be reused for another, because the ASTs are 
identical. Ideally, every time someone touches relative clauses 
in the any concrete syntax, the trees in the test suite will be 
linearised with the changed concrete syntax, and verified by someone
who speaks the language (or compared to the original gold standard, 
if there is one). This scheme can fail for various reasons: 

\begin{itemize}
\item The original list is not exhaustive: for instance, it tests only
``X, who loves me'' but not ``X, whom I love''. 
\item The original list is exhaustive in one language, but not in all:
for instance, it started in English and only included one noun, but in
French it would need at least one masculine and one feminine noun. 
\item The list is overly long, with redundant test cases, and human
testers are not motivated to read through. 
\item A grammarian makes a change somewhere else in the grammar, and
does not realize that it affects relative clauses, and thus does not
rerun the appropriate test suite. 
\end{itemize}


\section{Technical details}

GF grammar compiles into a low-level format called PGF. After the
compilation, we get one category for each combination of parameters:
for English adjectives, \texttt{A => A$_{pos}$, A$_{comp}$,
A$_{superl}$}, and for Spanish, \texttt{A => A$_{pos×sg×masc}$, \dots,
A$_{superl×pl×fem}$}. 

Suddenly, we have a bunch of new types, and those are different for
each concrete syntax! The original question ``we need a sample of
nouns/verbs/… that makes sense''”'' can be simplified ``we need one
noun/verb/… of each type''. The types are determined by the parameters
in the concrete syntax. 

So remember all the hassle when you can't pattern match strings to
know something, but instead you have to define a parameter? This is
actually a nice side effect from that: each parameter contributes to a
new category, so it pays off in generating examples. If the feature is
important for your grammar---say that in language A, negation is
simply attaching the word  ``no'' before the verb, and in language B,
negation changes the word order and the object case. Then in the GF
grammar for language B, we would need a Boolean \texttt{isNeg} field
in the relevant categories, which we then pattern match against in
order to determine the relevant operations. That parameter in the
abstract category translates into different concrete categories, and
that way, when we generate example trees, we make sure to include one
of each. For instance, in language A, we could end up with the trees
``any horse'' and ``all horses'' when testing NPs, but in language B,
the set would also include ``no horses''. 

\section{Evaluation}


\begin{itemize}
\item Cost
  \begin{itemize}
  \item time of generating examples
  \item time of looking at examples
  \end{itemize}

\item Effect
  \begin{itemize}
  \item compare against other methods -- what methods?
  \item For application grammars, if you're writing them from scratch, it is actually pretty feasible to just gt the hell out of it as you write. But this doesn't work for bigger grammars.
  \item Morphology can be tested efficiently againts any existing morphological analyser. I've used Apertium for Dutch and Basque.
  \end{itemize}
\end{itemize}


\section{Future work}

We plan to look into existing text corpora, and find trees that are
structurally identical  to those that our program generates as a
minimal and representative example. As a simplified example, ``a worm
without winter'', generated by the program, would be identical\footnote{This particular example holds for English, but in another language, the words ``pizza'' and ``worm'', as well as ``winter'' and ``cheese'' may not match in all relevant features---grammatical gender, whether the word starts with a vowel or a consonant, etc. All this information comes from the concrete syntax!} 
in structure to ``a pizza without cheese'', found in a real text, and
can thus be substituted for the generated one.   
Alternatively, we could use statistical information on co-occurrences
of words, and generate appropriate pools of words, from which we draw
example sentences. 
