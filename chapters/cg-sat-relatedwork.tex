Our work is inspired by previous approaches of encoding \cg{} in logic \cite{lager98, lager_nivre01}.
Lager \cite{lager98} presents a ``\cg{}-like, shallow and reductionist system'' translated into a disjunctive logic program.
Lager and Nivre \cite{lager_nivre01} build on that in a study which reconstructs
four different formalisms in first-order logic. 
\cg{} is contrasted with Finite-State Intersection Grammar (\fsig{}) \cite{koskenniemi90} 
and Brill tagging \cite{brill1995}; all three work on a set of constraint rules 
which modify the initially ambiguous input, but with some crucial differences.
On a related note, Yli-Jyr√§ \cite{yli-jyra2001} explores the structural correspondence 
between \fsig{} and constraint-solving problems.
In addition, logic programming has been applied for automatically inducing \cg{} rules from tagged corpora \cite{lindberg_eineborg98ilp,asfrent14,lager01transformation}.

There has been previous research on corpus-based methods in manual grammar development \cite{voutilainen2004}, as well as optimisation of hand-written \cg{}s~\cite{bick2013tuning}.
In addition, there is a large body of research on automatically
inducing rules, e.g. \cite{inducing_cg1996,lindberg_eineborg98ilp,lager01transformation,asfrent14}.
However, since our work is aimed to aid the process of hand-crafting rules, we omit those works from our discussion.


\paragraph{Corpus-based methods in manual grammar development}

Hand-annotated corpora are commonly used in the development of \cg{}s, because they give immediate feedback whether a new rule increases or decreases accuracy.
% This helps the grammar writer to arrange the rules in appropriate sections, with safest and most effective rules coming first.
% However, this method will not notice a missed opportunity or a grammar-internal conflict, nor suggest ways to improve.
Atro Voutilainen \cite{voutilainen2004} gives a detailed account about best practices of grammar writing and efficient use of corpora to aid the grammar development.
For a language with no free or tagset-compatible corpus available, Reynolds and Tyers \cite{tyers_reynolds2015} describe a method where they apply their rules to unannotated Wikipedia texts and pick 100 examples at random for manual check.

\cg{} rules are usually arranged in sections, and run in the following manner. 
First apply rules from section 1, and repeat until nothing changes in the text. Then apply rules from sections 1--2, then 1--3 and so on, until the set includes all rules.
The best strategy is to place the safest and most effective rules in the first sections,
so that they make way for the following, more heuristic and less safe rules to act on.
A representative corpus is arguably the best way to get concrete numbers---how many times a rule applied and how often it was correct---and to arrange the rules in sections based on that feedback.

Voutilainen \cite{voutilainen2004} states that the around 200 rules are probably enough to resolve 50--75 \% of ambiguities in the corpus used in the development. 
This figure is very much thanks to Zipf's law: we can add rules that target the most frequent \emph{tokens}, thus disambiguating a high number of word forms.
However, this method will not notice a missed opportunity or a grammar-internal conflict, nor suggest ways to improve; neither does it guarantee a coherent whole of rules. 
While the coverage information is easy to obtain from a corpus, there is no tool that would aid grammar writers in including wide coverage of different linguistic phenomena.


\paragraph{Automatic optimisation of hand-written grammars }

The corpus-based method can tell the effect of each single rule at their place in the rule sequence, and leaves the grammar writer to make changes in the grammar.
As a step further, Eckhard Bick \cite{bick2013tuning} modifies the grammar automatically, by trying
out different rule orders and altering the contexts of the rules. 
Bick reports error reduction of 7--15\% compared to the original grammars.
This is a valuable tool, especially for grammars that are so big that it's hard to keep track manually. A program can try all combinations whereas trying to make sense out of a huge set of rules would be hard for humans.
As a downside, the grammar writer will likely not know why exactly does the tuned grammar perform better.
%Previous work includes Inductive Logic Programming to learn \cg{} rules from a tagged corpus
% uses a Prolog-based system for transformation-based learning of \cg{} rules. 

