\section{Software testing and verification}
\label{sec:testing-intro} 

\todo{This whole section is just a draft.}

\begin{itemize}
\item All software has bugs.
\item Grammars are software.
\end{itemize}

The intelligent reader may complete the syllogism.

We can approach the elimination of bugs in two ways: reveal them
by constructing tests, or build safeguards into the program that
make it more difficult for bugs to occur in the first place. The
latter approach is more of a concern for developers of new programming
languages---the language can impose more checks and constraints on the
programmer, and thus make it harder to write buggy code. However, we
approach the problem from particular, existing grammar formalisms that
already have millions of lines of code written in them. Thus, we want
to develop methods that help finding bugs in existing software.

% \subsection{Purpose of testing}

% Ammann and Offutt \todo{cite \url{http://assets.cambridge.org/97811071/72012/excerpt/9781107172012_excerpt.pdf}}
% define different levels of enlightment for software engineers.

% \begin{quote}
% Level 0:  There is no difference between testing and debugging. \\
% Level 1: The purpose of testing is to show correctness. \\
% Level 2: The purpose of testing is to show that the software does not work. \\
% Level 3: The purpose of testing is not to prove anything specific, but to reduce the risk of using the software. \\
% Level 4: Testing is a mental discipline that helps all IT professionals develop higher-quality software.
% \end{quote}

% \subsection{Testing}

% More quotes from the Intro to Software testing book:

% \begin{quote}
% Testing: Evaluating software by observing its execution \\
% Test Failure: Execution of a test that results in a software failure \\
% Debugging: The process of finding a fault given a failure \\
% \\
% Not all inputs will “trigger” a fault into causing a failure
% \\
% \\
% Reachability :The location or locations in the program that contain the fault must be reached \\
% Infection :The state of the program must be incorrect \\
% Propagation :The infected state must cause some output or  final state of the program to be incorrect \\
% Reveal :The tester must observe part of the incorrect portion of the program state \\
% \end{quote}

% http://twiki.di.uminho.pt/twiki/pub/Research/CROSS/Publications/techReport-ATGsurvey.pdf

Testing a software involves a \emph{system} to test, an \emph{input}
and an \emph{expected output}. We run the system with the given
input, and compare \emph{actual output} to expected output.

Some examples different types of tests:

\paragraph{Unit testing}

Unit tests are particular, concrete test cases: assume we want to test the
addition function (+), we could write some facts we know, such as
``1+2 should be 3''. In the context of grammars and natural language,
we could assert translation equivalence between a pair of strings,
e.g. ``\emph{la casa grande} $\Leftrightarrow$ \emph{the big house}'',
or between a tree and its linearisation, e.g. ``\t{DetCN the\_Det
  (AdjCN  big\_A house\_N)} $\Leftrightarrow$ \emph{the big house}''.
Whenever a program is changed or updated, the collection of unit tests
are run again, to make sure that the change has not broken something
that previously worked.

\paragraph{Property-based testing}

The weakness of unit testing is that it only tests concrete values
that the developer has thought of adding. Another approach is to use
property-based testing: the developer defines abstract properties that
should hold for all test cases, and uses random generation to supply
values. If we want to test the (+) function again, we could write a
property that says ``for all integers $x$ and $y$, $x+y$ should be
equal to $y+x$''.  A grammar-related property could be, for instance,
``a linearisation of a tree must contain strings from all of its
subtrees''.  We formulate these properties, and generate a large
number of data---pairs of integers in the first case, syntax trees in
the second---and assert that the property holds for all of them.

% Of course, the single property of commutativity is not enough to
% define that (+) works as intended: if that were the only test, it
% would happily pass any function with similar property,
% e.g. multiplication, or some function $f(x, y) = 0$ for any $x$ and
% $y$. Likewise, some components in a syntax tree may not contribute
% with a string, but only a parameter to choose the right inflection
% form from another subtree.
%  To remedy this, we would need to test other
% properties of addition, or mix in some unit tests with specific
% values.


\paragraph{Deriving test cases}

Unit tests, as well as properties, can be written by a human or
derived automatically from some representation of the program. The
sources of tests can range from informal descriptions, such as
specifications or user stories, to individual statements in the source
code. Alternatively, tests can be generated from an abstract model of
the program, such as a UML diagram.

In the context of grammar testing, the specification is the whole
language of the grammar---hardly a formal and agreed-upon
document. Assuming no access to the computational grammar itself
(sometimes called \emph{black-box testing}), we could treat
traditional grammar books as an inspiration for properties and unit
tests. For example, we can test a feature such as ``pronouns must be
in an accusative case after a preposition'' by generating example
sentences where pronouns occur after a preposition, and reading
through them to see if the property holds.

If we have access to the grammar while designing tests
(\emph{white-box testing}), we can take advantage of the
structure---to start with, only test those features that are
implemented in the grammar. Another example is, if we know that
e.g. word order is a parameter with 3 values (statement, question and
indirect question), we must create a test for each of parameters: ``I am
old''; ``am I old''; ``I don't know if I am old''.

% We can name
% three levels of abstraction where to generate tests. \emph{Black-box
%   testing} relies on external descriptions of the software, without
% access to the source code. A tester would not care how the program
% produces the intended output, just that its output is correct. In
% contrast, \emph{white-box testing} has access to the source code, and
% can exploit concrete details of the program, such as individual
% conditions and statements. Finally, \emph{model-based testing} derives
% tests from some model of a program, such as a UML diagram.



\paragraph{Coverage criteria}

Beizer \cite{beizer2003software} says: ``Testing is simple---all a
tester needs to do is find a graph and cover it''.

When have we tested enough? We need structured ways of covering the input
space.

We are testing a grammar, which is necessarily an imperfect
approximation of the language it is based on. Thus, even if the
grammar generates an infinite amount of sentences, we still have only
a finite set of constructions and grammatical functions to cover.

\paragraph{Symbolic evaluation}

There are lots of things that can happen during the run of a
program. What happens if we get a 3 from the user as an input? Does
the system crash crash if it is 29th of February and we get a 3 from
the user?  Symbolic evaluation simulates the run of a program with
different inputs, using a constraint solver to find out where certain
combinations lead into.


\input{chapters/sat-intro}
