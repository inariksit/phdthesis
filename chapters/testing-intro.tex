\section{Software testing and verification}
\label{sec:testing-intro}

% \begin{itemize}
% \item All software has bugs.
% \item Grammars are software.
% \end{itemize}
%
% \noindent The intelligent reader may complete the syllogism.

We can approach the elimination of bugs in two ways: reveal them
by constructing tests, or build safeguards into the program that
make it more difficult for bugs to occur in the first place.
In this thesis, we concentrate on the first aspect: our starting point is two particular grammar
formalisms that already have millions of lines of code written in them.
Rather than change the design of the programming languages, we want to develop methods that help finding bugs in existing software.
In the present section, we introduce some key concepts from
the field of software testing, as well as their applications to grammar
testing.

%\todo{return to this possibly}
% The latter approach is more of a concern for developers of new programming
% languages---the language can impose more checks and constraints on the
% programmer, and thus make it harder to write buggy code. The two
% formalisms in this thesis fall in the opposite ends of the spectrum:
% GF has a very expressive type system,



% \subsection{Purpose of testing}

% Ammann and Offutt \todo{cite \url{http://assets.cambridge.org/97811071/72012/excerpt/9781107172012_excerpt.pdf}}
% define different levels of enlightment for software engineers.

% \begin{quote}
% Level 0:  There is no difference between testing and debugging. \\
% Level 1: The purpose of testing is to show correctness. \\
% Level 2: The purpose of testing is to show that the software does not work. \\
% Level 3: The purpose of testing is not to prove anything specific, but to reduce the risk of using the software. \\
% Level 4: Testing is a mental discipline that helps all IT professionals develop higher-quality software.
% \end{quote}

% \subsection{Testing}

% More quotes from the Intro to Software testing book:

% \begin{quote}
% Testing: Evaluating software by observing its execution \\
% Test Failure: Execution of a test that results in a software failure \\
% Debugging: The process of finding a fault given a failure \\
% \\
% Not all inputs will “trigger” a fault into causing a failure
% \\
% \\
% Reachability :The location or locations in the program that contain the fault must be reached \\
% Infection :The state of the program must be incorrect \\
% Propagation :The infected state must cause some output or  final state of the program to be incorrect \\
% Reveal :The tester must observe part of the incorrect portion of the program state \\
% \end{quote}

% http://twiki.di.uminho.pt/twiki/pub/Research/CROSS/Publications/techReport-ATGsurvey.pdf



\paragraph{Unit testing}

Unit tests are particular, concrete test cases: assume we want to test the
addition function (+), we could write some facts we know, such as
``1+2 should be 3''. In the context of grammars and natural language,
we could assert translation equivalence between a pair of strings,
e.g. ``\emph{la casa grande}'' $\Leftrightarrow$ ``\emph{the big house}'',
or between a tree and its linearisation, e.g. ``\t{DetCN the\_Det
  (AdjCN  big\_A house\_N)} $\Leftrightarrow$ \emph{the big house}''.
Whenever a program is changed or updated, the collection of unit tests
are run again, to make sure that the change has not broken something
that previously worked.

\paragraph{Property-based testing}

The weakness of unit testing is that it only tests concrete values
that the developer has thought of adding. Another approach is to use
property-based testing: the developer defines abstract properties that
should hold for all test cases, and uses random generation to supply
values. If we want to test the (+) function again, we could write a
property that says ``for all integers $x$ and $y$, $x+y$ should be
equal to $y+x$''.  A grammar-related property could be, for instance,
``a linearisation of a tree must contain strings from all of its
subtrees''.  We formulate these properties, and generate a large
amount of test data---pairs of integers in the first case, syntax trees in
the second---and assert that the property holds for all of them.

\paragraph{Model-based testing}
The programs we test are often large and complex, and their main logic is hard to
separate from less central components, such as graphical user interface, or
code dealing with input and output. In order to make testing easier, we can introduce
a \emph{model} of the real system, which we use to devise tests. To give a concrete
example, suppose we want to test a goal-line system: a program that checks whether
a goal has been scored or not, in a game such as football. The real program includes
complex components such as cameras and motion sensors, but our model can abstract
away such details, and consider only the bare bones: the ball and the goal line.
For our model, we define possible \emph{states} for the ball and goal line: the
ball can be inside or outside the line, and the goal line may be idle or in action.
Furthermore, we define legal \emph{transitions} between the states: the ball starts
outside, can stay outside, or go inside, but once it has entered the goal, it must
get out before another goal can be scored.

With such a model in place, we can query another program, called \emph{model checker},
for possible outcomes in the model, or ask whether a particular outcome would be
possible. For our goal-line system, we would like to be assured that it is possible
to score a goal; on the other hand, when a ball has entered the goal, it is only
registered as one goal, not repeated goals every millisecond until the ball is
removed.

What do we gain from building such a model? We describe the (intended) behaviour
of the real program in the form of a simplified model, and ask for logical
conclusions---sometimes we discover that our original description wasn't quite
as waterproof as we wanted. Of course, we still need to execute tests for the
real system---the model (together with model checker) has only given us inspiration
what to test.

Philosophically speaking, grammars are models for language: what is a grammar rule
if not a human's best attempt to describe the behaviour of a complex system.
In Chapter~\ref{chapterCGana}, we will take essentially the approach of a model
checker: ``you claimed that \emph{X} happens, now let's try applying \emph{X}
in all possible contexts''.

\paragraph{Deriving test cases}

Unit tests, as well as properties, can be written by a human or
derived automatically from some representation of the program. The
sources of tests can range from informal descriptions, such as
specifications or user stories, to individual statements in the source
code. Alternatively, tests can be generated from an abstract model of
the program, as previously explained.

In the context of grammar testing, the specification is the whole
natural language that the grammar approximates---hardly a formal and
agreed-upon document. Assuming no access to the computational grammar
itself (generally called \emph{black-box testing}), we can treat traditional
grammar books or speaker intuition as an inspiration for properties
and unit tests. For example, we can test a feature such as ``pronouns
must be in an accusative case after a preposition'' by generating
example sentences where pronouns occur after a preposition, and
reading through them to see if the rule holds.

If we have access to the grammar while designing tests
(\emph{white-box testing}), we can take advantage of the
structure---to start with, only test those features that are
implemented in the grammar. For example, if we know that word order is
a parameter with 2 values, direct statement and question,
then we need to create 2 tests, e.g. ``I am old'' and ``am I
old''. If the parameter had 3 values, say third for indirect question,
then we need a third test as well, e.g. ``I don't know if I am old''.

% We can name
% three levels of abstraction where to generate tests. \emph{Black-box
%   testing} relies on external descriptions of the software, without
% access to the source code. A tester would not care how the program
% produces the intended output, just that its output is correct. In
% contrast, \emph{white-box testing} has access to the source code, and
% can exploit concrete details of the program, such as individual
% conditions and statements. Finally, \emph{model-based testing} derives
% tests from some model of a program, such as a UML diagram.


\paragraph{Coverage criteria}

\citet{beizer2003software} describes testing as a
simple task: ``all a tester needs to do is find a graph and cover
it''. The flow of an imperative program can be modelled as a graph
with start and end points; multiple branches at conditional statements
and back edges at loops. Take a simple program that takes a number and
outputs ``even'' for even numbers and ``odd'' for odd numbers. The domain of this program is, in theory, infinite, as there is an infinite number of integers. But in practice, the program only has two branches, one for even and one for odd numbers. Thus in order to test the program exhaustively, i.e. cover both paths, one needs to supply two inputs: one even and one odd number.

Simulating the run of the program with all feasible paths is called
\emph{symbolic evaluation}, and a constraint solver is often used to
find out where different inputs lead into. It is often not feasible to
simulate all paths for a large and complex program; instead, several
heuristics have been created for increasing code coverage.

Symbolic evaluation works well for analysing (ordered) \onlycg{} grammars, at
least up to an input space of tens of thousands of different
morphological analyses. The range of operations is fairly limited, and
the program flow is straightforward: execute rule 1, then execute
rule 2, and so on.

For \gf{} grammars, the notion of code coverage is based on individual
grammatical functions, rather than a program flow. We want to test
linearisation, not parsing, and thus our ``inputs'' are just syntax
trees.  We need to test all syntactic functions (e.g. putting an
adjective and a noun together), with all the words that make a
difference in the output (some adjectives come before the noun, others
come after). Thus, even if the grammar generates an infinite amount of
sentences, we still have only a finite set of constructions and
grammatical functions to cover.


\input{chapters/sat-intro}
