\section{Software testing and verification}
\label{sec:testing-intro} 

\begin{itemize}
\item All software has bugs.
\item Grammars are software.
\end{itemize}

\noindent The intelligent reader may complete the syllogism.

We can approach the elimination of bugs in two ways: reveal them
by constructing tests, or build safeguards into the program that
make it more difficult for bugs to occur in the first place. The
latter approach is more of a concern for developers of new programming
languages---the language can impose more checks and constraints on the
programmer, and thus make it harder to write buggy code. However, we
approach the problem from particular, existing grammar formalisms that
already have millions of lines of code written in them. Thus, we want
to develop methods that help finding bugs in existing software.
In the present section, we introduce some key concepts from the field of
software testing, as well as their applications to grammar testing.
% \subsection{Purpose of testing}

% Ammann and Offutt \todo{cite \url{http://assets.cambridge.org/97811071/72012/excerpt/9781107172012_excerpt.pdf}}
% define different levels of enlightment for software engineers.

% \begin{quote}
% Level 0:  There is no difference between testing and debugging. \\
% Level 1: The purpose of testing is to show correctness. \\
% Level 2: The purpose of testing is to show that the software does not work. \\
% Level 3: The purpose of testing is not to prove anything specific, but to reduce the risk of using the software. \\
% Level 4: Testing is a mental discipline that helps all IT professionals develop higher-quality software.
% \end{quote}

% \subsection{Testing}

% More quotes from the Intro to Software testing book:

% \begin{quote}
% Testing: Evaluating software by observing its execution \\
% Test Failure: Execution of a test that results in a software failure \\
% Debugging: The process of finding a fault given a failure \\
% \\
% Not all inputs will “trigger” a fault into causing a failure
% \\
% \\
% Reachability :The location or locations in the program that contain the fault must be reached \\
% Infection :The state of the program must be incorrect \\
% Propagation :The infected state must cause some output or  final state of the program to be incorrect \\
% Reveal :The tester must observe part of the incorrect portion of the program state \\
% \end{quote}

% http://twiki.di.uminho.pt/twiki/pub/Research/CROSS/Publications/techReport-ATGsurvey.pdf



\paragraph{Unit testing}

Unit tests are particular, concrete test cases: assume we want to test the
addition function (+), we could write some facts we know, such as
``1+2 should be 3''. In the context of grammars and natural language,
we could assert translation equivalence between a pair of strings,
e.g. ``\emph{la casa grande}'' $\Leftrightarrow$ ``\emph{the big house}'',
or between a tree and its linearisation, e.g. ``\t{DetCN the\_Det
  (AdjCN  big\_A house\_N)} $\Leftrightarrow$ \emph{the big house}''.
Whenever a program is changed or updated, the collection of unit tests
are run again, to make sure that the change has not broken something
that previously worked.

\paragraph{Property-based testing}

The weakness of unit testing is that it only tests concrete values
that the developer has thought of adding. Another approach is to use
property-based testing: the developer defines abstract properties that
should hold for all test cases, and uses random generation to supply
values. If we want to test the (+) function again, we could write a
property that says ``for all integers $x$ and $y$, $x+y$ should be
equal to $y+x$''.  A grammar-related property could be, for instance,
``a linearisation of a tree must contain strings from all of its
subtrees''.  We formulate these properties, and generate a large
amount of data---pairs of integers in the first case, syntax trees in
the second---and assert that the property holds for all of them.

% Of course, the single property of commutativity is not enough to
% define that (+) works as intended: if that were the only test, it
% would happily pass any function with similar property,
% e.g. multiplication, or some function $f(x, y) = 0$ for any $x$ and
% $y$. Likewise, some components in a syntax tree may not contribute
% with a string, but only a parameter to choose the right inflection
% form from another subtree.
%  To remedy this, we would need to test other
% properties of addition, or mix in some unit tests with specific
% values.


\paragraph{Deriving test cases}

Unit tests, as well as properties, can be written by a human or
derived automatically from some representation of the program. The
sources of tests can range from informal descriptions, such as
specifications or user stories, to individual statements in the source
code. Alternatively, tests can be generated from an abstract model of
the program, such as a UML diagram.

In the context of grammar testing, the specification is the whole
natural language that the grammar approximates---hardly a formal and
agreed-upon document. Assuming no access to the computational grammar
itself (generally called \emph{black-box testing}), we can treat traditional
grammar books or speaker intuition as an inspiration for properties
and unit tests. For example, we can test a feature such as ``pronouns
must be in an accusative case after a preposition'' by generating
example sentences where pronouns occur after a preposition, and
reading through them to see if the rule holds.

If we have access to the grammar while designing tests
(\emph{white-box testing}), we can take advantage of the
structure---to start with, only test those features that are
implemented in the grammar. For example, if we know that word order is
a parameter with 2 values, direct statement and question,
then we need to create 2 tests, e.g. ``I am old'' and ``am I
old''. If the parameter had 3 values, say third for indirect question,
then we need a third test as well, e.g. ``I don't know if I am old''.

% We can name
% three levels of abstraction where to generate tests. \emph{Black-box
%   testing} relies on external descriptions of the software, without
% access to the source code. A tester would not care how the program
% produces the intended output, just that its output is correct. In
% contrast, \emph{white-box testing} has access to the source code, and
% can exploit concrete details of the program, such as individual
% conditions and statements. Finally, \emph{model-based testing} derives
% tests from some model of a program, such as a UML diagram.


\paragraph{Coverage criteria}

\citet{beizer2003software} describes testing as a
simple task: ``all a tester needs to do is find a graph and cover
it''. The flow of an imperative program can be modelled as a graph
with start and end points; multiple branches at conditional statements
and back edges at loops. Take a simple program that takes a number and
outputs ``even'' for even numbers and ``odd'' for odd numbers; it has
two branches, and to test it exhaustively, one needs to supply two
inputs; one even and one odd number.

Simulating the run of the program with all feasible paths is called
\emph{symbolic evaluation}, and a constraint solver is often used to
find out where different inputs lead into. It is often not feasible to
simulate all paths for a large and complex program; instead, several
heuristics have been created for increasing code coverage.

Symbolic evaluation works well for analysing (ordered) \onlycg{} grammars, at
least up to an input space of tens of thousands of different
morphological analyses. The range of operations is fairly limited, and
the program flow is straightforward: execute rule 1, then execute
rule 2, and so on.

For \gf{} grammars, the notion of code coverage is based on individual
grammatical functions, rather than a program flow. We want to test
linearisation, not parsing, and thus our ``inputs'' are just syntax
trees.  We need to test all syntactic functions (e.g. putting an
adjective and a noun together), with all the words that make a
difference in the output (some adjectives come before the noun, others
come after). Thus, even if the grammar generates an infinite amount of
sentences, we still have only a finite set of constructions and
grammatical functions to cover.


\input{chapters/sat-intro}
