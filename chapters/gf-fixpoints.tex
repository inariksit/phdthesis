\section{Fixpoint computation}
\label{sec:moreFP}

We touched upon fixpoint computation in the section for enumerating
contexts. Here we explain the method with more focus, along with
other, more general and language-independent analyses we can perform
on a grammar. The reader uninterested in technical details may well
skip everything after Section~\ref{additional-analyses} and move on to
evaluation.

\subsection{Additional analyses}
\label{additional-analyses}

Aside from concrete language-dependent phenomena, there are more
general questions a grammar writer may ask. For instance, say that our
concrete type for \t{CN} in some language is an inflection table from
case to string, we would like to know if (a) a given string field is
unreachable from the start category; (b) any two fields always contain
the same string; or (c) some fields are always the empty string.  In
addition, a whole argument may be erased by some function: say that
\t{AdjCN~:~Adj~$\rightarrow$~CN~$\rightarrow$~CN} never adds the
adjective to the new \t{CN}, in which case \t{AdjCN blue house} and
\t{house} are linearised identically. Instead of testing every single
function and finding out by accident, we would like to know if there
are any functions in the grammar that behave like this.

% In Dutch, nominative and accusative are only different for
% pronouns, so for this grammar we would indeed find out that case is
% redundant: all nominative and accusative fields would be
% identical. As grammarians, we could decide to keep the distinction for
% further extension of the grammar---maybe we want to add pronouns in
% the future---or remove it as redundant.

The analyses mentioned in this section are implemented in a similar
way to the method for enumerating all contexts: using fixpoint
computation. We use the simpler cases as examples to explain the
method, and then move on to a detailed explanation of context
generation.

\subsection{Example I: empty concrete categories}

We start with an extremely simple analysis: detecting empty concrete
categories. A single \gf{} category compiles into multiple concrete
categories, one for each combination of parameters. We have
e.g. \t{Det$_{\text{sg}}$} and \t{Det$_{\text{pl}}$}, as well as
\t{NP$_{\text{sg}}$} and \t{NP$_{\text{pl}}$}. But if there are no
words of type \t{Det$_{\text{pl}}$} in the lexicon, then there won't
be any way to construct elements of type \t{NP$_{\text{pl}}$}
either. This way, we can compute if a category is empty, given that we
know if its argument categories are empty or not.

As a first step, we can see \gf{} categories as mutually recursive
datatypes. Take a fragment of the \gf{} grammar in Figure~\ref{fig:exampleGrammar}:

\begin{itemize}
\item[\t{\OtherTok{cat}}]
\begin{HighlightingFancy}[]
\DataTypeTok{Adv} \NormalTok{; }\DataTypeTok{CN} \NormalTok{; }\DataTypeTok{Det} \NormalTok{; }\DataTypeTok{NP} \NormalTok{; }\DataTypeTok{Prep} \NormalTok{;}
\end{HighlightingFancy}
\item[\t{\OtherTok{fun}}]\begin{HighlightingFancy}[]
\NormalTok{PrepNP} \FunctionTok{:} \DataTypeTok{Prep} \OtherTok{->} \DataTypeTok{NP} \OtherTok{->} \DataTypeTok{Adv} \NormalTok{;}
\NormalTok{AdvCN}  \FunctionTok{:} \DataTypeTok{Adv}  \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;}
\NormalTok{DetCN}  \FunctionTok{:} \DataTypeTok{Det}  \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;}
\NormalTok{house, … }\FunctionTok{:} \DataTypeTok{CN} \NormalTok{;}
\NormalTok{this, these, … }\FunctionTok{:} \DataTypeTok{Det} \NormalTok{;}
\NormalTok{on, … }\FunctionTok{:} \DataTypeTok{Prep}
\end{HighlightingFancy}
\end{itemize}

\noindent We change the syntax of the functions slightly: move the result
category to the left and remove arrows.

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{Adv}  \OtherTok{::=} \NormalTok{PrepNP }\DataTypeTok{Prep} \DataTypeTok{NP} \NormalTok{;}
\DataTypeTok{CN}   \OtherTok{::=} \NormalTok{AdvCN }\DataTypeTok{Adv} \DataTypeTok{CN} \FunctionTok{|} \NormalTok{house }\FunctionTok{|} \NormalTok{… ;}
\DataTypeTok{NP}   \OtherTok{::=} \NormalTok{DetCN }\DataTypeTok{Det} \DataTypeTok{CN} \NormalTok{;}
\DataTypeTok{Det}  \OtherTok{::=} \NormalTok{this }\FunctionTok{|} \NormalTok{these }\FunctionTok{|} \NormalTok{… ;}
\DataTypeTok{Prep} \OtherTok{::=} \NormalTok{on }\FunctionTok{|} \NormalTok{… ;}
\end{HighlightingFancy}
\end{EmptyItem}


Now, let us move from the \gf{} abstract syntax to the \pmcfg{} concrete
categories. We label the different concrete categories with
subscript numbers rather arbitrarily; they don't have any deeper
meaning per se, and don't need to be memorised. Apart from the first
lines, we show only one function for each concrete category. This is
just to simplify the example; in reality, all of the result categories
may have several functions that produce them.

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{Adv₀  }\OtherTok{::=} \NormalTok{PrepNP} \DataTypeTok{Prep₇} \DataTypeTok{NP₃} \FunctionTok{|} \NormalTok{PrepNP} \DataTypeTok{Prep₇} \DataTypeTok{NP₄} \NormalTok{;}
\DataTypeTok{CN₁   }\OtherTok{::=} \NormalTok{AdvCN} \DataTypeTok{Adv₀} \DataTypeTok{CN₁ }\FunctionTok{|} \NormalTok{house} \NormalTok{;}
\DataTypeTok{CN₂   }\OtherTok{::=} \NormalTok{AdvCN} \DataTypeTok{Adv₀} \DataTypeTok{CN₂} \NormalTok{;}
\DataTypeTok{NP₃   }\OtherTok{::=} \NormalTok{DetCN} \DataTypeTok{Det₅} \DataTypeTok{CN₁} \NormalTok{;}
\DataTypeTok{NP₄   }\OtherTok{::=} \NormalTok{DetCN} \DataTypeTok{Det₆} \DataTypeTok{CN₂} \NormalTok{;}
\DataTypeTok{Det₅  }\OtherTok{::=} \NormalTok{this} \NormalTok{;}
\DataTypeTok{Det₆  }\OtherTok{::=} \NormalTok{these} \NormalTok{;}
\DataTypeTok{Prep₇ }\OtherTok{::=} \NormalTok{on} \NormalTok{;}
\end{HighlightingFancy}
\end{EmptyItem}


% Before, at the \gf{} level, we could just look at the lexicon and check whether there is some \t{CN} (e.g. \t{house}). But now, we don't know just by looking whether we have both \t{CN$_{\text 1}$} and \t{CN$_\text{2}$}: maybe the lexicon is so small that there are no instances of \t{CN$_\text{2}$}, or maybe some combination of parameters doesn't even exist. Regardless of the reason of emptiness, if \t{CN$_\text{2}$} is empty, then \t{NP$_\text{4}$} is too, because it is constructed from \t{CN$_\text{2}$}.  Thus, we can compute if a category is empty, given the emptiness of its argument categories.

We need some initial guesses for the values. Ultimately we want to
just know if a given category has a member or no, so we can deal with
Booleans. We give an initial value of False to all variables, meaning
``this category is empty'', and we mark that with red text.
In fact, now that we are reduced to Booleans, we don’t even need to
care about what the original GF functions do with their arguments. So
we can replace the GF functions \t{AdvCN}, \t{DetCN} and \t{PrepNP}
with just a conjunction ($\&\&$): both arguments to the function must
be non-empty. In case of multiple functions that have the same
concrete category as a result, we replace the $|$ with a disjunction
($||$): \emph{some} way of constructing the category must have only
non-empty arguments.

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\AlertTok{Adv₀  }\OtherTok{::=} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₃ }\FunctionTok{||} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₄} \NormalTok{;}
\AlertTok{CN₁   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₁ }\FunctionTok{||} \ErrorTok{house} \NormalTok{;}
\AlertTok{CN₂   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\AlertTok{NP₃   }\OtherTok{::=} \AlertTok{Det₅ }\FunctionTok{&&} \AlertTok{CN₁} \NormalTok{;}
\AlertTok{NP₄   }\OtherTok{::=} \AlertTok{Det₆ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\AlertTok{Det₅  }\OtherTok{::=} \ErrorTok{this} \NormalTok{;}
\AlertTok{Det₆  }\OtherTok{::=} \ErrorTok{these} \NormalTok{;}
\AlertTok{Prep₇ }\OtherTok{::=} \ErrorTok{on} \NormalTok{;}
\end{HighlightingFancy}
\end{EmptyItem}

A variable for a given category turns into True, when we find a member
of that category. On the first round, we start from the lexical
categories: \t{CN$_*$}, \t{Det$_*$} and \t{Prep$_*$}. To
continue with the example, say that all have a lexical item except for
\t{CN$_\text{2}$}. Thus, after the first round, the following
categories are found non-empty.

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\AlertTok{Adv₀  }\OtherTok{::=} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₃ }\FunctionTok{||} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₄} \NormalTok{;}
\DataTypeTok{CN₁   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₁ }\FunctionTok{||} \NormalTok{house} \NormalTok{;}
\AlertTok{CN₂   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\AlertTok{NP₃   }\OtherTok{::=} \AlertTok{Det₅ }\FunctionTok{&&} \AlertTok{CN₁} \NormalTok{;}
\AlertTok{NP₄   }\OtherTok{::=} \AlertTok{Det₆ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\DataTypeTok{Det₅  }\OtherTok{::=} \NormalTok{this} \NormalTok{;}
\DataTypeTok{Det₆  }\OtherTok{::=} \NormalTok{these} \NormalTok{;}
\DataTypeTok{Prep₇ }\OtherTok{::=} \NormalTok{on} \NormalTok{;}
\end{HighlightingFancy}
\end{EmptyItem}


On the second round, the change of status in \t{Det$_\text{5}$} and
\t{CN$_\text{1}$} updates \t{NP$_\text{3}$} into True. On the third
and final round, also \t{Adv$_\text{0}$} becomes True, due to
\t{Prep$_\text{7}$} and \t{NP$_\text{3}$} being True. But after the
third round, nothing is going to change, no matter how much we
recompute. In other words, we have found a fixed point.

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{Adv₀  }\OtherTok{::=} \DataTypeTok{Prep₇ }\FunctionTok{&&} \DataTypeTok{NP₃ }\FunctionTok{||} \DataTypeTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₄} \NormalTok{;}
\DataTypeTok{CN₁   }\OtherTok{::=} \DataTypeTok{Adv₀ }\FunctionTok{&&} \DataTypeTok{CN₁ }\FunctionTok{||} \NormalTok{house} \NormalTok{;}
\AlertTok{CN₂   }\OtherTok{::=} \DataTypeTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\DataTypeTok{NP₃   }\OtherTok{::=} \DataTypeTok{Det₅ }\FunctionTok{&&} \DataTypeTok{CN₁} \NormalTok{;}
\AlertTok{NP₄   }\OtherTok{::=} \DataTypeTok{Det₆ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\DataTypeTok{Det₅  }\OtherTok{::=} \NormalTok{this} \NormalTok{;}
\DataTypeTok{Det₆  }\OtherTok{::=} \NormalTok{these} \NormalTok{;}
\DataTypeTok{Prep₇ }\OtherTok{::=} \NormalTok{on} \NormalTok{;}
\end{HighlightingFancy}
\end{EmptyItem}

\subsection{Least fixpoint}

% In the previous example, we found \emph{a} fixed point. But there are several of them---why is ours a good one?

Assume for a moment that the set of variables  \t{Adv$_\text{0}$}--\t{Prep$_\text{7}$} has nothing to do with the original GF grammar. Then, we could easily conceive of other assignments to the variables that are also fixpoints: say, everything is False; only \t{Det$_\text{5}$} and \t{CN$_\text{2}$} are True; everything is True. (In contrast, “only \t{Det$_\text{5}$} and \t{CN$_\text{1}$} are True” is not a fixpoint, because if we iterated one more time, \t{NP$_\text{3}$} would change from False to True).

Of course, given that these variables come from an actual GF grammar, we don’t want to give an answer “everything is True” if some categories actually correspond to nonexisting combinations of parameters. Likewise, we don’t want to be too pessimistic and claim that some non-empty category has no words in it. Instead, we want the most conservative solution that respects reality---the least fixpoint, given the actual GF grammar.

To define \emph{least}, we need to define an ordering on the domain of possible solutions. In the case of Booleans, we just say False ≤ True, and hence a solution with more False is smaller. 
We start the computation by giving the least value to all variables.
Another requirement is that all right-hand sides of the equations need to be monotonic (which they are because every boolean expression that only contains $\&\&$ and $||$ is monotonic). Under these circumstances, the least fixpoint will be calculated.

\subsection{Example II: empty fields and unreachable categories}

Finding empty concrete categories was quite a trivial problem for two
reasons: the values are not changing after they get confirmed as True,
and we had absolutely no use for the actual \gf{} functions (or the
\pmcfg{} versions of them).  Before moving on to context generation,
we demonstrate briefly another two simple problems: finding categories
that are unreachable from the start category, and fields that are
always empty.

\paragraph{Is a category reachable from the start category?}

\begin{itemize}
\setlength\itemsep{0em}
\item Least value: False (all categories are non-reachable from the start category)
\item Confirm that the start category is reachable from the start category.
\item For each function whose result category is confirmed reachable, confirm its argument categories reachable.
\end{itemize}

\noindent We still don’t need the details of the function, just knowledge which arguments it takes. The values are still Booleans, and don’t change once they’ve become True.
However, the first problem was bottom-up, whereas this problem is
top-down. In the case of empty categories, we started from several terminal categories, and moved up all the way to the start category. This time we start from the top, and confirm more and more lower-level categories reachable. But the iterative process is the same in both cases.

\paragraph{Are some fields always empty?}

\begin{itemize}
\setlength\itemsep{0em}
\item Least value: all fields in all categories are empty. Now
  the value is not a Boolean, it is instead a set of fields that are
  non-empty---which in the beginning is an empty set. The ordering
  is the subset relation: \t{A ≤ B} if \t{A ⊆ B}.
% \t{A $\leq$ B} if \t{A $\subseteq$ B}.
\item A field \t{s} in a terminal category \t{T} is non-empty, if
  there is some actual word with a non-empty string in \t{s}. When
  such a word is found, add that field to the initial set of non-empty
  fields.
\item A field \t{s'} in a non-terminal category \t{N} is non-empty, if
  there is some function \t{f~:~T$_\text{1}$~$\rightarrow$
    \dots~$\rightarrow$~T$_\text{n}$~$\rightarrow$~N}, that uses at
  least one non-empty field from some \t{T$_\text{i}$}, or
  alternatively, introduces new strings into \t{s'}.
\end{itemize}

\noindent Here we need the actual \gf{} function, because we need to
find out which fields of its arguments it is using---it is not enough
to know that the argument has some fields with some properties. In
fact, since functions may not only use their arguments but also
introduce new strings, we definitely need all three pieces of
information: the emptiness status of the arguments’ fields, which
fields are used by \t{f}, and whether \t{f} introduces new strings.

\subsection{Context generation revisited}

We present context generation with fixpoints in the present section,
by using a concrete example. The general algorithm is presented in
Appendix~\ref{general-algorithm-context}.


\begin{table}
\ttfamily
\begin{tabular}{p{0.25cm} p{0.18cm} p{5cm} p{0.35cm} p{0.18cm} l}
\DataTypeTok{NP$_*$} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{PredAdj}\NormalTok{, }\DecValTok{0}\NormalTok{, [s }\DataTypeTok{Nom}\NormalTok{], }\DataTypeTok{S}\NormalTok{)} & \DataTypeTok{CN} &  \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Sg}\NormalTok{],  }\DataTypeTok{NP$_{\text{sg}}$}\NormalTok{)}\\
 & & \NormalTok{, (}\DataTypeTok{PredAdv}\NormalTok{, }\DecValTok{0}\NormalTok{, [s }\DataTypeTok{Nom}\NormalTok{], }\DataTypeTok{S}\NormalTok{)}
& & &                \NormalTok{, (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Pl}\NormalTok{],  }\DataTypeTok{NP$_{\text{pl}}$}\NormalTok{)}\\
 & & \NormalTok{, (}\DataTypeTok{UttNP}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s }\DataTypeTok{Nom}\NormalTok{], }\DataTypeTok{S}\NormalTok{)}
& & & \NormalTok{, (}\DataTypeTok{AdjCN}\NormalTok{,   }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Sg}\NormalTok{, s }\DataTypeTok{Pl}\NormalTok{], }\DataTypeTok{CN}\NormalTok{) \}}\\
& & \NormalTok{, (}\DataTypeTok{PrepNP}\NormalTok{,  }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Acc}\NormalTok{], }\DataTypeTok{Adv}\NormalTok{) \}}
& \DataTypeTok{Det$_{\text{sg}}$} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{NP$_{\text{sg}}$}\NormalTok{)}\\
\DataTypeTok{AP} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{PredAdj}\NormalTok{, }\DecValTok{1}\NormalTok{, [s], }\DataTypeTok{S}\NormalTok{)              }
& \DataTypeTok{Det$_{\text{pl}}$} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{NP$_{\text{pl}}$}\NormalTok{) \}}\\
& & \NormalTok{, (}\DataTypeTok{AdjCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{CN}\NormalTok{) \}}
& \DataTypeTok{Adv} & \OtherTok{$\mapsto$} &\NormalTok{\{ (}\DataTypeTok{PredAdv}\NormalTok{, }\DecValTok{1}\NormalTok{, [s], }\DataTypeTok{S}\NormalTok{)}\\
\DataTypeTok{Prep} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{PrepNP}\NormalTok{,  }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{Adv}\NormalTok{)\}}
& & & \NormalTok{, (}\DataTypeTok{AdvCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{CN}\NormalTok{) \}}\\
\end{tabular}
\caption{Category $\mapsto$ (function,
arg. position, [fields used by function], result category)}
\label{info-on-grammar}
\end{table}


Let us start by listing some information we have on the grammar.  For
every category \t{C}, we know which functions take it as an argument,
and which position \t{C} is. For instance, the category \t{AP} is
consumed as the first argument (position 0) of \t{AdjCN}, and second
argument (position 1) of \t{PredAdj}.  In addition, we know which
fields from its argument the function uses (i.e. sends upwards):
nominative for \t{PredAdj}, \t{PredAdv} and \t{UttNP}, and accusative
for \t{PrepNP}.  Table~\ref{info-on-grammar} shows this information
for the concrete categories based on the \gf{} categories \t{NP},
\t{AP}, \t{Prep}, \t{CN}, \t{Det} and \t{Adv} in an English concrete
syntax.  In the table, \t{NP$_{\text{sg}}$} and \t{NP$_{\text{pl}}$}
are merged into one, because the number of \t{NP} doesn't make a
difference in any of the functions that take it as an argument; both
\t{NP$_{\text{sg}}$} and \t{NP$_{\text{pl}}$} become the same concrete
\t{S}.

The least value for all contexts is just the empty set. We can start
the first round by finding a trivial context (the identity function)
for the start category \t{S}, along with all the fields that make it
to the top (the only field \t{s}). The following is our situation at round 0:

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{CtxS}    \OtherTok{::=} \NormalTok{\{ (id,[s]) \}}
\DataTypeTok{CtxNP$_*$}  \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxAP}   \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxAdv}  \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxCN}   \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxDet$_*$} \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxPrep} \OtherTok{::=} \NormalTok{\{ \}}
\end{HighlightingFancy}
\end{EmptyItem}

\noindent Now that \t{S} has a context, we can find some context for all the
categories that appear as arguments to some function that has \t{S} as
a goal category. Consulting Table~\ref{info-on-grammar}, we find
\t{NP}, \t{AP} and \t{Adv} in such a position, using the functions \t{UttNP},
\t{PredAdj} and \t{PredAdv}. We add these functions into
the contexts for \t{NP}, \t{AP} and \t{Adv} at round 1.

\paragraph{Round 1}

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{CtxS}    \OtherTok{::=} \NormalTok{\{ (id, [s]) \}}
\DataTypeTok{CtxNP$_*$}  \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{UttNP} \NormalTok{•), [s Nom]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}} 
\DataTypeTok{CtxAP}   \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PredAdj} \NormalTok{\gray{any NP} •), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}}
\DataTypeTok{CtxAdv}  \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PredAdv} \NormalTok{\gray{any NP} •), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}}
\DataTypeTok{CtxCN}   \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxDet$_*$} \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxPrep} \OtherTok{::=} \NormalTok{\{ \}}
\end{HighlightingFancy}
\end{EmptyItem}

\noindent For \t{AP} and \t{Adv}, there is only one function that
takes them into an \t{S}, but for \t{NP} there are 3
alternatives---why only one is chosen? In our case, we favour
\t{UttNP} because it creates the smallest tree. The other two
functions that take an \t{NP} into an \t{S} also choose the \t{s Nom}
field, so it is enough to just use one of the functions.
The contexts for \t{S}, \t{NP}, \t{AP} and \t{Adv}
unlock more contexts on round 2.

\paragraph{Round 2}

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{CtxS}    \OtherTok{::=} \NormalTok{\{ (id, [s]) \}}
\DataTypeTok{CtxNP$_*$}  \OtherTok{::=} \NormalTok{\{ (ctx
 (}\DataTypeTok{UttNP} \NormalTok{•), [s Nom]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}} $\cup$
            \NormalTok{\{ (ctx (}\DataTypeTok{PrepNP} \NormalTok{\gray{any Prep} •), [s Acc]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxAdv}\NormalTok{\}}
\DataTypeTok{CtxAP}   \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PredAdj} \NormalTok{\gray{any NP} •), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}}
\DataTypeTok{CtxAdv}  \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PredAdv} \NormalTok{\gray{any NP} •), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}}
\DataTypeTok{CtxCN}   \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{\gray{any Det$_{\text{sg}}$} •), [s Sg]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{sg}}$}\NormalTok{\}} $\cup$
            \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{\gray{any Det$_{\text{pl}}$} •), [s Pl]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{pl}}$}\NormalTok{\}}
\DataTypeTok{CtxDet$_{\text{sg}}$} \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{• \gray{any CN}), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{sg}}$}\NormalTok{\}}
\DataTypeTok{CtxDet$_{\text{pl}}$} \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{• \gray{any CN}), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{pl}}$}\NormalTok{\}}
\DataTypeTok{CtxPrep} \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PrepNP} \NormalTok{• \gray{any NP}), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxAdv}\NormalTok{\}}
\end{HighlightingFancy}
\end{EmptyItem}

\noindent On round 2, \t{NP$_*$} got another context using
\t{PrepNP}, which chooses the accusative field. With \t{UttNP}
choosing nominative and \t{PrepNP} choosing accusative, \t{NP$_*$} has
now an exhaustive set of contexts.

In fact, we are done for the whole context generation, even without consulting all functions!
This is the benefit of going top-down: we don’t waste time trying out
functions that may lead anywhere. Consider \t{AP} for instance: we
would have eventually found our way to \t{S} even by following \t{AdjCN} first, but
why bother when \t{PredAdj} already takes an \t{AP} directly to \t{S}?

In English, we don’t bother, because there’s only one field in
\t{AP}. Suppose there is a language that is just like English, except
that adjectives come in two variants, attributive and
predicative. Dutch fits the description pretty well: ``the warm pizza
is warm'' translates into ``de warme pizza is warm''. Now the grammar has two fields for
\t{AP}, which we call \t{s Pred} and \t{s Attr}. The function \t{PredAdj} covers the
field \t{s Pred} on the first round, and we need to wait until the third round, when \t{CtxCN} is
no more empty, to find a context that covers \t{s Attr}. 

\paragraph{Round 3 (only for Dutch)}

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{CtxS}    \OtherTok{::=} \NormalTok{\{ (id, [s]) \}}
\DataTypeTok{CtxNP$_*$}  \OtherTok{::=} \NormalTok{\{ (ctx
 (}\DataTypeTok{UttNP} \NormalTok{•), [s Nom]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}} $\cup$
            \NormalTok{\{ (ctx (}\DataTypeTok{PrepNP} \NormalTok{\gray{any Prep} •), [s Acc]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxAdv}\NormalTok{\}}
\DataTypeTok{CtxAP}   \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PredAdj} \NormalTok{\gray{any NP} •), [s Pred]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}} $\cup$
            \NormalTok{\{ (ctx (}\DataTypeTok{AdjCN} \NormalTok{• \gray{any CN}), [s Attr]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxCN}\NormalTok{\}}
\DataTypeTok{CtxAdv}  \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PredAdv} \NormalTok{\gray{any NP} •), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxS}\NormalTok{\}}
\DataTypeTok{CtxCN}   \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{\gray{any Det$_{\text{sg}}$} •), [s Sg]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{sg}}$}\NormalTok{\}} $\cup$
            \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{\gray{any Det$_{\text{pl}}$} •), [s Pl]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{pl}}$}\NormalTok{\}}
\DataTypeTok{CtxDet$_{\text{sg}}$} \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{• \gray{any CN}), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{sg}}$}\NormalTok{\}}
\DataTypeTok{CtxDet$_{\text{pl}}$} \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{DetCN} \NormalTok{• \gray{any CN}), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxNP$_{\text{pl}}$}\NormalTok{\}}
\DataTypeTok{CtxPrep} \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PrepNP} \NormalTok{• \gray{any NP}), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxAdv}\NormalTok{\}}
\end{HighlightingFancy}
\end{EmptyItem}

After the third round, we are done for Dutch as well. Before we
put the contexts together and fill the gray placeholders with actual
subtrees, we talk about some important properties of the fixpoint
computation.

\paragraph{First come first served / Monotonicity}

For fixpoint purposes, it is important that we do not change the
contexts for anything that uses fewer or the same amount of fields.
In the English example, it would not serve any purpose to swap
\t{PredAdj} for \t{AdjCN} in the context of \t{AP}, because both
choose the same field. Furthermore, if we did that on an arbitrary
basis, the sets would not converge, and we wouldn't find a fixpoint.

However, the functions can be replaced in the case that we find a
function that covers strictly more fields than any of the previously found.
Assume that we added a whole new abstract syntax construction of type
\t{CN $\rightarrow$ NP}, which uses both singular and plural in one
sentence. Then we get just one context which covers \t{[s Sg, s Pl]},
and thus we throw away both \t{(ctx (DetCN \gray{any
    Det$_{\text{sg}}$} •), [s Sg])} and \t{(ctx (DetCN \gray{any
    Det$_{\text{pl}}$} •), [s Pl])}, in favour of, say, \t{(ctx
  (SgAndPl •), [s Sg, s Pl])}.

So, the set of contexts for a category \t{C} may change during the
fixpoint computation. It grows as we unlock contexts for more
categories, further down from the start category. It may also shrink,
if we find a single context that covers the fields from multiple,
previously computed, contexts. But most importantly, the list of
fields from \t{C} that make it into the start category is growing
throughout the fixpoint computation. It’s just the way those fields
are clumped into contexts that changes.

\paragraph{Final contexts}

After round 2 in English, were left with contexts such as \t{\DataTypeTok{CtxPrep} \OtherTok{::=} \NormalTok{\{ (ctx (}\DataTypeTok{PrepNP} \NormalTok{• \gray{any NP}), [s]) | (ctx,\_) $\leftarrow$} \DataTypeTok{CtxAdv}\NormalTok{\}}}.
To compute the full contexts, we need to look into \t{CtxAdv}, as
follows:

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{CtxPrep} \OtherTok{::=} \textbf{\{} (ctx (\DataTypeTok{PrepNP} • \gray{any NP}), [s])
            | (ctx,\_) $\leftarrow$ \{ ctx' (\DataTypeTok{PredAdv} \gray{any NP} •)
                         | (ctx',\_) $\leftarrow$ \DataTypeTok{CtxS} \} 
            \textbf{\}}
\end{HighlightingFancy}
\end{EmptyItem}

\noindent We can now incorporate the contents of \t{CtxAdv} into
\t{CtxPrep}:


\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{CtxPrep} \OtherTok{::=} \{ (ctx' (\DataTypeTok{PredAdv} \gray{any NP} (\DataTypeTok{PrepNP} • \gray{any NP}), [s])
            | (ctx',\_) $\leftarrow$ \DataTypeTok{CtxS} \} 
\end{HighlightingFancy}
\end{EmptyItem}

\noindent The contexts for \t{S} is just the identity function, so the
whole set reduces to the following context.

\begin{EmptyItem}
\begin{HighlightingFancy}[]
\DataTypeTok{CtxPrep} \OtherTok{::=} \{ \DataTypeTok{PredAdv} \gray{any NP} (\DataTypeTok{PrepNP} • \gray{any NP}), [s]) \} 
\end{HighlightingFancy}
\end{EmptyItem}

\noindent In order to make the previous into a full context, we need to
generate two \t{NP}s, without any requirements; singular, plural,
human, non-human, etc. As explained in Section~\ref{sec:pruning_all},
we just enumerate all trees (using the \feat{} framework \cite{feat}),
and choose the alphabetically first; this is both extremely simple
solution, and it makes it easy to find identical trees. We could as
easily choose a random tree, or use some other heuristic.



% In our tool, computing relevant contexts in a given start category \t{S}, is done once, in advance, for all possible hole types $H$ at the same time, using a fixpoint iteration. It is possible to express the set of relevant contexts for one hole type $H$ in terms of the sets of relevant contexts for other hole types $H'$:
% $$
% \textsf{contexts}(H) = \textsf{filter}(\;\{ C[F(\_)] \; | \; F \in H \rightarrow H', \; C \in \textsf{contexts}(H') \}\;)
% $$
% In words, to generate contexts with holes of type $H$, we enumerate all functions $F$ that have a $H$ as an argument, and enumerate all contexts $C$ that have the result type $H'$ of $F$ as a hole type, and put $C$ and $F$ together to get a new context. Then, we apply a function $\textsf{filter}$ to the result in order to filter out redudant contexts, i.e. contexts whose uses of the strings of $H$ are already covered by other contexts in the same set.
% To compute relevant contexts with the start category \t{S} as a hole, we use the following definition $\textsf{contexts}(\t{S}) = \{ \; \_ \; \}$.

% Now, in order to compute all sets of contexts for all possible hole categories $H$, we set up a system of equations (as specified above). In general, this system of equations is recursive, and we use a fixpoint iteration to solve it, starting with the empty set $\varnothing$ for each set of contexts. There is a guaranteed minimal solution, because the RHSs are monotonic in $H'$.
