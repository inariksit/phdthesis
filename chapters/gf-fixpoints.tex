\section{Fixpoint computation}
\label{sec:moreFP}

We touched upon fixpoint computation in the section for enumerating
contexts. Here we explain the method with more focus, along with
other, more general and language-independent analyses we can perform
on a grammar. The reader uninterested in technical details may well
skip everything after Section~\ref{additional-analyses} and move on to
evaluation.

\subsection{Additional analyses}
\label{additional-analyses}

Aside from concrete language-dependent phenomena, there are more
general questions a grammar writer may ask. For instance, say that our
concrete type for \t{CN} in some language is an inflection table
from case to string, we would like to know if (a) a given string field
is unreachable from the start category; (b) any two fields always
contain the same string; or (c) some fields are always the empty
string.  In addition, a whole argument may be erased by some function:
say that \t{AdjCN~:~Adj~$\rightarrow$~CN~$\rightarrow$~CN} never adds
the adjective to the new \t{CN}, in which case \t{AdjCN blue house}
and \t{house} are linearised identically. Instead of testing every
single function, we would like to know if there are any functions in
the grammar that behave like this.

% In Dutch, nominative and accusative are only different for
% pronouns, so for this grammar we would indeed find out that case is
% redundant: all nominative and accusative fields would be
% identical. As grammarians, we could decide to keep the distinction for
% further extension of the grammar---maybe we want to add pronouns in
% the future---or remove it as redundant.

The analyses mentioned in this section are implemented in a similar
way to the method for enumerating all contexts: using fixpoint
computation. We use the simpler cases as examples to explain the
method, and then move on to a detailed explanation of context
generation.

\subsection{Example I: empty concrete categories}

We start with an extremely simple analysis: detecting empty concrete
categories. A single \gf{} category compiles into multiple concrete
categories, one for each combination of parameters. We have
e.g. \t{Det$_{\text{sg}}$} and \t{Det$_{\text{pl}}$}, as well as
\t{NP$_{\text{sg}}$} and \t{NP$_{\text{pl}}$}. But if there are no
words of type \t{Det$_{\text{pl}}$} in the lexicon, then there won't
be any way to construct elements of type \t{NP$_{\text{pl}}$}
either. This way, we can compute if a category is empty, given that we
know if its argument categories are empty or not.

As a first step, we can see \gf{} categories as mutually recursive
datatypes. Take a fragment of the \gf{} grammar in Figure~\ref{fig:exampleGrammar}:

\begin{itemize}
\item[\t{\OtherTok{cat}}]
\begin{Highlighting}[]
\DataTypeTok{Adv} \NormalTok{; }\DataTypeTok{CN} \NormalTok{; }\DataTypeTok{Det} \NormalTok{; }\DataTypeTok{NP} \NormalTok{; }\DataTypeTok{Prep} \NormalTok{;}
\end{Highlighting}
\item[\t{\OtherTok{fun}}]\begin{Highlighting}[]
\NormalTok{PrepNP} \FunctionTok{:} \DataTypeTok{Prep} \OtherTok{->} \DataTypeTok{NP} \OtherTok{->} \DataTypeTok{Adv} \NormalTok{;}
\NormalTok{AdvCN}  \FunctionTok{:} \DataTypeTok{Adv}  \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;}
\NormalTok{DetCN}  \FunctionTok{:} \DataTypeTok{Det}  \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;}
\NormalTok{house, … }\FunctionTok{:} \DataTypeTok{CN} \NormalTok{;}
\NormalTok{this, these, … }\FunctionTok{:} \DataTypeTok{Det} \NormalTok{;}
\NormalTok{on, … }\FunctionTok{:} \DataTypeTok{Prep}
\end{Highlighting}
\end{itemize}

\noindent We change the syntax of the functions slightly: move the result
category to the left and remove arrows.

\begin{EmptyItem}
\begin{Highlighting}[]
\DataTypeTok{Adv}  \OtherTok{::=} \NormalTok{PrepNP }\DataTypeTok{Prep} \DataTypeTok{NP} \NormalTok{;}
\DataTypeTok{CN}   \OtherTok{::=} \NormalTok{AdvCN }\DataTypeTok{Adv} \DataTypeTok{CN} \FunctionTok{|} \NormalTok{house }\FunctionTok{|} \NormalTok{… ;}
\DataTypeTok{NP}   \OtherTok{::=} \NormalTok{DetCN }\DataTypeTok{Det} \DataTypeTok{CN} \NormalTok{;}
\DataTypeTok{Det}  \OtherTok{::=} \NormalTok{this }\FunctionTok{|} \NormalTok{these }\FunctionTok{|} \NormalTok{… ;}
\DataTypeTok{Prep} \OtherTok{::=} \NormalTok{on }\FunctionTok{|} \NormalTok{… ;}
\end{Highlighting}
\end{EmptyItem}


Now, let us move from the \gf{} abstract syntax to the \pmcfg{} concrete
categories. We label the different concrete categories with
subscript numbers rather arbitrarily; they don't have any deeper
meaning per se, and don't need to be memorised. Apart from the first
lines, we show only one function for each concrete category. This is
just to simplify the example; in reality, all of the result categories
may have several functions that produce them.

\begin{EmptyItem}
\begin{Highlighting}[]
\DataTypeTok{Adv₀  }\OtherTok{::=} \NormalTok{PrepNP} \DataTypeTok{Prep₇} \DataTypeTok{NP₃} \FunctionTok{|} \NormalTok{PrepNP} \DataTypeTok{Prep₇} \DataTypeTok{NP₄} \NormalTok{;}
\DataTypeTok{CN₁   }\OtherTok{::=} \NormalTok{AdvCN} \DataTypeTok{Adv₀} \DataTypeTok{CN₁ }\FunctionTok{|} \NormalTok{house} \NormalTok{;}
\DataTypeTok{CN₂   }\OtherTok{::=} \NormalTok{AdvCN} \DataTypeTok{Adv₀} \DataTypeTok{CN₂} \NormalTok{;}
\DataTypeTok{NP₃   }\OtherTok{::=} \NormalTok{DetCN} \DataTypeTok{Det₅} \DataTypeTok{CN₁} \NormalTok{;}
\DataTypeTok{NP₄   }\OtherTok{::=} \NormalTok{DetCN} \DataTypeTok{Det₆} \DataTypeTok{CN₂} \NormalTok{;}
\DataTypeTok{Det₅  }\OtherTok{::=} \NormalTok{this} \NormalTok{;}
\DataTypeTok{Det₆  }\OtherTok{::=} \NormalTok{these} \NormalTok{;}
\DataTypeTok{Prep₇ }\OtherTok{::=} \NormalTok{on} \NormalTok{;}
\end{Highlighting}
\end{EmptyItem}


% Before, at the \gf{} level, we could just look at the lexicon and check whether there is some \t{CN} (e.g. \t{house}). But now, we don't know just by looking whether we have both \t{CN$_{\text 1}$} and \t{CN$_\text{2}$}: maybe the lexicon is so small that there are no instances of \t{CN$_\text{2}$}, or maybe some combination of parameters doesn't even exist. Regardless of the reason of emptiness, if \t{CN$_\text{2}$} is empty, then \t{NP$_\text{4}$} is too, because it is constructed from \t{CN$_\text{2}$}.  Thus, we can compute if a category is empty, given the emptiness of its argument categories.

We need some initial guesses for the values. Ultimately we want to
just know if a given category has a member or no, so we can deal with
Booleans. We give an initial value of False to all variables, meaning
``this category is empty'', and we mark that with red text.
In fact, now that we are reduced to Booleans, we don’t even need to
care about what the original GF functions do with their arguments. So
we can replace the GF functions \t{AdvCN}, \t{DetCN} and \t{PrepNP}
with just a conjunction ($\&\&$): both arguments to the function must
be non-empty. In case of multiple functions that have the same
concrete category as a result, we replace the $|$ with a disjunction
($||$): \emph{some} way of constructing the category must have only
non-empty arguments.

\begin{EmptyItem}
\begin{Highlighting}[]
\AlertTok{Adv₀  }\OtherTok{::=} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₃ }\FunctionTok{||} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₄} \NormalTok{;}
\AlertTok{CN₁   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₁ }\FunctionTok{||} \ErrorTok{house} \NormalTok{;}
\AlertTok{CN₂   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\AlertTok{NP₃   }\OtherTok{::=} \AlertTok{Det₅ }\FunctionTok{&&} \AlertTok{CN₁} \NormalTok{;}
\AlertTok{NP₄   }\OtherTok{::=} \AlertTok{Det₆ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\AlertTok{Det₅  }\OtherTok{::=} \ErrorTok{this} \NormalTok{;}
\AlertTok{Det₆  }\OtherTok{::=} \ErrorTok{these} \NormalTok{;}
\AlertTok{Prep₇ }\OtherTok{::=} \ErrorTok{on} \NormalTok{;}
\end{Highlighting}
\end{EmptyItem}

A variable for a given category turns into True, when we find a member
of that category. On the first round, we start from the lexical
categories: \t{CN$_*$}, \t{Det$_*$} and \t{Prep$_*$}. To
continue with the example, say that all have a lexical item except for
\t{CN$_\text{2}$}. Thus, after the first round, the following
categories are found non-empty.

\begin{EmptyItem}
\begin{Highlighting}[]
\AlertTok{Adv₀  }\OtherTok{::=} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₃ }\FunctionTok{||} \AlertTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₄} \NormalTok{;}
\DataTypeTok{CN₁   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₁ }\FunctionTok{||} \NormalTok{house} \NormalTok{;}
\AlertTok{CN₂   }\OtherTok{::=} \AlertTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\AlertTok{NP₃   }\OtherTok{::=} \AlertTok{Det₅ }\FunctionTok{&&} \AlertTok{CN₁} \NormalTok{;}
\AlertTok{NP₄   }\OtherTok{::=} \AlertTok{Det₆ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\DataTypeTok{Det₅  }\OtherTok{::=} \NormalTok{this} \NormalTok{;}
\DataTypeTok{Det₆  }\OtherTok{::=} \NormalTok{these} \NormalTok{;}
\DataTypeTok{Prep₇ }\OtherTok{::=} \NormalTok{on} \NormalTok{;}
\end{Highlighting}
\end{EmptyItem}


On the second round, the change of status in \t{Det$_\text{5}$} and
\t{CN$_\text{1}$} updates \t{NP$_\text{3}$} into true. On the third
and final round, also \t{Adv$_\text{0}$} becomes true, due to
\t{Prep$_\text{7}$} and \t{NP$_\text{3}$} being true. But after the
third round, nothing is going to change, no matter how much we
recompute. In other words, we have found a fixed point.

\begin{EmptyItem}
\begin{Highlighting}[]
\DataTypeTok{Adv₀  }\OtherTok{::=} \DataTypeTok{Prep₇ }\FunctionTok{&&} \DataTypeTok{NP₃ }\FunctionTok{||} \DataTypeTok{Prep₇ }\FunctionTok{&&} \AlertTok{NP₄} \NormalTok{;}
\DataTypeTok{CN₁   }\OtherTok{::=} \DataTypeTok{Adv₀ }\FunctionTok{&&} \DataTypeTok{CN₁ }\FunctionTok{||} \NormalTok{house} \NormalTok{;}
\AlertTok{CN₂   }\OtherTok{::=} \DataTypeTok{Adv₀ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\DataTypeTok{NP₃   }\OtherTok{::=} \DataTypeTok{Det₅ }\FunctionTok{&&} \DataTypeTok{CN₁} \NormalTok{;}
\AlertTok{NP₄   }\OtherTok{::=} \DataTypeTok{Det₆ }\FunctionTok{&&} \AlertTok{CN₂} \NormalTok{;}
\DataTypeTok{Det₅  }\OtherTok{::=} \NormalTok{this} \NormalTok{;}
\DataTypeTok{Det₆  }\OtherTok{::=} \NormalTok{these} \NormalTok{;}
\DataTypeTok{Prep₇ }\OtherTok{::=} \NormalTok{on} \NormalTok{;}
\end{Highlighting}
\end{EmptyItem}

\subsection{Least fixpoint}

% In the previous example, we found \emph{a} fixed point. But there are several of them---why is ours a good one?

Assume for a moment that the set of variables  \t{Adv$_\text{0}$}--\t{Prep$_\text{7}$} has nothing to do with the original GF grammar. Then, we could easily conceive of other assignments to the variables that are also fixpoints: say, everything is False; only \t{Det$_\text{5}$} and \t{CN$_\text{2}$} are True; everything is True. (In contrast, “only \t{Det$_\text{5}$} and \t{CN$_\text{1}$} are True” is not a fixpoint, because if we iterated one more time, \t{NP$_\text{3}$} would change from False to True).

Of course, given that these variables come from an actual GF grammar, we don’t want to give an answer “everything is True” if some categories actually correspond to nonexisting combinations of parameters. Likewise, we don’t want to be too pessimistic and claim that some non-empty category has no words in it. Instead, we want the most conservative solution that respects reality---the least fixpoint, given the actual GF grammar.

To define \emph{least}, we need to define an ordering on the domain of possible solutions. In the case of Booleans, we just say False ≤ True, and hence a solution with more False is smaller. 
We start the computation by giving the least value to all variables.
Another requirement is that all right-hand sides of the equations need to be monotonic (which they are because every boolean expression that only contains $\&\&$ and $||$ is monotonic). Under these circumstances, the least fixpoint will be calculated.

\subsection{Example II: empty fields and unreachable categories}

Finding empty concrete categories was quite a trivial problem for two
reasons: the values are not changing after they get confirmed as True,
and we had absolutely no use for the actual \gf{} functions (or the
\pmcfg{} versions of them).  Before moving on to context generation,
we demonstrate briefly another two simple problems: finding categories
that are unreachable from the start category, and fields that are
always empty.

\paragraph{Is a category reachable from the start category?}

\begin{itemize}
\item Start (least) value: False (all categories are non-reachable from the start category)
\item Confirm that the start category is reachable from the start category.
\item For each function whose result category is confirmed reachable, confirm its argument categories reachable.
\end{itemize}

We still don’t need the details of the function, just knowledge which arguments it takes. The values are still Booleans, and don’t change once they’ve become True.

Notice that the first problem was bottom-up: we started from several terminal categories, and moved up all the way to the start category. This time we start from the top, and confirm more and more lower-level categories reachable. But the iterative process is the same in both cases.

\paragraph{Are some fields always empty?}

\begin{itemize}
\item Start (least) value: all fields in all categories are empty. Now
  the value is not a Boolean, it is instead a set of fields that are
  non-empty empty–which in the beginning is an empty set. The ordering
  is the subset relation: \t{A ≤ B} if \t{A ⊆ B}.
% \t{A $\leq$ B} if \t{A $\subseteq$ B}.
\item A field \t{s} in a terminal category \t{T} is non-empty, if
  there is some actual word with a non-empty string in \t{s}. When
  such a word is found, add that field to the initial set of non-empty
  fields.
\item A field \t{s'} in a non-terminal category \t{N} is non-empty, if
  there is some function \t{f~:~T$_\text{1}$~$\rightarrow$
    \dots~$\rightarrow$~T$_\text{n}$~$\rightarrow$~N}, that uses at
  least one non-empty field from some \t{T$_\text{i}$}, or
  alternatively, introduces new strings into \t{s'}.
\end{itemize}

Here we need the actual GF function, because we need to find out which
fields of its arguments it is using---it is not enough to know that
the argument has some fields with some properties. In fact, since
functions may not only use their arguments but also introduce new
strings, we definitely need all three pieces of information: the
emptiness status of the arguments’ fields, which fields are used by
\t{f}, and whether \t{f} introduces new strings.

\subsection{Context generation revisited}

Let us start by listing some information we have on the grammar.  For
every category \t{C}, we know which functions take it as an argument, and
which position \t is. For instance, the category \t{AP} is consumed as
the first argument (position 0) of \t{AdjCN}, and second argument
(position 1) of \t{PredAdj}.  In addition, we know which fields from
its argument the function uses (i.e. sends upwards): nominative for
\t{PredAdj}, \t{PredAdv} and \t{UttNP}, and accusative for \t{PrepNP}.
Table~\ref{info-on-grammar} shows this information for the concrete
categories based on the \gf{} categories \t{NP}, \t{AP}, \t{Prep},
\t{CN}, \t{Det} and \t{Adv} in an English concrete syntax.
In the table, \t{NP$_{\text{sg}}$} and \t{NP$_{\text{pl}}$} are merged
into one, because the number of \t{NP} doesn't make a difference in
any of the functions that take it as an argument; both
\t{NP$_{\text{sg}}$} and \t{NP$_{\text{pl}}$} become the same concrete \t{S}.


\begin{table}
\ttfamily
\begin{tabular}{p{0.25cm} p{0.18cm} p{5cm} p{0.35cm} p{0.18cm} l}
\DataTypeTok{NP$_*$} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{PredAdj}\NormalTok{, }\DecValTok{0}\NormalTok{, [s }\DataTypeTok{Nom}\NormalTok{], }\DataTypeTok{S}\NormalTok{)} & \DataTypeTok{CN} &  \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Sg}\NormalTok{],  }\DataTypeTok{NP$_{\text{sg}}$}\NormalTok{)}\\
 & & \NormalTok{, (}\DataTypeTok{PredAdv}\NormalTok{, }\DecValTok{0}\NormalTok{, [s }\DataTypeTok{Nom}\NormalTok{], }\DataTypeTok{S}\NormalTok{)}
& & &                \NormalTok{, (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Pl}\NormalTok{],  }\DataTypeTok{NP$_{\text{pl}}$}\NormalTok{)}\\
 & & \NormalTok{, (}\DataTypeTok{UttNP}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s }\DataTypeTok{Nom}\NormalTok{], }\DataTypeTok{S}\NormalTok{)}
& & & \NormalTok{, (}\DataTypeTok{AdjCN}\NormalTok{,   }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Sg}\NormalTok{, s }\DataTypeTok{Pl}\NormalTok{], }\DataTypeTok{CN}\NormalTok{) \}}\\
& & \NormalTok{, (}\DataTypeTok{PrepNP}\NormalTok{,  }\DecValTok{1}\NormalTok{, [s }\DataTypeTok{Acc}\NormalTok{], }\DataTypeTok{Adv}\NormalTok{) \}}
& \DataTypeTok{Det$_{\text{sg}}$} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{NP$_{\text{sg}}$}\NormalTok{)}\\
\DataTypeTok{AP} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{PredAdj}\NormalTok{, }\DecValTok{1}\NormalTok{, [s], }\DataTypeTok{S}\NormalTok{)              }
& \DataTypeTok{Det$_{\text{pl}}$} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{DetCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{NP$_{\text{pl}}$}\NormalTok{) \}}\\
& & \NormalTok{, (}\DataTypeTok{AdjCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{CN}\NormalTok{) \}}
& \DataTypeTok{Adv} & \OtherTok{$\mapsto$} &\NormalTok{\{ (}\DataTypeTok{PredAdv}\NormalTok{, }\DecValTok{1}\NormalTok{, [s], }\DataTypeTok{S}\NormalTok{)}\\
\DataTypeTok{Prep} & \OtherTok{$\mapsto$} & \NormalTok{\{ (}\DataTypeTok{PrepNP}\NormalTok{,  }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{Adv}\NormalTok{)\}}
& & & \NormalTok{, (}\DataTypeTok{AdvCN}\NormalTok{,   }\DecValTok{0}\NormalTok{, [s], }\DataTypeTok{CN}\NormalTok{) \}}\\
\end{tabular}
\caption{Category $\mapsto$ (function,
arg. position, [fields used by function], result category)}
\label{info-on-grammar}
\end{table}

The strongest clue was the notion of dependence: in order to compute
contexts for Kind, we need to already have computed contexts for
Item. All categories depend on other categories, except for the start
category.

So, in the beginning we know the optimal path (“do nothing, you’re
already there!”) for the start category, but not for other
categories. This is a hint that we could do top-down, just like we did
when computing reachable categories. Let’s start writing and figure
out the actual values and types as we go.

Remember again that contexts are trees with holes, or in other words,
functions of type Tree -> Tree. To construct paths, we apply the trees
that are closer to the start category to the trees that are
lower. Well, technically we cannot apply Tree -> Tree into another Tree
-> Tree–we just get a composition that is still Tree -> Tree. But
eventually there will be a Tree: one of those examples we’ve generated
at the step before context generation.

So what kind of a trivial Tree -> Tree function we could use for
Comment? Well, there is always id, the most trivial of all a -> a
functions! So let’s plug that in there.

\begin{EmptyItem}
\begin{Highlighting}[]
\DataTypeTok{CtxS}    \OtherTok{::=} \NormalTok{\{ id \}}
\DataTypeTok{CtxNP}   \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxAP}   \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxAdv}  \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxCN}   \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxDet}  \OtherTok{::=} \NormalTok{\{ \}}
\DataTypeTok{CtxPrep} \OtherTok{::=} \NormalTok{\{ \}}
\end{Highlighting}
\end{EmptyItem}



% In our tool, computing relevant contexts in a given start category \t{S}, is done once, in advance, for all possible hole types $H$ at the same time, using a fixpoint iteration. It is possible to express the set of relevant contexts for one hole type $H$ in terms of the sets of relevant contexts for other hole types $H'$:
% $$
% \textsf{contexts}(H) = \textsf{filter}(\;\{ C[F(\_)] \; | \; F \in H \rightarrow H', \; C \in \textsf{contexts}(H') \}\;)
% $$
% In words, to generate contexts with holes of type $H$, we enumerate all functions $F$ that have a $H$ as an argument, and enumerate all contexts $C$ that have the result type $H'$ of $F$ as a hole type, and put $C$ and $F$ together to get a new context. Then, we apply a function $\textsf{filter}$ to the result in order to filter out redudant contexts, i.e. contexts whose uses of the strings of $H$ are already covered by other contexts in the same set.
% To compute relevant contexts with the start category \t{S} as a hole, we use the following definition $\textsf{contexts}(\t{S}) = \{ \; \_ \; \}$.

% Now, in order to compute all sets of contexts for all possible hole categories $H$, we set up a system of equations (as specified above). In general, this system of equations is recursive, and we use a fixpoint iteration to solve it, starting with the empty set $\varnothing$ for each set of contexts. There is a guaranteed minimal solution, because the RHSs are monotonic in $H'$.
