\def\newcite#1{\cite{#1}}

\def\noun{\textsc{N}}
\def\verb{\textsc{V}}
\def\sg{\textsc{Sg}}
\def\pl{\textsc{Pl}}
\def\detdef{\textsc{DetDef}}

\def\la{\text{\em la}}
\def\casa{\text{\em casa}}
\def\grande{\text{\em grande}}

\def\det{{\text{\sc Det}}}
\def\prn{{\text{\sc  Prn}}}
\def\n{{\text{\sc N}}}
\def\v{{\text{\sc V}}}
\def\adj{{\text{\sc Adj}}}

\def\laDet{\la_\det}
\def\laPrn{\la_\prn}
\def\casaN{\casa_\n}
\def\casaV{\casa_\v}
\def\grandeAdj{\grande_\adj}

\def\t#1{\texttt{#1}}
\def\ob#1{\overbrace{ #1 \rule{0pt}{2ex}}}
\def\cgrule#1{{\ttfamily #1}}

\def\defRule{``do not remove the last reading''}


\chapter{Symbolic Evaluation of Constraint Grammar}
\label{chapterCGSAT}

\epigraph{\it You should do it because it solves a problem, not because your supervisor has a fetish for SAT.}{Koen Claessen, 2016}


\noindent In this chapter, we present CG as a Boolean satisfiability (SAT) problem,
and describe an implementation using a SAT-solver. 
This is attractive for several reasons: formal logic is
well-studied, and serves as an abstract language to reason about the
properties of CG. Constraint rules encoded in logic capture richer
dependencies between the tags than standard CG. 


Applying logic to reductionist grammars has been explored earlier by Torbj√∂rn Lager and Joakim Nivre \cite{lager98,lager_nivre01}, but there has not been, to our knowledge, a full logic-based CG implementation; at the time, logic programming was too slow to be used for tagging or parsing. 
Since those works, SAT-solving techniques have improved significantly \cite{marques_silva2010}, and they are used in domains such as microprocessor design and computational 
biology---these problems easily match or exceed CG in complexity. 
In addition, SAT-solving brings us more practical tools, such as maximisation, which enables us to implement a novel conflict resolution method for parallel CG.


The content in this chapter is based on ``Constraint Grammar as a SAT problem'' \cite{listenmaa_claessen2015} and ``Analysing Constraint Grammars with a SAT-solver'' \cite{listenmaa_claessen2016}.
As in the original papers, we present a translation of CG rules into logical formulas, and show how to encode it into a SAT-problem.
This work is implemented as an open-source software SAT-CG\footnote{\url{https://github.com/inariksit/cgsat}}. It uses the high-level library SAT+\footnote{\url{https://github.com/koengit/satplus}}, which is based on MiniSAT \cite{een04sat}.
We evaluate SAT-CG against the state of the art, VISL CG-3.
The experimental setup is the same, but we ran the tests again for this thesis: since the writing of  \cite{listenmaa_claessen2015}, we have optimised our program and fixed some bugs; this 
makes both execution time and F-scores better than we report in the earlier paper. 
%Likewise, VISL CG-3 has been updated, and executes faster.


\section{Related work}
\label{sec:cg-related-work}
\input{chapters/cg-sat-relatedwork}


\section{CG as a SAT-problem}
\label{sec:CGSAT}

In this section, we translate the disambiguation of a sentence into a SAT-problem.
We demonstrate our encoding with an example in Spanish, shown in Figure~\ref{fig:laCasaGrande}: {\em la casa grande}. % (`the big house'). 
The first word, {\em la}, is ambiguous between a definite article (`the') or an object pronoun (`her'), and the second word, {\em casa}, can be a noun (`house') or a verb (`(he/she) marries').
The subsegment {\em la casa} alone can be either a noun phrase, $\laDet \ \casaN$ 
`the house'  or a verb phrase $\laPrn \ \casaV$   `(he/she) marries her'. 
However, the unambiguous adjective, {\em grande} (`big'), disambiguates the whole segment into a noun phrase: `the big house'.
%
Firstly, we translate input sentences into variables and rules into clauses.
Secondly, we disambiguate the sentence by asking for a solution. 
Finally, we consider different ordering schemes and conflict handling.


\subsection{Encoding the input}


\begin{figure}[h]
\centering
\begin{tabular}{p{0.6cm} l | c | c }
%\multicolumn{2}{c}{}
   & \textbf{Original~analysis} 
                & \textbf{Variables}
                              & \textbf{Default rule} \\ \hline
\t{"<la>"}   &   &            &  {\small \defRule} \\
  & \t{"el" 
  det def f sg}  & $\laDet$   &  \\
  & \t{"lo" 
  prn p3 f sg}   & $\laPrn$   &   $\laDet \vee \laPrn$ \\
\t{"<casa>"} &   &            &   \\
  & \t{"casa" 
  n f sg}        & $\casaN$   &  \\
  & \t{"casar"
   v pri p3 sg}  & $\casaV$   & $\casaN \vee \casaV$  \\
\t{"<grande>"} & &            & \\
  & \t{"grande" 
  adj mf sg}   & $\grandeAdj$ & $\grandeAdj$
\end{tabular}
\caption{Ambiguous segment in Spanish: translation into SAT-variables.}
\label{fig:laCasaGrande}
\end{figure}


% \begin{figure}[h]
% \centering
% \begin{verbatim}
% "<la>"
%         "el" det def f sg
%         "lo" prn p3 f sg
% "<casa>"
%         "casa" n f sg
%         "casar" v pri p3 sg
% "<grande>"
%         "grande" adj mf sg
% \end{verbatim}
% \caption{Ambiguous segment in Spanish.}
% \label{fig:laCasaGrande}
% \end{figure}

\paragraph{Reading}
The readings of the word forms make a natural basis for variables.
We translate a combination of a word form and a reading, such as \texttt{"<la>" ["el" det def f sg]}, into a variable $\laDet$, which represents the possibility that \la{} is a determiner. This example segment gives us five variables: $\{ \laDet , \laPrn , \casaN , \casaV,  \grandeAdj \}$, shown in \ref{fig:laCasaGrande}.

\paragraph{Cohort} As in the original input, the readings are grouped together in cohorts. We need to keep this distinction, for instance, to model {\sc select} rules and cautious context: 
\t{SELECT~"casa"~n} means, in effect, ``remove~$\casaV$'', and \t{IF (-1C prn)} means ``if $\laPrn$ is true and $\laDet$ false''. 
%
Most importantly, we need to make sure that the last reading is not removed. Hence we add the default rule, \defRule, as shown in the third column of \ref{fig:laCasaGrande}. 
These disjunctions ensure that at least one variable in each cohort must be true.



\paragraph{Sentence}
In order to match conditions against analyses, the input needs to be structured as a sentence: the cohorts must follow each other like in the original input, indexed by their absolute position in the sentence. Thus when we apply \texttt{REMOVE v IF (-1 det)} to the cohort $2 \rightarrow [\casaN , \casaV]$, the condition will match on $\laDet$ in cohort 1.


\paragraph{Rule}

Next, we formulate a rule in SAT. A single rule, such as \texttt{REMOVE v IF (-1 det)}, is a template for forming an implication; when given a concrete sentence, it will pick concrete variables by the following algorithm.

\begin{enumerate}
\item Match rule against all cohorts
 \begin{itemize}
    \item[\la:] No target found
    \item[\casa:] Target found in $\casaV$, match conditions to \la
      \begin{itemize}
       \item Condition found in $\laDet$
       \item Create a clause: $\laDet \Rightarrow \neg \casaV \ $ `if \la{} is a determiner, \casa{} is not a verb'
      \end{itemize}
    \item[\grande:] No target found
  \end{itemize}
\item Solve with all clauses: 
  $\{ \ob{\laDet \! \vee \laPrn, \ \casaN \vee \casaV, \  \grandeAdj}^{\text{given by the default rule}}, \ 
      \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}} \}$
\end{enumerate}

In Appendix~\ref{appendix1}
, we have included a translation of all the rule types that SAT-CG supports: 
{\sc remove} and {\sc select} rules, with most of the operations from CG-2 \cite{tapanainen1996}, and a couple of features from VISL CG-3 \cite{vislcg3}.
% In addition, we include a few features from VISL CG-3 \cite{vislcg3}, in order to parse most modern grammars.
The following examples in this section do not require reading the appendix.

\subsection{Applying a rule}

%Finally, we have all we need to solve the disambiguation problem. Given the clauses presented in step 2, SAT-solver returns a model---this is our disambiguated sentence. 

Finally, we have all we need to disambiguate the segment: the sentence and the constraints encoded as SAT-variables and clauses. The SAT-solver returns a model that satisfies all the clauses presented in step 2.
We started off with all the variables unassigned, and required at least one variable 
in each cohort to be true. In addition, we gave the clause $\laDet \Rightarrow \neg \casaV$.
We can see with a bare eye that this problem will have a solution; in fact, multiple ones, 
shown in Figure~\ref{fig:modelsOneRule}.
The verb analysis is removed in the first two models, as required by the presence of $\laDet$. However, the implication may as well be interpreted ``if $\casaV$ may not follow $\laDet$, better remove $\laDet$ instead''; this has happened in Models 3--4. 
We see a third interpretation in Model 5: $\casaV$ may be removed even without 
the presence of $\laDet$. This is possible, because $\laDet \Rightarrow \neg \casaV$ is only an implication, not an equivalence.

\begin{figure}[h]
\centering
$$\begin{array}{ c | c | c | c | c}
\textbf{Model 1}  & \textbf{Model 2}  & \textbf{Model 3} & \textbf{Model 4} & \textbf{Model 5} \\ \hline
 \laDet   &  \laDet  &         &        &        \\
          &  \laPrn  & \laPrn  & \laPrn & \laPrn \\
 \casaN   &  \casaN  & \casaN  &        & \casaN \\
          &          & \casaV  & \casaV &         \\
\grandeAdj & \grandeAdj & \grandeAdj & \grandeAdj & \grandeAdj \\

\end{array}$$
\caption{Possible models for \t{REMOVE v IF (-1 det)}.}
\label{fig:modelsOneRule}
\end{figure}


It seems like SAT-CG does worse than any standard CG implementation:
the latter would just remove the verb, not give 5 different interpretations for a single rule.
In fact, the rule \t{REMOVE v IF (-1 det)} alone behaves exactly like \t{REMOVE det IF (1 v)}.
%This behaviour is explained by simple properties of logical formulas: 
%the implication $\laDet \Rightarrow \neg \casaV$ can be expressed as a disjunction 
%$\neg \laDet \vee \neg \casaV$
But there is power to this property. Now, we add a second rule: \texttt{REMOVE n IF (-1 prn)}, which will form the clause $\laPrn \Rightarrow \neg \casaN$. The new clause
%, together with $\laDet \Rightarrow \neg \casaV$, 
prohibits the combination $\laPrn \ \casaN$, which rules out three models out of five. The disambiguation is shown in Figure~\ref{fig:modelsTwoRules}.

\begin{figure}[h!]
\centering
$$\begin{array}{ c | c }
 \textbf{Model 1}  & \textbf{Model 2}  \\ \hline
 \laDet   &          \\
          &  \laPrn  \\
 \casaN   &          \\
          &  \casaV   \\
\grandeAdj & \grandeAdj \\

\end{array}$$
\caption{Possible models for \t{REMOVE v IF (-1 det)} and \t{REMOVE n IF (-1 prn)}.}
\label{fig:modelsTwoRules}
\end{figure}


After two rules, we only have two models: one with $\laDet \ \casaN$ and other with $\laPrn \ \casaV$. 
%This behaviour corresponds to FSIG: 
In fact, we have just implemented parallel CG (PCG), introduced in Section~\ref{sec:ordering}: the rules act in parallel, and if the sentence cannot be fully disambiguated, the remaining uncertainty is modelled as a disjunction of all possible combinations of readings.
In contrast, a sequential CG (SCG) engine applies each rule individually, and it cannot handle disjunction; its only operation is to manipulate lists of readings in a cohort.
%remove \footnote{In CG-3, we can also add readings to a cohort, and cohorts to a sentence.} readings from a cohort. 
The SCG engine would have just applied one of the rules---say, the first one, removed the verb and stopped there. If another rule later in the sequence removes the determiner, there is no way to restore the verb. 

To finish our PCG example, let us add one more rule: \t{REMOVE v IF (1 adj)}, and the corresponding clause $\grandeAdj \Rightarrow \neg \casaV$. This clause will rule out Model~2 of Figure~\ref{fig:modelsTwoRules}, and we will get Model~1 as the unique solution. 
We can see another benefit in allowing connections between rules: none of the three rules has targeted \la{}, still it has become unambiguous. 

% Now, this is all very nice, but the present thesis is not called ``Implementing FSIG with a SAT-solver''. 
% However, understanding the translation of rules to implications is vital to the rest of this thesis, and FSIG provides, arguably, a simpler starting point.
% In the following sections, we will discuss the concepts of conflict resolution and ordering of the rules. 
% Firstly, we show two ways to handle conflicts in the parallel setting, 
% and secondly, we consider an alternative method for a sequential SAT-encoding.


% We have given a minimal description of SAT-based implementation. 
% Many details are left vague: Do we enforce that all readings that are not targeted by rules will resolve to true? How do we treat ordering? 


\subsection{Solving conflicts in the parallel scheme}
\label{sec:parallelScheme}

As described in Section~\ref{sec:ordering}, PCG behaves differently from 
SCG: the rules are dependent on each other, and the order does not matter.
This prevents too hasty decisions, such as removing $\casaV$ before we know the status of \la{}. 
However, ignoring the order means that we miss significant information in the rule set. 
The truth is that pure PCG is very brittle: each and every rule in the set must fit together, without the notion of order. The rule sequence in Figure~\ref{fig:ruleOrder}, taken from a Dutch grammar\footnote{\url{https://svn.code.sf.net/p/apertium/svn/languages/apertium-nld/apertium-nld.nld.rlx}}, will be well-behaved in an SCG with strict rule order.
The grammar will behave as intended also in a heuristic variant of SCG,
because the rules with a longer context are matched first.
But in PCG, the rule set will definitely cause a conflict, rendering the whole grammar useless.



The order clearly demonstrates the course of action: ``If a potential imperative starts a sentence and is followed by an object pronoun, select the imperative reading; then, move on to other rules; finally, if any imperative is still ambiguous, remove the imperative reading.'' 
Comparing the success of SCG to PCG in practical applications, one may speculate that the sequential order is easier to understand---undeniably, its behaviour is more transparent. %As opposed to FSIG, the rules are ordered. As opposed to the heuristic order, the rules behave always the same way, regardless of the input.
If two rules target the same cohort, the first mentioned gets to apply, and removes the target. When the first rule has acted, the second rule is not even considered, because it would remove the last reading.




\begin{figure}[ht]
\centering
   \begin{verbatim}
SECTION

   # Zeg me
   SELECT Imp IF (-1 BOS) (1 (prn obj)) ;

   # . Heb je
   SELECT (vbhaver pres p2 sg) IF (-1 BOS) (1 (prn obj uns p2 mf sg)) ;

   [--]

SECTION

   # remove all imperative readings that have not been explicitly selected
   REMOVE Imp ;

   # remove informal 2nd person singular reading of "heb"
   REMOVE (vbhaver pres p2 sg) ;

   \end{verbatim}
\caption{Example from a Dutch grammar}
\label{fig:ruleOrder}
\end{figure}


% In the carefully crafted examples, we have ignored the careful mode: \t{IF (-1C det)} `if the previous word is unambiguously determiner'. 
Ideally, both ways of grammar writing should yield similar results:
sequential CG rules are more imperative, and parallel CG rules are more declarative.
But the problem of conflicts in PCG still remains. 
In the following, we present two solutions: 
in the first one, we emulate ordering in choosing which clauses to keep, and in the second one, we maximise the number of rule applications. 



\paragraph{Emulating order} 

We keep the parallel base, but use ordering as information for solving conflicts.
This means that all the benefits of parallel execution still hold: the three rules, which all target \emph{casa}, may still disambiguate \emph{la}, without \emph{la} ever being the target.
If all the rules play well together, or if the earlier rules do not match any cohorts, 
then no rule applications need to be removed. 
However, if we have the grammar from Figure~\ref{fig:ruleOrder}, 
and imperative is the right analysis for a given context, then the clauses created by 
\t{REMOVE Imp} would be ignored, in favour of the clauses that are created 
by \t{SELECT Imp IF (-1 BOS) (1 (prn obj))}.



% we keep the parallel base: the cohort vectors are not manipulated between the rule applications, thus the 100\textsuperscript{th} rule still accesses the same variables as the first rule.
%the cohorts are encoded as vectors of variables, and the rules form implications at each application.

In this modified scheme, we introduce the clauses to the SAT-solver one by one, 
and attempt to solve after each clause. If the SAT-problem after the 50$^{th}$ rule 
has a solution, we accept all the clauses created by rule 50. %, and commit to them.
If rule 51 causes a conflict, we prioritise the previous, well-behaving subset of
50 rules, and discard the conflicting clauses created by rule 51.

If a rule matches multiple cohorts, it creates a separate clause for each instance.
Thus, it is no problem if the rule causes a conflict in only one cohort---say, we 
have another potential imperative in the sentence, 
but there is no other rule which targets its other readings. 
We can discard only the conflicting instances: we prevent 
\t{REMOVE Imp} from applying to \emph{Zeg} in the sequence \emph{\# Zeg me}, 
but it still may apply to other ambiguous tokens with imperative reading.


Let us demonstrate the procedure with the Spanish segment {\em la casa grande}.
Assuming our rule set is $\{$\t{REMOVE v IF (-1 det)}, \t{REMOVE v IF (1 adj)}, \t{REMOVE n}$\}$, the revised algorithm goes as follows:


\begin{enumerate}
\item Apply \t{REMOVE v IF (-1 det)}
 \begin{itemize}
    \item Create a clause: $\laDet \Rightarrow \neg \casaV$
    \item Solve with previous clauses:
  $\{ \ob{\laDet \! \vee \laPrn, \ \casaN \vee \casaV, \  \grandeAdj}^{\text{default rule}}, \ 
      \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}} \}$
    \item Solution found: add new clause to the formula
 \end{itemize}
\item Apply \t{REMOVE v IF (1 adj)} 
 \begin{itemize}
    \item Create a clause: $\grandeAdj \Rightarrow \neg \casaV$
    \item Solve with previous clauses:
  $\{..., \laDet \Rightarrow \neg \casaV, \ 
      \ob{\grandeAdj \Rightarrow \neg \casaV}^{\t{REMOVE v IF (1 adj)}}  \}$
    \item Solution found: add new clause to the formula
 \end{itemize}
\item Apply \t{REMOVE n}
 \begin{itemize}
    \item Create a clause: $\neg \casaN$
    \item Solve with previous clauses:
      $\{ ..., \laDet \Rightarrow \neg \casaV, \ 
      \grandeAdj \Rightarrow \neg \casaV, \ 
      \ob{\neg \casaN}^{\t{REMOVE n}} \}$
  % $\{ \ob{\laDet \! \vee \laPrn, ...}^{\text{default rule}}, \ 
  %     \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}}, \ 
  %     \ob{\grandeAdj \Rightarrow \neg \casaV}^{\t{REMOVE v IF (1 adj)}}, \ 
    \item No solution: discard clause
 \end{itemize}

\end{enumerate}

With this procedure, we use ordering to decide which clauses to include, and
then apply all of them in parallel.
After going through all the rules, the final formula to the SAT-solver will contain the clauses  
$\laDet$~$\vee$~$\laPrn$, $\casaN$~$\vee$~$\casaV$,  $\grandeAdj$, $\laDet$~$\Rightarrow$~$\neg$~$\casaV$ and $\grandeAdj$~$\Rightarrow$~$\neg$~$\casaV$.





\paragraph{Maximisation} 

Solving conflicts means that we have multiple rules that target the same reading, and we must choose which rule to apply.
Strict ordering substitutes the question with a simpler one: ``which rule comes first in the grammar?''
Heuristic rule order asks ``out of all the rules that target this cohort, which one has the best matching context?''
If the competitors are \cgrule{REMOVE n IF (-1 prn)} and \cgrule{REMOVE v IF (-1 det) (1 adj)}, then the second one will win. However, if the rules are both as good a match, which happens in Figure~\ref{fig:modelsTwoRules}, we need to resort to mere guessing, or fall back to ordering.

However, we can ask yet another question: ``Out of all the rules that target this cohort, which one is a best fit \emph{with other rules that will apply to this whole sentence}?'' 
%We are not looking at just the initial context, but all the other rules that are going to apply to the same sentence---all of them are going to perform some changes,
As opposed to heuristic or weighted approaches \cite{voutilainen1994designing,oflazer97votingconstraints}, here all the individual rule applications are 
equally important; we just want to find the largest possible subset of rule applications that can act together without conflict.
We will explain the procedure in the following.
%This way is more similar to resolving conflicts in two-level morphology \todo{cite}
%This approach is similar to \todo{add the sources that Anssi mentioned!}.
%With a SAT-solver, we can address the question in the following way.
%Addressing this is beyond the means of previous FSIG implementations \todo{confirm}, but with a SAT-solver, we can answer this question. 


Each rule application to a concrete cohort produces a clause,
and the whole rule set applied to the whole sentence produces 
a large formula. In an ideal case, all the rules are well-behaved, 
and the whole formula is satisfiable. However, if the whole formula 
is unsatisfiable, we may still ask for an assignment that satisfies 
the maximum number of the clauses; that is, rule applications. 
If the grammar is good, we hope that the interaction between 
the appropriate rules would make a large set of clauses that 
fit together, and the inapplicable rule would not ``fit in''.

%In the SAT-world, this means that the largest number of satisfiable clauses would include the group of well-fitting rules, and leave the odd rule out.
% The order-based heuristic in the traditional CG is replaced by a more
% holistic behaviour: if the rules conflict, discard the one that seems
% like an outlier.

We keep the Spanish segment and the rule set $\{$\t{REMOVE v IF (-1 det)}, \t{REMOVE v IF (1 adj)}, \t{REMOVE n} $\}$.
Now the procedure goes as follows:

\begin{enumerate}
\item Apply \t{REMOVE v IF (-1 det)}
 \begin{itemize}
    \item Create a clause: $\laDet \Rightarrow \neg \casaV$
 \end{itemize}
\item Apply \t{REMOVE v IF (1 adj)} 
 \begin{itemize}
    \item Create a clause: $\grandeAdj \Rightarrow \neg \casaV$
 \end{itemize}
\item Apply \t{REMOVE n}
 \begin{itemize}
    \item Create a clause: $\neg \casaN$
 \end{itemize}

\item Solve with all clauses:
  $\{ \ob{\laDet \! \vee \laPrn, ...}^{\text{default rule}}, \ 
      \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}}, \ 
      \ob{\grandeAdj \Rightarrow \neg \casaV}^{\t{REMOVE v IF (1 adj)}}, \ 
      \ob{\neg \casaN}^{\t{REMOVE n}} \}$
\item No solution for all clauses: try to find a solution that satisfies maximally many rule applications; however, default rule cannot be overridden.
\end{enumerate}

Similarly to the previous, order-based scheme, we create a clause for each 
instance of the rule application. In the case of a conflict, we can 
only discard the clauses targeting the offending cohort, but the rule may apply 
elsewhere in the sentence.


The problem of satisfying maximum amount of clauses is known as \emph{Maximum Satisfiability} (MaxSAT).
Whereas SAT is a decision problem, MaxSAT is an optimisation problem.
However, optimisation can be expressed as a sequence of decision problems:
first, we compute a solution, then we add a constraint ``the solution must be better than the one just found'', and ask for another one. 
This process repeats until a better solution cannot be found; then we accept the 
latest solution.

Now let us define how is one solution ``better'' than other,
by using a simple trick. 
%To start, remember that implications can be translated into disjunctions: 
%$\laDet \Rightarrow \neg\casaV$ is equivalent to $\neg\laDet \vee \neg\casaV$. 
%We will create a set of helper variables, and associate them to the clauses 
%with a simple trick.
For each clause $c$, we create a new variable $v$. 
Instead of the original clause, we give the SAT-solver 
an implication $v \Rightarrow c$. 
This means that if $v$ is false, the SAT-solver can ignore the 
actual clause $c$---the part that comes from the rule application.
Conversely, if $v$ is true, then the SAT-solver must handle
the original clause.
Then, we ask for a solution where maximally many of these $v$s are true,
and the question for improvement becomes ``can we make any more of the $v$s true''?
The method of maximising the variables is described in \cite{een06minisatplus}.

As a alternative to creating a helper variable, we could also separate the variables into 
contexts and targets, and maximise the set of contexts: for $\laDet \Rightarrow \neg \casaV$
and $\grandeAdj \Rightarrow \neg \casaV$, maximise the set of $\{\laDet, \grandeAdj\}$.
This variant would bring back the distinction between targets and contexts; given the design of most actually used CGs, it may be better suited for a practical implementation.


%%%%%%%%%
% TODO: move this section somewhere else, it's redundant here in the middle of a chapter!
\section{Grammar Analysis}

In the previous sections, we presented a tool.
In the current section, we will solve a problem.


Recall the design principles of CG from Section~\ref{sec:properties}: 
by design, the grammars are shallow and low-level.
There is no particular hierarchy between lexical, morphological,
syntactic or even semantic tags: individual rules can be written to address any
property, such as ``verb'', ``auxiliary verb in first person singular'',
or ``the word form \emph{sailor}, preceded by \emph{drunken} anywhere in the
sentence''. This makes it possible to treat very particular edge
cases without touching the more general rule: we would simply write
the narrow rule first (``if noun AND \emph{sailor}''), and introduce
the general rule (``if noun'') later.


However, this design is not without problems. As CGs grow larger, it
gets harder to keep track of all the rules and their interaction.
Despite this well-known issue, there has not been a tool that would help 
grammar writers to detect conflicting rules.
Following the idea further, the tool could give feedback that is not 
restricted to conflicts, but also other features that are helpful 
in the process of writing grammar.
Given the rules in Figure~\ref{fig:infrules}, a grammar writer may 
ask the following questions.



\begin{itemize}
\item Are all the Portuguese rules distinct? (e.g. \texttt{Para} and \texttt{De} may be included in \texttt{Prep})
\item Could two or more rules be merged? (e.g. \texttt{SELECT Inf IF -1 Prep OR Vai OR Vbmod ...})
\item What is the best order for the rules?
\item Can the Finnish rule on the left be rewritten in the form shown on the right?
\item Generate an example sequence that triggers rule(s) $R$ but not rule(s) $R'$. 
\end{itemize}

%%%%%


\begin{figure}[t]
\ttfamily
\centering
\begin{tabular}{l | @{~~~} l  l}
SELECT Inf IF ... & \multicolumn{2}{c}{SELECT V + Prs/Imprt + Act + Neg IF ...} \\
~~(-1 Prep) (0C V) ;       & (*-1C Negv LINK NOT *1 Vfin)  & (NOT *-1 Niin OR Neg)  \\
~~(-1 Para OR De) (0C V) ; & (NOT 0 N) (NOT 0 Pron)        & (*-1C Negv \\
~~(-1C Vbmod) (0C V) ;     & (NOT *1 Neg) (NOT *-1 Neg)    &  ~~LINK NOT 0 Imprt \\
~~(-1C Vai) ;              & (NOT 0 Pass) (NOT *-1 Niin)   &  ~~LINK NOT *1 Vfin OR CLB?) \\
~~(-1C Vbmod) (0 Ser) ;    & (*-1C Negv LINK NOT *1 CLB?)  & (NOT 0 N OR Pron OR Pass) \\
~~(-1C Ter/de) ;           & (*-1C Negv LINK NOT 0 Imprt) ;  & (NOT *1 Neg) ; \\

\end{tabular}

\caption{Left: rules to select infinitive in Portuguese. 
        Right: two versions of a condition in Finnish.}

\label{fig:infrules}
\end{figure}

The chapter follows with introduction of related work: namely, corpus-based methods to aid grammar writing, and automatic optimisation of a complete, human-written grammar. We continue by presenting our solution, along with a working implementation, and finally, evaluate its performance.
%%%%%%%%%


\section{Analysing CGs}
\label{sec:sectionCGana}

We start by defining a conflict, and present requirements for a solution.
Then, we introduce a logical translation of sequential CG, corresponding to \cite{lager_nivre01}, and modify it into a SAT-problem about the \emph{original} sentence before applying the rules.
%this will tell us if it is possible for a senten
We refine our solution by restricting what kind of sentences we can create.
The whole method requires only a morphological lexicon, no corpus. 

\paragraph{Conflict}

We define \emph{conflict} as follows: a list of rules $R$ is in conflict with the rule $r$, if applying $R$ makes it impossible to apply $r$, regardless of input. 
Some examples of conflicts follow:

\begin{itemize}
\item If two equivalent rules $r$ and $r'$ occur in the grammar, the second occurrence will be disabled by the first
\item A list of rules $R$ selects something in a context, and $r'$ removes it
\item A list of rules $R$ removes something in a context, and $r'$ selects it
\item A list of rules $R$ removes something from the context of a rule $r'$, so $r'$ can never apply
\item A rule $r$ has an internal conflict, such as non-existent
tag combination, or contradictory requirements for a context word
\end{itemize}

This definition is very similar to the concept \emph{bleeding order} in generative phonology \cite{kiparsky1968}; however, since we are talking about an explicit list of 
human-written rules, we include also rule-internal conflicts in our classification.
The conflicting (or ``bleeding'') $R$ can be a single rule or a list of rules: for instance, if one rule removes a verb in
context $C$, and another in context $\neg C$, together these rules
remove a verb in all possible cases, disabling any future rule that
targets verbs.

% While rule-internal conflicts can be detected by simpler means, taking
% care of rule interaction requires a {\em semantic} rather than a {\em
%  syntactic} analysis.
% In order to find effects of rule interaction, we must keep track of
% the possible sentences at each step. After each rule, we have two
% possibilities: the rule fires, or it does not fire. In case the rule does
% not fire, we have again two options: either its conditions are not met,
% or its target is the only remaining analysis. 

\paragraph{Solution}

How do we find out if a rule $r$ can act? 
We could apply the grammar to a large corpus and count the number of times 
each rule fires; if some rule never fires, we can suspect there is something wrong 
in the rule itself, or in the interaction with previous rules. 
But it can also be that $r$ just targets a rare phenomenon, and there was no sentence in the corpus that would trigger it.

Of course, tagged corpora are extremely useful for many questions in CG analysis.
A corpus can show which rules are the most used, or which rules give false analyses. 
Luckily, we have already methods for finding such statistics---the question 
about conflicts is orthogonal to those, and the solution needs to address only 
the part about conflicts, not about rules being frequent or accurate.
Therefore, we can take a more artificial approach. % generate our own sentences.
Remember the definition of conflict: ``applying $R$ makes it impossible to apply $r$ \emph{regardless of input}''.
In a nutshell, we are going to show the absence of a conflict by trying to create 
a sequence where $r$ can apply after $R$; conversely, we detect a conflict by 
showing that such sequence cannot be created.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\newVar{$\text{\em word}'_\textsc{ RD}$}
\def\oldVar{$\text{\em word}_\textsc{\,RD}$}
\def\eqdef{\Coloneqq}
\def\invConds{\text{invalid condition}}
\def\onlyTrgLeft{\text{only target left}}

\subsection{From disambiguation to generation}

\paragraph{SAT-encoding of sequential CG}
\label{sec:orderedScheme}

In order to analyse real-life CGs, we need to model the semantics of sequential CG: 
rule application takes effect immediately, is irreversible\footnote{As pointed out by Eckhard Bick, VISL CG-3 allows reference to deleted readings. In principle, this would not be an obstacle for our implementation, because no variables are removed.}, and only allows changes in the target.
We restrict ourselves to the operations on morphological disambiguation, and only {\sc select} and {\sc remove} rules. 
The following encoding does not support dependency relations, nor rule types which add readings or cohorts. 
%In order to support the full feature set of  most likely, we will have to modify our encoding to fully support the features of VISL CG-3.

%There is no way around it: an analysis that treats \t{REMOVE~v ; REMOVE~v~IF~(-1~det)} the same as \t{REMOVE~v~IF~(-1~det) ; REMOVE~v} is worth nothing. The first one is a true conflict, because the first rule has a broader condition; it removes the verb in any possible case. The second rule order is possible: there can always be a sentence that has a verb, but is not preceded by a determiner, hence the first rule would not match, and the verb is saved for the second rule. 
%
%
%
%We need to model the state of the sentence after each rule application. 
%Luckily, we do not need to reinvent the wheel\footnote{of course we did. like, who reads other people's papers.}: 
% This is done in \cite{lager_nivre01}: they present CG as a composition of predicates, 
% numbered by the rules in the grammar. Each predicate is applied to the result of the previous 
% applications, and the ``do not remove last reading'' property is checked each time.
%
%
Last time, we only used ordering as a way to choose the which rules to apply.
But there was no state: all clauses operated in parallel, on the same variables. 
Now, we need a new variable for a reading every time when it is targeted; 
that is, when its state potentially changes.
%But now, we assume that each variable starts off as true: 
%all those readings are true at the ``first round'', and the goal is to make more and more readings false, as more rules are applied.
As before, a sentence is a vector of cohorts, which is, in turn, a vector of variables representing the readings of the current cohort.
At each rule application, we create a new variable \newVar{} for each targeted reading \oldVar{}.
The new variable \newVar{} is true iff 

\begin{figure}[h]
\begin{tabular}{l l}
(a) \oldVar{} was true, and 
                             & (b) the rule cannot apply: this can be because \\
                                     & ~~~~-- its conditions do not hold, or \\
                                     & ~~~~-- it would remove the last reading.
\end{tabular}
\end{figure}

\noindent We keep the same example sequence from Chapter~\ref{chapterCGSAT}, {\em la casa grande}. In the following, we apply the rule \t{REMOVE v IF (-1 det)} to it.

$$\begin{array}{r l}
\text{New variable } \casa{}'_\v 
      & \Longleftrightarrow \quad \casaV\ 
        \wedge\: ( \; \ob{\neg\laDet}^{\invConds} 
        \vee  \ob{(\casaV \wedge \neg \casaN) }^{\onlyTrgLeft} ) \\
\end{array}$$


\noindent After the application, we replace each \oldVar with \newVar in the sentence vector; those variables that are not touched by the rule, will be carried over to the next round unchanged. 
For example, if we apply two rules which target verbs and one which targets pronouns, 
the sentence vector will look like the following. 


%\begin{figure}
$$\begin{array}{r @{~\rightarrow~} l}
\emph{la} & \{\laDet, \la{}'_\prn \} \\
\emph{casa} & \{\casa{}''_\v, \casaN \} \\
\emph{grande} & \{ \grandeAdj \} \\
\end{array}$$
%\label{fig:after3Rules}
%\end{figure}


\paragraph{Symbolic sentence}

We saw how $\casa{}'_\v$ was created, based on the status of $\casaV$ and the conditions at the time. Similarly, $\casa{}''_\v$ will be created based on $\casa{}'_\v$. 
%If there is a pronoun in its conditions, and the rule which targest
But what is the status of the variables in the beginning?
%We have not specified yet what is the status of the variables in the beginning. 
In fact, that decision makes a crucial difference. 
If all variables start off as true, then we have, in effect, reimplemented the logical encoding by Lager and Nivre \cite{lager_nivre01}. 
This option would not make an interesting SAT-problem: 
there is no search involved, just manipulation of Boolean expressions in a completely deterministic way.
All the new variables, created from the rule applications, would get their value immediately: $\casa{}'_\v \Leftrightarrow \grandeAdj \wedge \neg (\casaV \wedge \neg \casaN)$ just translates into $\casa{}'_\v \Leftrightarrow \text{\em True} \wedge \neg (\text{\em True} \wedge \neg \text{\em True})$. 

%There is nothing to decide, no search whatsoever; this problem is even simpler than the animal problem, where we at least had some choices to make.


%However, when all the readings start off as unassigned, the SAT-problem becomes 
%``Which readings were true before any rule applications?''
In order to turn this problem into a SAT-problem, we will have the readings start off
unassigned. All the other variables computed along the way depend on the original variables, so the question to the SAT-solver becomes: \emph{``Which readings were originally true?''}
For implementing a CG engine, this question does not make much sense: we know which readings were given by the morphological analyser. 
But our task now is to {\em generate} the original sentence, which will pass through the rules. 
Here comes the most important modification: we will apply the rules to something we call {\em symbolic sentence}. 
Every cohort, called {\em symbolic word}, contains every possible reading, and rule applications are responsible for shaping the sentence into a concrete one.

% Our analysis operates on a rule $r$, which is preceded by a list of rules $R$, and is concerned with answering the following question: ``Does there exist an input sentence $S$ that can trigger rule $r$, even after passing all rules $R$ that came before $r$?''
% Instead of concrete sentences from a corpus, we apply rules on {\em symbolic sentences}

Before we can do any analysis any of the rules, we need to find out what the set of all possible readings of a word is. We can do this by extracting this information from a lexicon, but there are other ways too; we will explain this in more detail in the coming sections. In our experiments, the number of readings has ranged from about 300 to about 9000. 

\paragraph{Width of a rule}
Furthermore, when we analyse a rule $r$, we need to decide the {\em width} $w(r)$ of the rule $r$: How many different words should there be in a sentence that can trigger $r$? Most often, $w(r)$ can be easily determined by looking at how far away the rule context indexes in the sentence relative to the target. For example, in the rule \t{REMOVE v IF (-1 det)}, the width is 2.

If the context contains a \t{*} (context word can be anywhere),
we need to make an approximation of $w(r)$, which may result in false positives or negatives later on in the analysis; this indeed happened in the Finnish grammar in Section~\ref{sec:finnishEval}. %For the implementation, we tried for each \t{*} multiple variants of the sentence. 
For example, given the rule \t{REMOVE~v~IF~(-1*~det)}, 
we tried first a sentence of width 2; if there was a conflict, we tried width 3, and then 4. For a rule with multiple \t{*}s, we create combinations in the range of $\pm$ 2 symbolic words for each \t{*}-condition; 
in addition, we need to specify where the target is in the symbolic sentence. 
For instance, the rule \t{REMOVE~v~IF~(-1*~det)~(1*~det)} would be tested 
with the following combinations, where C means condition and T means target:
% in a range of 3--7 symbolic words: both \t{1*} and \t{-1*} can be interpreted as \t{}. 
% For the rule with two \t{*}s, we tried all the following combinations: 
(C,T,C); 
(C,C,T,C); 
(C,T,C,C); 
(C,C,T,C,C); 
(C,C,C,T,C,C); 
(C,C,T,C,C,C) and
(C,C,C,T,C,C,C).


%we create sentences that are up to 3 words wider than the context without \t{*}, and try them all.

\paragraph{Rule application}
Finally, we define what does it mean for a sentence to ``pass through'' a rule. 
Let us enumerate the cases:
\begin{enumerate}
\item The sentence is out of scope; target not removed
\item The conditions of the rule do not hold; target not removed
\item The target is the only possible reading left; target not removed
\item The target was never in place
\item The target is removed
\end{enumerate}
%In a symbolic sentence, we cannot properly distinguish between the last two cases. 
Let us illustrate the difference between the last two cases with a rule that targets pronouns, say, \t{REMOVE prn IF (1 v)}. 
If the target was never in place, then both the original $\laPrn$ and the newly created $\la{}'_\prn$ end up as false. 
If the target is removed, then $\laPrn$ will be true and $\la{}'_\prn$ false.
This means that a rule with the condition \t{IF (-1 prn)} behaves differently depending on where in the rule sequence it is placed: 
if it is applied before \t{REMOVE prn IF (1 v)}, then it will match the original reading $\laPrn$. Any rule applied after that will get the newly created variable $\la{}'_\prn$.

%that is, whether the new variable depends on $\laPrn$ or  $\la{}'_\prn$.
%The difference between the last two cases is that, say we have the readings $\laPrn$ and $\la{}'_\prn$

Now we have the definitions in place. In the following, we are going to show two examples; first one a very simple conflict, and the second one with more complicated interaction.


\paragraph{Example 1: conflict}

Let us look at a conflicting case. For simplicity, we assume that the full set of readings in the language is $\{ \emph{det def, noun sg, noun pl, verb sg, verb pl} \}$. We ignore all lexical readings for now, and assume dummy words of the form \emph{w$_{i}$}, where $i$ refers to the index of the word.
The rules are as follows:


\begin{verbatim}
r1 = REMOVE verb IF (-1 det) ;
r2 = REMOVE verb IF (-1 det) (1 noun) ;
\end{verbatim}


We want to know if the last rule is able to apply, after going through the rules that come before it---in this case, there is only one such rule. 
The width of the last rule is three: one condition to the left of the target, one to the right, so we create a symbolic sentence of three words. Below, we show the symbolic sentence, consisting of the symbolic words {\em w1, w2} and {\em w3}.

\begin{figure}[h]
\centering
\begin{tabular}{p{0.6cm} l  p{0.6cm} l p{0.6cm} l }
\t{"<w1>"}    &                     &  \t{"<w2>"}  &           &  \t{"<w3>"}    \\
              & \t{"w1" det def}    & &      \t{"w2" det def}  & &  \t{"w3" det def} \\
              & \t{"w1" noun sg}    & &      \t{"w2" noun sg}  & &  \t{"w3" noun sg} \\
              & \t{"w1" noun pl}    & &      \t{"w2" noun pl}  & &  \t{"w3" noun pl} \\
              & \t{"w1" verb sg}    & &      \t{"w2" verb sg}  & &  \t{"w3" verb sg} \\
              & \t{"w1" verb pl}    & &      \t{"w2" verb pl}  & &  \t{"w3" verb pl} \\
\end{tabular}
\end{figure}

After applying the first rule, we have a situation which looks much like the one in the previous chapter, Figure~\ref{fig:modelsOneRule}. 
If the symbolic word {\em w1} is a determiner, then {\em w2} cannot be a verb; 
the only exception is the case where verb is the only analysis of {\em w2}. 
As before, the verb analysis {\em w2} can also be false, even if {\em w1} 
is not a determiner. The exact same dependencies are created between the 
symbolic words {\em w2} and {\em w3}.
The first word {\em w1} is out of scope of the condition, because it has no preceding word. 
Below we see the affected readings after the first rule application, with newly created variables:

\begin{figure}[h]
$$\begin{array}{l @{~\rightarrow~} l}
1 & \{w1_{\detdef}, \  w1_{\noun\sg}, \  w1_{\noun\pl}, \ w1_{\verb\sg}, \ w1_{\verb\pl} \} \\
2 & \{w2_{\detdef}, \  w2_{\noun\sg}, \  w2_{\noun\pl}, \ w2'_{\verb\sg}, \ w2'_{\verb\pl} \} \\
3 & \{w3_{\detdef}, \  w3_{\noun\sg}, \  w3_{\noun\pl}, \ w3'_{\verb\sg}, \ w3'_{\verb\pl} \} \\
\end{array}$$
\end{figure}

There is no ``final sentence'' yet, simply constraints on the possible combinations of determiners and verbs. If we asked for a solution now, it could be anything; for instance, all three words are determiners. Just asking for a freely chosen sequence is not very interesting; there are so many possibilities, and even after applying more rules, most of the combinations are not explicitly prohibited. 

We want to know if there is a sequence that can trigger the last rule.
In order to trigger the rule, the sequence must have the following three features:
\begin{itemize}
\item Target readings: at least one reading with a \emph{verb} tag in the target position {\em w2}.
\item Ambiguity: at least one reading without a \emph{verb} tag in the target position; if there are only \emph{verb} readings in the target, the rule would not fire.
\item Conditions: at least one reading with a \emph{det} tag in the cohort preceding the target, and at least one reading with a \emph{noun} tag in the cohort following the target.
\end{itemize}


We can see that some of these requirements can be fulfilled: the first rule allows models where {\em w2} contains \emph{target readings}. If the rule had been \t{REMOVE verb}, that is, unconditionally remove all verbs, then this requirement could not be fulfilled. But so far we have not run into the wall. 
The second requirement, for \emph{ambiguity} is no problem either: other readings of {\em w2} have not been targeted, so we are free to choose anything.

As for \emph{conditions}, the part about \t{(1 noun)} can be fulfilled; nothing prevents {\em w3} from being a noun. But the first condition, \t{(-1 det)}, cannot be true, if the target {\em w2} has to be a verb---the first rule has prohibited exactly that combination.
Therefore, when we try to ask for a solution where all these requirements hold, we will get a conflict. The result shows us that the rule \t{REMOVE~verb~IF~(-1~det)~(1~noun)} cannot ever apply, if the rule \t{REMOVE~verb~IF~(-1~det)} has been already applied. 
%For any pair of two rules \t{REMOVE x IF C1} and \t{REMOVE x IF C2}, if $C2 \subseteq C1$, then the latter rule will not have a chance to apply; simply because there is no condition that would fulfil C2 but not C1.
% As we see later from the evaluation, recognising such pairs is not always easy.

\paragraph{Example 2: no conflict}
The previous was a simple example of a conflict: two rules target the same reading, and the first one had broader conditions. 
%and the conditions were chosen such that the first rule applies in more cases than the second.
Since we had only one preceding rule, we could not demonstrate why is it important to apply all the rules in order---even with a longer list of rules, the previous example could have also worked unordered, as long as the last rule is separated from rules before it.
%two rules had the same target, and the first mentioned had a broader set of conditions.
%Furthermore, the order was not really crucial. 
Now we will show another example, where we illustrate why is it important to create new variables, and how conditions can affect the state of the variables, but in a more limited way. The set of readings is the same, and the rules are as follows.

\begin{verbatim}
r1 = REMOVE verb IF (-1C det) ;
r2 = SELECT det  IF ( 1 verb) ;
r3 = REMOVE verb IF (-1 det) ;
\end{verbatim}

\noindent The width of the last rule is 2, thus we create a symbolic sentence with only {\em w1} and {\em w2}. The sentence is shown below:

\begin{figure}[h]
\centering 
\begin{tabular}{p{0.6cm} l  p{0.6cm} l }
\t{"<w1>"}    &                     &  \t{"<w2>"}  &           \\
              & \t{"w1" det def}    & &      \t{"w2" det def}  \\
              & \t{"w1" noun sg}    & &      \t{"w2" noun sg}  \\
              & \t{"w1" noun pl}    & &      \t{"w2" noun pl}  \\
              & \t{"w1" verb sg}    & &      \t{"w2" verb sg}  \\
              & \t{"w1" verb pl}    & &      \t{"w2" verb pl}  \\
\end{tabular}
% \label{fig:ambiguousDet}
% \caption{After $r1$, the symbolic word {\em w1} has to be determiner, but ambiguously so.}
\end{figure}


To begin, let us only look at {\em r1} and {\em r3}. Like in the previous example, they target the same reading, but now the order is good: the first rule is the one with a narrower condition, which means that it is possible for a sequence to pass through it, and still have the verb reading in {\em w2} intact---it just needs to have something else in addition to the determiner in {\em w1}.
The following is an example of such sequence (false readings not shown). %---if we stopped after $r1$ and asked for a solution that triggers $r3$, we might get just that.

\begin{figure}[h]
\centering
\begin{tabular}{p{0.6cm} l  p{0.6cm} l }
\t{"<w1>"}    &                     &  \t{"<w2>"}  &           \\
              & \t{"w1" det def}    & &      \t{"w2" noun pl}  \\
              & \t{"w1" noun sg}    & &      \t{"w2" verb sg}  \\
\end{tabular}
% \label{fig:ambiguousDet}
% \caption{After $r1$, the symbolic word {\em w1} has to be determiner, but ambiguously so.}
\end{figure}


So far, we have passed through {\em r1} with the case ``condition does not hold, target not removed''. Now, let us add {\em r2}: \t{SELECT det IF (1 verb)}. 
We must, in fact, select the determiner and remove everything else: 
the condition of {\em r2} happens to be the target of {\em r3}, so it must hold. 
%if the condition of $r2$ did not hold, then $r3$ would not have its target.
But we have the notion of state now, so this is no problem.
On arriving to {\em r1}, the symbolic word {\em w1} had to be ambiguous---that is, one of the variables $w1_{\noun\sg}, \  w1_{\noun\pl}, \ w1_{\verb\sg}, \ w1_{\verb\pl}$ must be true. 
But after passing through {\em r2}, the state of {\em w1} has changed:
it contains a set of new variables $w1'_{\noun\sg}, \ w1'_{\noun\pl}, \ w1'_{\verb\sg}, \ w1'_{\verb\pl}$, and all of them must be false.
Since the clauses formed by {\em r1} and {\em r3} get access to different variables, there is no conflict.

% Thanks to the distinction, the initial {\em w1}, with the primeless variables, does not trigger {\em r1}. 
% The {\em w1} changed by {\em r2} is not visible to {\em r1}, so 
% We have arrived to the situation where {\em w1} at time {\em t1} does not trigger {\em r1}, 
% but {\em w1} at time {\em t3} triggers {\em r3}.


% The state of a given variable can still be affected by a condition, but in a more restricted way.
% We allow \t{w1<n>} to be true and \t{w1'<n>} be false; both true; both false, but not \t{w1<n>} to be false and \t{w1'<n>} true. In other words, a reading may be in place all the time; absent all the time; or in place earlier and get removed later. No other changes are allowed.




% In the system of interconnected clauses, application of rule number 100 may not only affect the target of rule number 1, but conditions as well. 
% A reading may be removed from a symbolic word between rules 1 and 100, if there is a rule that targets it among r2--r99. But if r1 requires w1 to be a noun, and r100 requires it to not be noun, this condition of r100 is not enough to make w1 change its nounhood at random.





\subsection{Towards realistic language}

\paragraph{Creating realistic readings}
\label{sec:realistic_readings}

Earlier we have shown an example with 5 readings (``det def'', ``noun sg'', ...). In a realistic case, we operate between hundreds and thousands of possible readings. 
%This is very much dependent on language: the simplest language we tested was Dutch, with 336 readings. The most complex was 
In order to find the set of readings, we expand a morphological lexicon\footnote{We used the lexica from Apertium, found in \url{https://svn.code.sf.net/p/apertium/svn/languages/}.}, ignore the word forms and lemmas, and take all distinct analyses. 
However, many grammar rules target a specific lemma or word form.
A simple solution is to retain the lemmas and word forms only for those entries where it is specified in the grammar, and otherwise leave them out. For example, the Dutch grammar contains the following rule:

\begin{itemize}
 \item[] \texttt{REMOVE ("zijn" vbser) IF (-1 Prep) (1 Noun) ;}
\end{itemize}

This hints that there is something special about the verb \emph{zijn}, compared to the other verbs. Looking at the lexicon, we find \emph{zijn} in the following entries:

\begin{itemize}
 \item[] 
\begin{verbatim}zijn:zijn<det><pos><mfn><pl>
zijn:zijn<det><pos><mfn><sg>
zijn:zijn<vbser><inf>
zijn:zijn<vbser><pres><pl>
\end{verbatim}
\end{itemize}

Thus we add special entries for these: in addition to the anonymous
``det pos mfn pl'' reading, we add ``\emph{zijn} det pos mfn pl''. 
The lemma is treated as just another tag.

 However, for languages with more readings, this may not be feasible. For instance, Spanish has a high number of readings, not only because of many inflectional forms, but because it is possible to add 1--2 clitics to the verb forms.
The number of verb readings without clitics is 213, and with clitics 1572.
With the previously mentioned approach, we would have to duplicate 1572 entries for each verb lemma. Even ignoring the clitics, each verb lemma still adds 213 new readings.

The readings in a grammar can be underspecified: for example, the rule
\texttt{REMOVE (verb sg) IF (-1 det)} gives us ``verb sg'' and ``det''.
%Set and list definitions were unfolded; a rule such as
In contrast, the lexicon only gives us fully specified readings, such
as ``verb pres p2 sg''. We implemented a version where we took
the tag combinations specified in the grammar directly as our
readings, and we could insert them into the symbolic sentences as well.
The shortcut works most of the time, but if we only take the readings
from the grammar and ignore the lexicon, it is possible to
miss some cases: e.g. the rule \texttt{SELECT (pron rel) IF (0 nom)} 
may require ``pron rel nom'' in one reading, but this method only gives
``pron rel'' and ``nom'' separately. 


In addition, we found that the tag lists in the grammars sometimes
contain errors, such as using a nonexistent tag or using a wrong level
in a subreading. If we accept those lists as readings, we will
generate symbolic sentences that are impossible, and not discover
the bug in the grammar.
However, if we are primarily interested in rule interaction, then using
the underspecified readings from the grammar may be an adequate solution.

%In fact, it may even catch interaction conflicts between rules which have an internal conflict


\paragraph{Creating realistic ambiguities}




In the previous section, we have created realistic \emph{readings}, by simply hardcoding legal tag combinations into variables. The next step in creating realistic \emph{ambiguities} is to constrain which readings can go together. For instance, the case of \emph{zijn} shows us that ``determiner or verb'' is a possible ambiguity. In contrast, there is no word form in the lexicon that would be ambiguous between an adjective and a comma, hence we do not want to generate such ambiguity in our symbolic sentences.

\begin{center}
\begin{tabular}{c|c|c|c|c}


            & n nt sg  & n f pl  & vblex sep inf & det pos mfn  \\ \hline
uitgaven    & 0        & 1       & 1             & 0    \\ 
toespraken  & 0        & 1       & 1             & 0    \\ 
haar        & 1        & 0       & 0             & 1    \\ 


\end{tabular}
\end{center}

We solve the problem by creating \emph{ambiguity classes}: groups of readings that can be ambiguous with each other. 
We represent the expanded morphological lexicon as a matrix, as seen
above: word forms on the rows and analyses on the columns. Each
distinct row forms an ambiguity class. For example, one class may
contain words that are ambiguous between plural feminine nouns and
separable verb infinitives; another contains masculine plural adjectives 
and masculine plural past participles.
Then we form SAT-clauses that allow or prohibit certain combinations. These clauses will interact with the constraints created from the rules, and the end result will be closer to real-life sentences.

Our approach is similar to \newcite{cutting_etal92}, who use ambiguity classes instead of distinct word forms, in order to reduce the number of parameters in a Hidden Markov Model. They take advantage of the fact that they don't have to model ``bear'' and ``wish'' as separate entries, but they can just reduce it to ``word that can be ambiguous between noun and verb'', and use that as a parameter in their HMM. 
%We can do a similar thing by saving a list of words with each ambiguity class. For example, we map the ambiguity class ``feminine plural noun or a separable verb infinitive'' to the list of word forms \{``uitgaven'', ``toespraken''\}, and then, if we generate such reading for our symbolic word, we can give one of these words as an example word.

There are two advantages of restricting the ambiguity within words.
Firstly, we can create more realistic example sentences, which should help the grammar writer.
Secondly, we can possibly detect some more conflicts. Assume that the grammar contains the following rules:

 \begin{itemize}
 \item[] 
\begin{verbatim}
 REMOVE adj IF (-1 aux) ;
 REMOVE pp  IF (-1 aux) ;
 \end{verbatim}
 \end{itemize}

 With our symbolic sentence, these rules will be no problem; to apply the latter, we only need to construct a target that has a realistic ambiguity with a past participle; the adjective will be gone already.
However, it could be that past participles (pp) only ever get confused with adjectives---in that case, the above rules would contradict each other.
 By removing the adjective reading, the first rule selects the past participle reading, making it an instance of ``$r$ selects something in a context, $r'$ removes~it''. 
The additional constraints will prevent the SAT-solver from creating an ambiguity outside the allowed classes, and such a case would be caught as a conflict.

\subsection{Use cases}

In the beginning of this chapter, we gave a list of questions, regarding the rules in Figure~\ref{fig:infrules}. After describing our implementation, we return to these questions, and explain how a SAT-solver can answer them. 
Section~\ref{sec:eval} shows the evaluation of the conflict detection, which we tried out for three grammars of different sizes. 
The use cases presented in this section have not been tried in practice; however, our setup makes them fairly straight-forward to implement.

\paragraph{Are all the rules distinct?} We gave the example of two rules in the Portuguese grammar, where one had the condition \t{(-1 Prep)} and the other \t{(-1 Para OR De)}. A grammarian who has some knowledge of Portuguese could tell that {\em para} and {\em de} are both prepositions, so these two rules seem to do almost the same thing.

How can we verify this? To start, we apply all candidate rules to the same initial symbolic sentence. For the resulting symbolic sentence, we can ask for solutions with certain requirements.
For instance, ``give me a model where a reading $a \notin \t{Inf}$ is true''.
There are less such models allowed after \t{SELECT Inf IF (-1 Prep)}---if 
a non-infinitive reading is in place, it means that the previous word cannot be any determiner---and 
they are all in the set of models allowed \t{SELECT Inf IF (-1 Para OR De)}. Thus, we can show that the first rule implies the second. It is in the hands of the grammar writer to decide whether to keep the stronger or the weaker rule, or if they should be placed in different sections.


\paragraph{Could two or more rules be merged?} This example concerns two or more rules with the same target but different conditions in the same position. 
All the six rules in Figure~\ref{fig:infrules} have conditions in position -1; four of them also in 0. Some of them have an additional careful context, and some do not.
A grammar writer might think that \t{IF (-1C Vbmod) (0C V)} and \t{IF (-1C Vbmod) (0 Ser)} are very similar, and could be merged into \t{SELECT Inf IF (-1C Vbmod) (0C V OR Ser)}. But could there be some unintended side effects in merging these two rules? Why is there a C in the first rule, but not in the second rule? 

The procedure is similar to the previous one. We initialise two symbolic sentences; on one we run the original rules in a sequence, and on the other the merged rule. 
Then, we can perform tests on the resulting symbolic sentences. Assuming that the ambiguity class constraints are in place, the result may show that C is not needed for the condition about {\em ser}, simply because {\em ser} is not ambiguous with anything else in the lexicon; hence the merged rule can safely have the condition \t{(0C V OR Ser)}. However, if {\em ser} can be ambiguous with something else, then this merged rule is stricter than the two original rules. If the grammar writer is still unsure whether there would be any meaningful sequences that would be missed, they can ask the SAT-solver to generate all those cases---this requires that the ambiguity classes are implemented, 
otherwise the number of solutions would blow up due to all the readings that are irrelevant to the rules in question.
%\formulation{otherwise the number of solutions would be exponential on all possible readings in the lexicon.} 

\paragraph{Generate a sequence that triggers rule(s) $R$ but not rule(s) $R'$.}
For any given rule, we can extract three requirements that would make it trigger. We illustrate them for the rule \t{REMOVE v IF (-1 det)}. In order to trigger the rule, the sequence must have
\begin{itemize}
\item target readings: at least one reading with the \emph{v} tag in the target position
\item ambiguity: at least one reading without the \emph{v} tag in the target position; if there are only \emph{v}-readings in the target, the would not fire.
\item conditions: at least one reading with the \emph{det} tag in the cohort preceding the target.
\end{itemize}

We can extract these requirements from both the rules that must be triggered, and the rules that must be not triggered. Then, we can request a solution from the SAT-solver.

\paragraph{What is the best order for the rules?}
We can generate variants of the rule order, and run them to a set of symbolic sentences. Then, for the resulting symbolic sentences, we can query which one is the most restricted, that is, allows the least models.
As a variant, we may be interested in the placement of just one rule in the sequence.

\paragraph{Does a rewritten rule correspond to the original?}
We can initialise two symbolic sentences, then run the original rule and the rewritten rule, and check if they allow the same models. 



\section{Evaluation}
\label{sec:eval}

We tested three grammars to find conflicting rules: 
Dutch\footnote{\scriptsize{\url{https://svn.code.sf.net/p/apertium/svn/languages/apertium-nld/apertium-nld.nld.rlx}, revision number r65111}},
with 59 rules; 
Spanish\footnote{\scriptsize{\url{https://svn.code.sf.net/p/apertium/svn/languages/apertium-spa/apertium-spa.spa.rlx}}, revision number r66938},
with 279 rules; and 
Finnish\footnote{\scriptsize{\url{https://github.com/flammie/apertium-fin/raw/master/apertium-fin.fin.rlx}}},
with 1185 rules. We left out \textsc{map}, \textsc{substitute} and other rule
types introduced in CG-3, and only tested \textsc{remove} and \textsc{select} rules.
The results for Dutch and Spanish are shown in Table~\ref{table:res},
and the results for Finnish in Table~\ref{table:resFin}.


% Unfortunately, we did not have time to perform such
% evaluation, and in addition, we only have gold standard corpus (20~000~words) for Spanish.



The experiments revealed problems in all grammars. For the smaller
grammars, we were able to verify manually that nearly all detected conflicts were
true positives---we found one false positive and one false negative,
when using a shortcut for the Spanish grammar. 
%The results for the Finnish grammar are inconclusive, 
% For the Finnish grammar, we did not have time to
% investigate all of them, but among those we could, we found both true and false negatives.
We did not systematically check for false negatives in any of the
grammars, but we kept track of a number of known tricky cases; mostly
rules with negations and complex set operations.
As the tool matures and we add new features, a more in-depth analysis
will be needed.
Another natural follow-up evaluation will be to compare the accuracy of the
grammar in the original state, and after removing the conflicts found
by our tool. %We aim to perform such evaluation, when the toolset is more mature.


\begin{table}[h]
\centering
\begin{tabular}{|p{2.84cm}|p{1cm}|p{1.15cm}|p{1.55cm}|}
%\begin{tabular}{|p{2.9cm}|p{0.95cm}|p{1.15cm}|p{1.55cm}|}

\hline
                   & \textsc{nld}  & \textsc{spa}  & \textsc{spa}~\textsuperscript{sep.~lem.} \\ \hline
\# rules           & 59            & 279       & 279     \\ \hline
\# readings        & 336           & 3905      & 1735    \\ \hline
\# true~positives~\textsuperscript{AC}% with~amb.~classes
                   & 7             & 45        & 44      \\ 
{\small (internal~+~interaction)}
                   & {\small
                      (6~+~1)}     & {\small 
                                    (21~+~24)} & {\small (20~+~24)} \\ \hline

\# true~positives~\textsuperscript{no AC}  & 7             & 43        & 42      \\ 
{\small (internal~+~interaction)}
                   & {\small
                      (6~+~1)}     & {\small 
                                    (18~+~25)} & {\small (17~+~25)} \\ \hline
\# false positives 
                   & 0             & 0        & 1  \\ \hline

\clock{} with amb. 
           classes & 7 s        & 1h 46m   &  23 min  \\ \hline

\clock{} no amb. 
           classes & 3 s        & 44 min       & 16 min     \\ \hline 


\end{tabular}
\caption{Results for Dutch and Spanish grammars.}
\label{table:res}
\end{table}

\subsection{Dutch} The Dutch grammar had two kinds of errors: rule-internal and rule interaction. As for rule-internal conflicts, one was due to a misspelling in the list definition for personal pronouns, which rendered 5 rules ineffective. The other was about subreadings: the genitive \emph{s} is analysed as a subreading in the Apertium morphological lexicon, but it appeared in one rule as the main reading. 
There was one genuine conflict with rule interaction, shown below:

\begin{itemize}
\item[\textsc{d$_1$.}] 
\begin{verbatim}REMOVE Adv IF (1 N) ;
REMOVE Adv IF (-1 Det) (0 Adj) (1 N) ;
\end{verbatim}
\end{itemize}

% These two rules both remove an adverb, but the first one has a broader condition:
% remove adverb if followed by a noun. In contrast, the second rule has a stricter condition: only remove adverb if it is preceded by a determiner, the adverb itself is ambiguous with an adjective, and followed by a noun. 
\noindent These two rules share a target: both remove an adverb.
The problem is that the first rule has a broader condition than the second, hence the second will not have any chance to act. 
If the rules were in the opposite order, then there would be no problem.



We also tested rules individually, in a way that a grammar writer might use our tool when writing new rules.
The following rule was one of them:

\begin{itemize}
\item[\textsc{d$_2$.}] 
\texttt{SELECT DetPos IF (-1 (vbser pres p3 sg)) (0 "zijn") (1 Noun);}
\end{itemize} 

\noindent As per VISL CG-3, the condition \texttt{(0 "zijn")} does not require
 \emph{zijn} to be in the same reading with the target \t{DetPos}.
It just means that at index 0,
there is a reading with any possessive determiner, and a reading with any \emph{zijn}.
However, the intended action is to select a ``det pos \emph{zijn}'' all in one reading;
this is expressed as \texttt{SELECT DetPos + "zijn"}.
In contrast, the 0-condition in example~\textsc{d$_1$} is used correctly:
the adjective and the adverb are supposed to be in different readings.


Can we catch this imprecise formulation with our tool? The SAT-solver will not mark it as a conflict (which is the correct behaviour). But if we ask it to generate an example sequence, the target word may be either of the following options. Seeing interpretation a) could then direct the grammar writer to modify the rule.

\begin{itemize}
\item[a)] \begin{verbatim}
"<w2>"
    "w2" det pos f sg
    "zijn" vbser inf
\end{verbatim}

\item[b)] \begin{verbatim}
"<w2>"
    "zijn" det pos mfn pl
\end{verbatim}
\end{itemize}


We found the same kind of definition in many other rules and grammars.
To catch them more systematically, we could add a feature that alerts in all cases where a condition with 0 is used. As a possible extension, we could automatically merge the 0-condition into the target reading, then show the user this new version, along with the original, and ask which one was intended.

% In the latter case, the grammar writer would hopefully notice the imprecise definition and change their definition. However, this is more of a happy side effect than intended feature---the grammar writer cannot count on our tool to notice all similar cases.

\subsection{Spanish} The Spanish grammar had proportionately the
highest number of errors. The grammar we ran is like the one
found in the Apertium repository (linked on the previous page), 
apart from two changes: we fixed some typos (capital O for 0) in order to make it compile, and
commented out two rules that used regular expressions, because we did not implement the support for them yet.
For a full list of found conflicts, see the annotated log of running our program in \url{
https://github.com/inariksit/cgsat/blob/master/data/spa/conflicts.log}. 


We include two versions of the Spanish grammar in Table~\ref{table:res}: in column \textsc{spa}, we added the lemmas and word forms as described in Section~\ref{sec:realistic_readings}, and in column \textsc{spa}\textsuperscript{sep.~lem.}, we just added each word form and lemma as individual readings, allowed to combine with any other reading. 
This latter version ran much faster, but failed to detect an internal conflict for one rule, and reported a false positive for another. 
% FAIL TO DETECT: SELECT:pr_cnjadv_3 cnjadv IF (0 "despu√©s de") 
% FALSE POSITIVE: SELECT:este_1 det IF (0 "este" + (m sg)|(m sp)|(mf sg)|(mf sp))

When we added ambiguity class constraints, we found three more internal conflicts.
Interestingly, the version with ambiguity classes fails to detect an interaction conflict, which the simpler version reports, because one of the rules is first detected as an internal conflict. 
We think that neither of these versions is a false positive or negative; it is just a matter of priority. Sometimes we prefer to know that the rule cannot apply, given the current lexicon. 
However, we may know that the lexicon is about to be updated, and would rather learn about all potential interaction conflicts.

As an example of internal conflict, there are two rules that use \texttt{SET Cog = (np cog)}: the problem is that the tag ``cog'' does not exist in the lexicon. As another example, four rules require a context word tagged as NP with explicit number, but the lexicon does not indicate any number with NPs. It is likely that this grammar has been written for an earlier version, where such tags have been in place.
One of the conflicts that was only caught by the ambiguity class constraints had the condition \texttt{IF (1 Comma) (..) (1 CnjCoo)}. The additional constraints correctly prevent commas from being ambiguous with anything else.

As for the 25 interaction conflicts, there were only 9 distinct rules that rendered 25 other rules ineffective.
In fact, we can reduce these 9 rules further into 3 different groups: 4~+~4~+~1, where the groups of 4 rules are variants of otherwise identical rule, each with different gender and number.
An example of such conflict is below (gender and number omitted for readability):

\begin{itemize}
\item[\textsc{s$_{1}$.}] 
\begin{verbatim}
# NOM ADJ ADJ
SELECT A OR PP IF (-2 N) (-1 Adj_PP) (0 Adj_PP) (NOT 0 Det);

# NOM ADJ ADJ ADJ
SELECT A OR PP IF (-3 N) (-2 N) (-1 Adj_PP) (0 Adj_PP) (NOT 0 Det);
\end{verbatim}
\end{itemize}


In addition, the grammar contains a number of set definitions that were never
used. Since VISL CG-3 already points out unused sets, we did not add such
feature in our tool. However, we noticed an unexpected benefit when
we tried to use the set definitions from the grammar directly as our
readings: this way, we can discover inconsistencies even in
set definitions that are not used in any rule.
For instance, the following definition requires the word to be all of
the listed parts of speech at the same time---most likely, the grammar writer meant 
OR instead of +:
\begin{itemize}
\item[\textsc{s$_2$.}] 
\texttt{SET NP\_Member = N + A + Det + PreAdv + Adv + Pron ;}
\end{itemize}

If it was used in any rule, that rule would have been marked as
conflicting. We noticed the error by accident, when the program
offered the reading ``\emph{w2}~n~adj~det~preadv~adv~prn''
in an example sequence meant for another rule.


As with the Dutch grammar, we ran the tool on individual rules and
examined the sequences that were generated. None of the following was
marked as a conflict, but looking at the output indicated that there
are multiple interpretations, such as whether two analyses for a
context word should be in the same reading or different readings.
We observed also cases where the grammar writer has specified desired
behaviour in comments, but the rule does not do what the grammar
writer intended. 

\begin{itemize}
\item[\textsc{s$_3$.}] \t{REMOVE Sentar IF (0 Sentar) (..) ;}
\item[] \t{SELECT PP IF (0 "estado") (..) ;}
\end{itemize}

The comments make it clear that the first rule is meant to disambiguate between \emph{sentar} and \emph{sentir}, but the rule does not mention anything about \emph{sentir}.
Even with the ambiguity class constraints, the SAT-solver only created an ambiguity where \emph{sentar} in 1st person plural is ambiguous with an anonymous 1st person plural reading.
This does not reflect the reality, where the target is only ambiguous with certain verbs, and in certain conjugated forms.

The second case is potentially more dangerous. 
The word form $estado_{W}$ 
can be either a noun ($estado_{L}$, `state'), or the past participle of the verb $estar_{L}$. 
The condition, however, addresses the lemma of the noun, $estado_L$, whereas the lemma of the PP is $estar_{L}$.
This means that, in theory, there can be a case where the condition to select the PP is already removed. As for now, the lexicon does not contain other ambiguities with the word form $estado_{W}$, but we could conceive of a scenario where someone adds e.g. a proper noun $Estado_{L}$ to the lexicon. Then, if some rule removes the lemma $estado_{L}$, the rule to select PP will not be able to trigger.


Another question is whether this level of detail is necessary. 
After all, the grammar will be used to disambiguate real life texts, where neither \emph{sentar} nor \emph{estado} are likely to have any other ambiguities.
In fact, we are planning to change how we handle the lexical forms; with those changes, it will become clear whether the imprecision will result in potential errors, given the current lexicon. 



\subsection{Finnish} 
\label{sec:finnishEval}

The results for the Finnish grammar are shown separately, in Table~\ref{table:resFin}. We encountered a number of difficulties and used a few shortcuts, which we did not need for the other grammars---most importantly, not using the ambiguity class constraints. Due to these complications, the results are not directly comparable, but we include Finnish in any case, 
to give an idea how our method scales up: both to more rules, and more complex rules.

\paragraph{Challenges with Finnish} The first challenge is the morphological complexity of Finnish.
There are more than 20,000 readings, when all possible clitic combinations are included.
After weeding out the most uncommon combinations, we ended up with sets of 4000--8000 readings.

The second challenge comes from the larger size of the grammar. Whereas the Spanish and Dutch had only tens of word forms or lemmas, the Finnish grammar specifies around 900 of them.
Due to both of these factors, the procedure described in Section~\ref{sec:realistic_readings} would have exploded the number of readings, so we simply took the lemmas and word forms, and added them as single readings. 
In cases where they were combined with another tag in the grammar, we took that combination directly and made it into an underspecified reading: for instance, we included both \emph{aika} and ``\emph{aika} n'' from the rule \texttt{SELECT "aika" + N},
but nothing from the rule \texttt{SELECT Pron + Sg}. This method gave us 1588 additional readings.

Finally, we were not able to create ambiguity class constraints---expanding the Finnish morphological lexicon results in 100s of gigabytes of word forms, which is simply too big for our method to work. 
For future development, we will see if it is possible to manipulate the finite automata directly to get hold of the ambiguities, instead of relying on the output in text.




\def\oneClLG{{\sc 1~cl~+~lem}}
\def\twoClLG{{\sc 2~cl~+~lem}}
\def\oneClRG{{\sc 1~cl~+~rds}}
\def\allRG{{\sc only~rds}}

\def\wH{1.1cm}
\def\wdt{0.7cm}

\begin{table}[t]
\centering
\begin{tabular}{| p{\wH} @{~+~} p{\wH}  | r @{~+~} l  | r @{~+~} l  | r @{~+~} l  | r @{~+~} l  |}

%\begin{tabular}{| p{\wH} @{~+~} p{\wH}  | p{\wdt} @{~+~}p{\wdt}  | p{\wdt} @{~+~}p{\wdt}  | p{\wdt} @{~+~}p{\wdt}  | p{\wdt} @{~+~}p{\wdt}  |}

\hline
\multicolumn{2}{|c|}{} & \multicolumn{2}{c|}{\oneClLG}
                              & \multicolumn{2}{c|}{\twoClLG}
                                              & \multicolumn{2}{c|}{\oneClRG}      				   & \multicolumn{2}{c|}{\allRG} \\ \hline
\multicolumn{2}{|l|}{\# readings}
              & \multicolumn{2}{c|}{5851}         
              				  & \multicolumn{2}{c|}{9494} 
              				  				  & \multicolumn{2}{c|}{6657}                & \multicolumn{2}{c|}{2394} \\
lexicon &
grammar   & 4263 & 1588 &  7906 & 1588  & 4263 & 2394  & 0 & 2394  \\ \hline
\multicolumn{2}{|l|}{\#~conflicts}
              & \multicolumn{2}{c|}{214}   
              				  & \multicolumn{2}{c|}{214}
              				                  & \multicolumn{2}{c|}{22}
              				                                  & \multicolumn{2}{c|}{22} \\
internal & 
 interaction & 211 & 3  & 211 & 3  & 19 & 3   &  19 & 3   \\ \hline

\multicolumn{2}{|l|}{\clock{} all 
       rules (approx.)}
             & \multicolumn{2}{c|}{\~{}4h 30min}
             		          & \multicolumn{2}{c|}{\~{}9h 30min}
             		          			     & \multicolumn{2}{c|}{\~{}7h 45min} 
             		          			     				&  \multicolumn{2}{c|}{\~{}2h 30min} \\ \hline


\end{tabular}
\caption{Results for Finnish (1185 rules). 
(\oneClLG) 1 clitic + lemmas from the grammar; 
(\twoClLG) 2 clitics + lemmas from the grammar;  
(\oneClRG) 1 clitic + all readings from the grammar;
(\allRG) all readings from the grammar. }
\label{table:resFin}
\end{table}

\paragraph{Results}
The results are shown in Table~\ref{table:resFin}.
In the first column, we included only possessive suffixes. In the second column, we included question clitics as well.
Both of these readings include the 1588 lemmas and word forms from the grammar.
In the third column, we included all the tag combinations specified in the grammar, and in the fourth, we took only those, ignoring the morphological lexicon.

The first two variants reported a high number of internal conflicts. 
These are almost all due to nonexisting tags. The grammar was written in 1995, and updated by \newcite{pirinen2015}; such a high number of internal conflicts indicates that possibly something has gone wrong in the conversion, or in our expansion of the morphological lexicon.
As for accuracy, adding the question clitics did not change anything: they were already included in some of the 1588 sets with word forms or lemmas, and that was enough for the SAT-solver to find models with question clitics.
We left the result in the table just to demonstrate the change in the running time.

%Example reading that adds question clitic to our arsenal: \texttt{SELECT "joka" + Pron + Q}

The second two variants are playing with the full set of readings from the grammar. For both of these, the number of reported conflicts was only 22.
Given the preliminary nature of the results, we did not do a full analysis of all the 214 reported conflicts.
Out of the 22, we found 17 of them as true conflicts,
 but 5 seemed to be caused by our handling of rules with \t{*}: all of these 5 rules contain a LINK and multiple \t{*}s. On a positive note, our naive handling of the \t{*} seems to cover the simplest cases.
Some examples of true positives are shown in the following.

%SELECT ("oma" gen) IF (NOT 1 n|adj|vblex|vaux|pron|cs|cc|adp|post|pr|intj|num|abbr) (0 LINK *-1 "olla"|"voida"|"saattaa") (0 n|adj|vblex|vaux|pron|cs|cc|adp|post|pr|intj|num|abbr) (0C nom)

\begin{itemize}
\item[\textsc{f$_1$}.]\t{"oma" SELECT Gen IF (..) (0C Nom) ;}

\item[] \t{SELECT Adv IF (NOT 0 PP) (..) ;}
\end{itemize}

Both of these are internal conflicts, which may not be trivial to see.
The first rule requires the target to be genitive and unambiguously nominative; however, these two tags cannot combine in the same reading.
As for the second rule, the definition of \texttt{PP} includes \texttt{adv} among others---with the sets unfolded, this rule becomes \texttt{SELECT~adv~IF~(NOT~0~pp|adv|adp|po|pr)~(..)}.

The following two examples are interaction conflicts:

\begin{itemize}
\item[\textsc{f$_2$}.]\begin{verbatim}
REMOVE A (0 Der) ; 
REMOVE N (0 Der) ; 
REMOVE A/N (0 Der) ; 
\end{verbatim}
\end{itemize}

This is the same pattern we have already seen before, but with a set of rules as the reason for conflict.
The first two rules together remove the target of the third, leaving no way for there to be adjective or noun.

\begin{itemize}
\item[\textsc{f$_3$.}]\begin{verbatim}
SELECT .. IF (-1 Comma/N/Pron/Q) ;
SELECT .. IF (-2 ..) (-1 Comma) ;
\end{verbatim}
\end{itemize}

The rules above have been simplified to show only the relevant part.
The conflict lies in the fact that \texttt{Comma} is a subset of \texttt{Comma/N/Pron/Q}:
there is no way to trigger the second rule without placing a comma in position -1, and thereby triggering the first rule.




\subsection{Performance} 
The running time of the grammars ranges from seconds to hours. 
Note that the times in the Finnish table are not entirely comparable with each other: we were forced to run the tests in smaller batches, and it is possible that there are different overheads, unrelated to the size of the SAT-problem, from testing 50 or 500 rules at a time. 
Despite the inaccuracies, we can see that increasing the number of readings 
and adding the ambiguity class constraints
slow the program down significantly.
%In order to understand the effect of each feature more precisely, we should run our tests on grammars that differ on only one of the variables. 

However, many of the use cases do not require running the whole
grammar. Testing the interaction between 5--10 rules takes just
seconds in all languages, if the ambiguity class constraints are not included. 
A downside in the ambiguity classes is that generating them takes a long time, 
and while the overhead may be acceptable when checking the full grammar,
it is hardly so when analysing just a handful of rules. 
We are working on an option to store and reuse the ambiguity class constraints.

\todo{Include results from the Basque experiment}

\section{Conclusions and future work}


We set out to design and implement an automatic analysis of constraint grammars that can find problematic rules and rule combinations, without the need for a corpus.
Our evaluation indicates that the tool indeed finds non-trivial conflicts and dead rules
from actual grammars. 

We did not have a volunteer to test the tool in
the process of grammar writing, so we cannot conclude whether the
constructed examples are useful for getting new insights on the rules.
In any case, there are still a number of features to improve and add.
Future work can be divided in roughly three categories: 
\begin{inparaenum}
\item[(a)] general improvement of the tool
\item[(b)] evaluation with users, and 
\item[(c)] integration as a part of CG development framework.
\end{inparaenum}

\subsection{General improvement}

\paragraph{Combining morphological and lexical tags}

Our solution to hardcode the tag combinations in the readings is
feasible for simple morphology, but it can cause problems with more
complex morphology.
Currently, if we add one new lemma to the set of readings, we need to
create as many new variables as there are inflectional forms
for that lemma. %easily hundreds for languages with rich morphology. 

We are currently working on adding the concepts of lemmas and word
forms directly to the representation of the possible readings.
A possible solution would be to make each tag a variable, and ask the
question ``can this reading be a noun? singular? 
conditional?'' separately for each tag. Then we could lift the
restriction of tag combinations into the SAT side: make SAT-clauses
that prohibit a comparative to go with a verb, or conditional with a noun.
Alternatively, we can still hardcode the set of morphological readings, and 
only use SAT-clauses to restrict which lexical form can go with which morphological analysis.

\paragraph{Heuristic checks for common issues} 
As mentioned earlier, some grammar design choices  
are common sources of misinterpretation.
Many of these issues concern the case where the conditions include 
the target cohort---does \t{SELECT foo IF (0 bar)} mean that ``foo'' and ``bar'' 
should be in the same reading or in different readings? 
Lemmas and word forms are another source of confusion, which is easy to check automatically against the lexicon. 
Ideally, these checks should be included in a special ``paranoid mode'', to not clutter the analysis\footnote{As pointed out by Eckhard Bick, the program should act upon this only if the 0 relates to an existing ambiguity class.}.


\paragraph{Support for more features of VISL CG-3}
As for longer-term goals, we want to handle more of the features in VISL CG-3,
such as \textsc{map}, \textsc{append} and
\textsc{substitute} rules, as well as dependency structure. 
This also means finding different kinds of conflicts, such as dependency circularity.
In order to implement rules that may add new readings, or new tags to
existing readings, we need to modify our approach in the SAT-encoding.
Even if the lexicon gives all readings that exist in the lexicon, the
user might give a nonexistent reading, or in the case of {\sc map}, a
syntactic tag, which is (by definition) not in the lexicon. We may need to move
to a more scalable solution.

\subsection{Evaluation with user base}

Our next step is to evaluate our tools together with actual grammar writers,
in comparison with a corpus-based method or machine learning. 
Below, we envision some properties that might be interesting; however, we would be interested in getting feedback from actual grammarians and adding features based on what is needed.

\paragraph{Reformatting a rule}

Another possible feature is to suggest reformattings for a rule. Recall
Figure~\ref{fig:infrules} from the introduction; in the case on the right, the
original rule was written by the original author, and another
grammarian thought that the latter form is nicer to read. Doing the
reverse operation could also be possible. If a rule with long
disjunctions conflicts, it may be useful to split it into smaller
conditions, and eliminate one at a time, in order to find the
reason(s) for the conflict.


\paragraph{Suggesting alternative orders} 
On a speculative note, it could be interesting to identify pairs for a potential ``feeding order'' that is missed in the grammar. Say we have the following rule sequence:

\begin{verbatim}
REMOVE:r1 x IF (-1C y)
SELECT:s2 y IF (...)
\end{verbatim}

If $s2$ appears before $r1$, if makes way for $r1$ to act later on the same round. 
However, if the rules are ordered as shown, and $y$ is not unambiguous from the beginning, then $r1$ has to wait for the next round to be applied.



Lager \cite{lager01transformation} observed that the rule sequence learned by the $\mu$TBL system did not remove further ambiguities after its first run, and concluded that the sequence was ``optimal''. 
It would be interesting to recreate the goals in \cite{lager01transformation} and \cite{bick2013tuning}, to see if this semantic analysis of rule dependencies could lead also to better ordering within a grammar.

Of course, it remains to be seen if any of these improvements would make a difference in speed; VISL CG-3 is already very fast, when the grammars are run multiple times.

% \paragraph{More cohesive grammar} 
% The SAT-based tool could potentially compliment
% \cite{voutilainen2004} state that the around 200 rules are probably enough to resolve 50--75 \% of ambiguities in the corpus used in the development. 
% This figure is very much thanks to Zipf's law: we can add rules that target the most frequent \emph{tokens}, thus disambiguating a high number of word forms. However, this does not guarantee a coherent whole of rules. 
% While the coverage information is easy to obtain from a corpus, our SAT-based tool could potentially compliment the process, and guide grammar writers towards a wide coverage of different linguistic phenomena.

\subsection{Integration as a part of CG development environment}

In order to attract the attention of the CG community, it would be desirable to incorporate the tools as a part of existing CG software. 
Currently, the described software consists of just under 3000 lines of Haskell code, including both the CG engine and the grammar analysis tool.
The grammar used for parsing the original CG files is written in BNFC \cite{bnfc}, and it is missing many constructs in CG-3. 
Given these factors, the preferred option would be a full reimplementation and integration as a part of VISL CG-3, or any other CG development framework. We believe this would make the tools easier to use, more cohesive and synchronised with the main CG engine, and likely much faster. Of course, it is up to the community and the developers to decide if these tools are of interest.







%%%%%%%
% Too verbose beginning

% In the previous chapter, we have seen the SAT encoding of CG used to
% create a CG engine.
% We evaluated our engine against the state-of-the-art VISL CG-3, using
% the same grammar and same gold standard corpus.
% Unsurprisingly, we got worse results when using the SAT-based parallel
% implementation on grammars that were written for an imperative and
% sequential CG engine. 
% Given that most real grammars out there are written in such way, 
% using SAT in the CG engine offers little practical use.


% In the implementation described in the previous paragraph, we analysed
% some real input sentences, and generated clauses of the rules that
% applied to those particular sentences. If there is a word that is
% analysed as n or v, it can only match rules that target those analyses
% (and is surrounded by appropriate context).

% Now, we operate on \emph{symbolic sentences}. We start from a
% situation where each word in the sentence can have any analysis: this
% means that every rule potentially applies to every word. This
% combination of rule application starts narrowing down the potential
% sentence.
% The rules are interpreted as more abstract and declarative:
% \texttt{REMOVE verb IF -1 det} does not just check if a particular
% word is verb, it prohibits a combination of determiner followed by
% verb \emph{anywhere}. The restriction can show in various ways, 
% %if another rule requires the 3rd word of the sentence to be determiner, then the 4th may not be a verb. If a rule requires
% and must be in sync with other restrictions.

% If it turns out that there is no symbolic sentence that can satisfy a
% number of rules, this means that there is a conflict among the
% rules. In the following chapter, we will give examples of such
% conflicts and describe how to detect them.


